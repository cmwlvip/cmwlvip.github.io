<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoop 生态 | Ofra Serendipity</title><meta name="author" content="Shiqing Huang"><meta name="copyright" content="Shiqing Huang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Apache Hadoop、HDFSApache Hadoop概述Hadoop介绍、发展简史、现状Hadoop介绍 狭义上Hadoop指的是Apache软件基金会的一款开源软件。  用java语言实现，开源允许用户使用简单的编程模型实现跨机器集群对海量数据进行分布式计算处理  Hadoop核心组件  Hadoop HDFS（分布式文件存储系统）：解决海量数据存储Hadoop YARN（集群资源管理">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop 生态">
<meta property="og:url" content="https://cmwlvip.github.io/2022/11/12/HadoopBase/index.html">
<meta property="og:site_name" content="Ofra Serendipity">
<meta property="og:description" content="Apache Hadoop、HDFSApache Hadoop概述Hadoop介绍、发展简史、现状Hadoop介绍 狭义上Hadoop指的是Apache软件基金会的一款开源软件。  用java语言实现，开源允许用户使用简单的编程模型实现跨机器集群对海量数据进行分布式计算处理  Hadoop核心组件  Hadoop HDFS（分布式文件存储系统）：解决海量数据存储Hadoop YARN（集群资源管理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg">
<meta property="article:published_time" content="2022-11-12T13:31:16.000Z">
<meta property="article:modified_time" content="2022-11-16T16:00:00.000Z">
<meta property="article:author" content="Shiqing Huang">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg"><link rel="shortcut icon" href="/img/favicon01.png"><link rel="canonical" href="https://cmwlvip.github.io/2022/11/12/HadoopBase/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Shiqing Huang","link":"链接: ","source":"来源: Ofra Serendipity","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop 生态',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-17 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar001.gif" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ofra Serendipity</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop 生态</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-12T13:31:16.000Z" title="发表于 2022-11-12 21:31:16">2022-11-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-16T16:00:00.000Z" title="更新于 2022-11-17 00:00:00">2022-11-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop 生态"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Apache-Hadoop、HDFS"><a href="#Apache-Hadoop、HDFS" class="headerlink" title="Apache Hadoop、HDFS"></a>Apache Hadoop、HDFS</h2><h3 id="Apache-Hadoop概述"><a href="#Apache-Hadoop概述" class="headerlink" title="Apache Hadoop概述"></a>Apache Hadoop概述</h3><h4 id="Hadoop介绍、发展简史、现状"><a href="#Hadoop介绍、发展简史、现状" class="headerlink" title="Hadoop介绍、发展简史、现状"></a>Hadoop介绍、发展简史、现状</h4><h5 id="Hadoop介绍"><a href="#Hadoop介绍" class="headerlink" title="Hadoop介绍"></a>Hadoop介绍</h5><ul>
<li><mark class="hl-label blue">狭义上Hadoop指的是Apache软件基金会的一款开源软件。</mark> 
<p>用java语言实现，开源<br>允许用户使用<strong>简单的编程模型</strong>实现<strong>跨机器</strong>集群对海量数据进行<strong>分布式计算</strong>处理</p>
</li>
<li><mark class="hl-label blue">Hadoop核心组件</mark> 
<p>Hadoop HDFS（分布式文件<strong>存储</strong>系统）：解决海量数据存储<br>Hadoop YARN（集群<strong>资源管理</strong>和任务调度框架）：解决资源任务调度<br>Hadoop MapReduce（分布式<strong>计算</strong>框架）：解决海量数据计算</p>
</li>
<li><mark class="hl-label blue">官网</mark> 
<p><a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
</li>
<li><mark class="hl-label red">广义上Hadoop指的是围绕Hadoop打造的大数据生态圈。</mark> 
<p><img src="/2022/11/12/HadoopBase/2022-11-12-22-38-08.png" alt="广义Hadoop"></p>
</li>
</ul>
<h5 id="Hadoop发展简史"><a href="#Hadoop发展简史" class="headerlink" title="Hadoop发展简史"></a>Hadoop发展简史</h5><blockquote class="pullquote right"><p><img src="/2022/11/12/HadoopBase/2022-11-12-22-42-09.png" alt="Hadoop之父"></p>
</blockquote>

<ul>
<li><mark class="hl-label blue">Hadoop之父</mark> 
<p><strong>Doug Cutting</strong></p>
</li>
<li><mark class="hl-label blue">Hadoop起源于ApacheLucene子项目：Nutch</mark> 
<p>Nutch的设计目标是构建一个大型的全网搜索引擎。<br>遇到瓶颈：如何解决数十亿网页的存储和索引问题</p>
</li>
<li><mark class="hl-label red">Google三篇论文</mark> 
<p>《The Google file system》：谷歌分布式文件系统GFS<br>《MapReduce: Simplified Data Processing on Large Clusters》：谷歌分布式计算框架MapReduce<br>《Bigtable: A Distributed Storage System for Structured Data》：谷歌结构化数据存储系统</p>
</li>
</ul>
<h5 id="Hadoop现状"><a href="#Hadoop现状" class="headerlink" title="Hadoop现状"></a>Hadoop现状</h5><ul>
<li><strong>HDFS</strong>作为分布式文件存储系统，处在<strong>生态圈的底层与核心地位</strong>；</li>
<li><strong>YARN</strong>作为分布式通用的集群资源管理系统和任务调度平台，<strong>支撑各种计算引擎运行</strong>，保证了Hadoop地位；</li>
<li><strong>MapReduce</strong>作为大数据生态圈第一代分布式计算引擎，由于自身设计的模型所产生的弊端，导致企业一线<strong>几乎不再直接使用</strong>MapReduce进行编程处理，但是很多软件的底层依然在使用MapReduce引擎来处理数据。</li>
</ul>
<div class="note info modern"><ol>
<li>狭义上Hadoop指软件，广义上Hadoop指生态圈</li>
<li>Hadoop之父Doug Cutting</li>
<li>Hadoop起源于Nutch项目</li>
<li>受Google3篇论文启发</li>
<li>2008年开源给Apache软件基金会</li>
</ol>
</div>

<h4 id="Hadoop特性优点、国内外应用"><a href="#Hadoop特性优点、国内外应用" class="headerlink" title="Hadoop特性优点、国内外应用"></a>Hadoop特性优点、国内外应用</h4><h5 id="Hadoop特性优点"><a href="#Hadoop特性优点" class="headerlink" title="Hadoop特性优点"></a>Hadoop特性优点</h5><ol>
<li><p><strong>扩容能力</strong> scalability<br>Hadoop是在可用的计算机集群间分配数据并完成计算任务的，这些集群可方便灵活的方式扩展到数以千计的节点。</p>
</li>
<li><p><strong>成本低</strong> Economical<br>Hadoop集群允许通过部署普通廉价的机器组成集群来处理大数据，以至于成本很低。看重的是集群整体能力。</p>
</li>
<li><p><strong>效率高</strong> efficiency<br>通过<strong>并发数据</strong>，Hadoop可以在节点之间动态<strong>并行</strong>的移动数据，使得速度非常快。</p>
</li>
<li><p>可靠性 reliability<br>能自动维护数据的多份复制，并且在任务失败后能自动地重新部署（redeploy）计算任务。所以Hadoop的按位存储和处理数据的能力值得人们信赖。</p>
</li>
</ol>
<h5 id="Hadoop国外应用"><a href="#Hadoop国外应用" class="headerlink" title="Hadoop国外应用"></a>Hadoop国外应用</h5><ul>
<li><p>Yahoo<br>支持广告系统<br>用户行为分析<br>支持Web搜索<br>反垃圾邮件系统</p>
</li>
<li><p>Facebook<br>存储处理数据挖掘和日志统计<br>构建基于Hadoop数据仓库平台（Apache Hive来自FB）</p>
</li>
<li><p>IBM<br>蓝云基础设施构建<br>商业化Hadoop发行、解决方案支持</p>
</li>
</ul>
<h5 id="Hadoop国内应用"><a href="#Hadoop国内应用" class="headerlink" title="Hadoop国内应用"></a>Hadoop国内应用</h5><ul>
<li><p>百度<br>用户搜索表征的需求数据、阿拉丁爬虫数据存储<br>数据分析和挖掘竞价排名</p>
</li>
<li><p>阿里巴巴<br>为电子商务网络平台提供底层的基础计算和存储服务<br>交易数据、信用数据</p>
</li>
<li><p>腾讯<br>用户关系数据<br>基于Hadoop、Hive构建TDW（腾讯分布式数据仓库）</p>
</li>
<li><p>华为<br>对Hadoop的HA方案，以及HBase领域有深入研究</p>
</li>
</ul>
<div class="note info modern"><ul>
<li><p>Hadoop成功的魅力–<strong>通用性</strong><br>精准区分做什么和怎么做<br>做什么属于业务问题怎么做属于技术问题。<br>用户负责业务Hadoop负责技术</p>
</li>
<li><p>Hadoop成功的魅力–<strong>简单</strong><br><strong>一个东西你用起来比较简单，可不是你的能力！</strong></p>
</li>
</ul>
</div>

<h4 id="Hadoop发行版本、架构变迁"><a href="#Hadoop发行版本、架构变迁" class="headerlink" title="Hadoop发行版本、架构变迁"></a>Hadoop发行版本、架构变迁</h4><h5 id="Hadoop发行版本"><a href="#Hadoop发行版本" class="headerlink" title="Hadoop发行版本"></a>Hadoop发行版本</h5><p><img src="/2022/11/12/HadoopBase/2022-11-12-23-32-21.png" alt="Hadoop发行版本"></p>
<ul>
<li><p>Apache开源社区版本<br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
</li>
<li><p>商业发行版本<br>Cloudera: <a target="_blank" rel="noopener" href="https://www.cloudera.com/products/open-source/apache-hadoop.html">https://www.cloudera.com/products/open-source/apache-hadoop.html</a><br>Hortonworks: <a target="_blank" rel="noopener" href="https://www.cloudera.com/products/hdp.html">https://www.cloudera.com/products/hdp.html</a></p>
</li>
</ul>
<h5 id="Hadoop架构变迁（1-0-2-0变迁）"><a href="#Hadoop架构变迁（1-0-2-0变迁）" class="headerlink" title="Hadoop架构变迁（1.0-2.0变迁）"></a>Hadoop架构变迁（1.0-2.0变迁）</h5><ul>
<li><p>Hadoop 1.0<br>HDFS（分布式文件存储）<br>MapReduce（资源管理和分布式数据处理）</p>
</li>
<li><p>Hadoop 2.0<br>HDFS（分布式文件存储）<br>MapReduce（分布式数据处理）<br><strong>YARN</strong>（集群资源管理、任务调度）</p>
</li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-12-23-38-22.png" alt="Hadoop架构变迁（1.0-2.0变迁）"></p>
<h5 id="Hadoop架构变迁（3-0新版本）"><a href="#Hadoop架构变迁（3-0新版本）" class="headerlink" title="Hadoop架构变迁（3.0新版本）"></a>Hadoop架构变迁（3.0新版本）</h5><p><img src="/2022/11/12/HadoopBase/2022-11-12-23-39-05.png" alt="Hadoop架构变迁（3.0新版本）"><br>Hadoop 3.0架构组件和Hadoop 2.0类似,<strong>3.0着重于性能优化</strong>。</p>
<ul>
<li><p>通用方面<br>精简内核、类路径隔离、shell脚本重构</p>
</li>
<li><p>Hadoop HDFS<br>EC纠删码、多NameNode支持</p>
</li>
<li><p>Hadoop MapReduce<br>任务本地化优化、内存参数自动推断</p>
</li>
<li><p>Hadoop YARN<br>Timeline Service V2、队列配置</p>
</li>
</ul>
<h3 id="Apache-Hadoop集群搭建"><a href="#Apache-Hadoop集群搭建" class="headerlink" title="Apache Hadoop集群搭建"></a>Apache Hadoop集群搭建</h3><h4 id="Hadoop集群简介"><a href="#Hadoop集群简介" class="headerlink" title="Hadoop集群简介"></a>Hadoop集群简介</h4><ul>
<li>Hadoop集群包括两个集群：HDFS集群、YARN集群</li>
<li>两个集群<strong>逻辑上分离、通常物理上在一起</strong>(可单独启动，部署于一台计算机)</li>
<li>两个集群都是标准的<strong>主从架构</strong>集群</li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-12-23-46-13.png" alt="Hadoop集群"><br><img src="/2022/11/12/HadoopBase/2022-11-12-23-48-36.png" alt="Hadoop集群"></p>
<ul>
<li><p>逻辑上分离<br>两个集群<strong>互相之间没有依赖、互不影响</strong></p>
</li>
<li><p>物理上在一起<br>某些角色进程往往<strong>部署在同一台物理服务器上</strong></p>
</li>
<li><p>MapReduce集群呢？<br>MapReduce是计算框架、代码层面的组件没有集群之说</p>
</li>
</ul>
<h4 id="Hadoop集群模式-分布式-安装（Cluster-mode）"><a href="#Hadoop集群模式-分布式-安装（Cluster-mode）" class="headerlink" title="Hadoop集群模式(分布式)安装（Cluster mode）"></a>Hadoop集群模式(分布式)安装（Cluster mode）</h4><p>详细的集群搭建步骤可参考<a href="/2022/10/25/HadoopClusterBuilding3-3-4/" title="Hadoop 3.3.4 集群搭建">Hadoop 3.3.4 集群搭建</a></p>
<h5 id="Hadoop源码编译"><a href="#Hadoop源码编译" class="headerlink" title="Hadoop源码编译"></a>Hadoop源码编译</h5><ul>
<li>安装包、源码包下载地址<br><a target="_blank" rel="noopener" href="https://archive.apache.org/dist/hadoop/common/">https://archive.apache.org/dist/hadoop/common/</a><br><img src="/2022/11/12/HadoopBase/2022-11-13-00-08-55.png" alt="Hadoop版本"></li>
<li>为什么要重新编译Hadoop源码?<br>匹配不同<strong>操作系统本地库环境</strong>，Hadoop某些操作比如压缩、IO需要调用系统本地库（*.so|*.dll）<br><strong>修改源码、重构源码</strong></li>
<li>如何编译Hadoop<br>源码包根目录下文件：BUILDING.txt<br><img src="/2022/11/12/HadoopBase/2022-11-13-00-09-25.png" alt="如何编译Hadoop"></li>
</ul>
<h5 id="Step1-集群角色规划"><a href="#Step1-集群角色规划" class="headerlink" title="Step1:集群角色规划"></a>Step1:集群角色规划</h5><ul>
<li><p>角色规划的准则<br>根据软件工作特性和服务器硬件资源情况合理分配<br>比如依赖内存工作的NameNode是不是部署在大内存机器上？</p>
</li>
<li><p>角色规划注意事项<br><strong>资源上有抢夺冲突的，尽量不要部署在一起</strong><br><strong>工作上需要互相配合的。尽量部署在一起</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>服务器</th>
<th>运行角色</th>
</tr>
</thead>
<tbody><tr>
<td>node1.itcast.cn</td>
<td>namenode datanode resourcemanager nodemanager</td>
</tr>
<tr>
<td>node2.itcast.cn</td>
<td>secondarynamenode datanode nodemanager</td>
</tr>
<tr>
<td>node3.itcast.cn</td>
<td>datanode nodemanager</td>
</tr>
</tbody></table>
<h5 id="Step2-服务器基础环境准备"><a href="#Step2-服务器基础环境准备" class="headerlink" title="Step2:服务器基础环境准备"></a>Step2:服务器基础环境准备</h5><ul>
<li><p>主机名（3台机器）<br><code>vim /etc/hostname</code></p>
</li>
<li><p>Hosts映射（3台机器）<br><code>vim /etc/hosts</code></p>
</li>
<li><p>防火墙关闭（3台机器）<br><code>systemctl stop firewalld.service</code> #关闭防火墙<br><code>systemctl disable firewalld.service</code> #禁止防火墙开启自启</p>
</li>
<li><p>ssh免密登录<br><code>ssh-keygen</code>#4个回车生成公钥、私钥<br><code>ssh-copy-id node1</code>、<code>ssh-copy-id node2</code>、<code>ssh-copy-id node3</code></p>
</li>
<li><p>集群时间同步（3台机器）<br><code>yum -y install ntpdate</code><br><code>ntpdate ntp4.aliyun.com</code></p>
</li>
<li><p>创建统一工作目录（3台机器）</p>
</li>
</ul>
<h5 id="Step3-上传安装包、解压安装包"><a href="#Step3-上传安装包、解压安装包" class="headerlink" title="Step3:上传安装包、解压安装包"></a>Step3:上传安装包、解压安装包</h5><ul>
<li>JDK 1.8安装（3台机器）</li>
<li>上传、解压Hadoop安装包</li>
</ul>
<h5 id="Step4-Hadoop安装包目录结构"><a href="#Step4-Hadoop安装包目录结构" class="headerlink" title="Step4:Hadoop安装包目录结构"></a>Step4:Hadoop安装包目录结构</h5><table>
<thead>
<tr>
<th>目录</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>bin</strong></td>
<td>Hadoop最基本的<strong>管理脚本</strong>和使用脚本的目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用Hadoop。</td>
</tr>
<tr>
<td><strong>etc</strong></td>
<td>Hadoop<strong>配置文件</strong>所在的目录</td>
</tr>
<tr>
<td>include</td>
<td>对外提供的编程库头文件（具体动态库和静态库在lib目录中），这些头文件均是用C++定义的，通常用于C++程序访问HDFS或者编写MapReduce程序。</td>
</tr>
<tr>
<td>lib</td>
<td>该目录包含了Hadoop对外提供的编程动态库和静态库，与include目录中的头文件结合使用。</td>
</tr>
<tr>
<td>libexec</td>
<td>各个服务对用的shell配置文件所在的目录，可用于配置日志输出、启动参数（比如JVM参数）等基本信息。</td>
</tr>
<tr>
<td><strong>sbin</strong></td>
<td>Hadoop管理脚本所在的目录，主要包含HDFS和YARN中各类服务的<strong>启动&#x2F;关闭脚本</strong>。</td>
</tr>
<tr>
<td><strong>share</strong></td>
<td>Hadoop各个模块编译后的<strong>jar包</strong>所在的目录，<strong>官方自带示例</strong>。</td>
</tr>
</tbody></table>
<h5 id="配置文件概述"><a href="#配置文件概述" class="headerlink" title="配置文件概述"></a>配置文件概述</h5><ul>
<li><p>官网文档<br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/">https://hadoop.apache.org/docs/</a></p>
</li>
<li><p>第一类1个: <strong>hadoop-env.sh</strong></p>
</li>
<li><p>第二类4个：xxxx-site.xml ,site表示的是用户定义的配置，会覆盖default中的默认配置。</p>
<ul>
<li><strong>core-site.xml</strong> 核心模块配置</li>
<li><strong>hdfs-site.xml</strong> hdfs文件系统模块配置</li>
<li><strong>mapred-site.xml</strong> MapReduce模块配置</li>
<li><strong>yarn-site.xml</strong> yarn模块配置</li>
</ul>
</li>
<li><p>第三类1个：<strong>workers</strong></p>
</li>
<li><p>上述的配置文件目录：$HADOOP_HOME&#x2F;etc&#x2F;hadoop</p>
</li>
</ul>
<h5 id="Step5-编辑Hadoop配置文件-hadoop-env-sh"><a href="#Step5-编辑Hadoop配置文件-hadoop-env-sh" class="headerlink" title="Step5:编辑Hadoop配置文件 hadoop-env.sh"></a>Step5:编辑Hadoop配置文件 hadoop-env.sh</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=jdk安装路径</span><br><span class="line"><span class="comment">#文件最后添加</span></span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>

<h5 id="Step5-编辑Hadoop配置文件-core-site-xml"><a href="#Step5-编辑Hadoop配置文件-core-site-xml" class="headerlink" title="Step5:编辑Hadoop配置文件 core-site.xml"></a>Step5:编辑Hadoop配置文件 core-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--设置默认使用的文件系统Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--设置Hadoop本地保存数据路径--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--设置HDFS web UI用户身份--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--整合hive 用户代理设置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--垃圾桶文件保存时间--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="Step5-编辑Hadoop配置文件hdfs-site-xml"><a href="#Step5-编辑Hadoop配置文件hdfs-site-xml" class="headerlink" title="Step5:编辑Hadoop配置文件hdfs-site.xml"></a>Step5:编辑Hadoop配置文件hdfs-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--设置SNN进程运行机器位置信息--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="Step5-编辑Hadoop配置文件-mapred-site-xml"><a href="#Step5-编辑Hadoop配置文件-mapred-site-xml" class="headerlink" title="Step5:编辑Hadoop配置文件 mapred-site.xml"></a>Step5:编辑Hadoop配置文件 mapred-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--设置MR程序默认运行模式：yarn集群模式local本地模式--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--MR程序历史服务器端地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--历史服务器web端地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="Step5-编辑Hadoop配置文件-yarn-site-xml"><a href="#Step5-编辑Hadoop配置文件-yarn-site-xml" class="headerlink" title="Step5:编辑Hadoop配置文件 yarn-site.xml"></a>Step5:编辑Hadoop配置文件 yarn-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--设置YARN集群主角色运行机器位置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--是否将对容器实施物理内存限制--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--是否将对容器实施虚拟内存限制。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--开启日志聚集--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--设置yarn历史服务器地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--保存的时间7天--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="Step5-编辑Hadoop配置文件-workers"><a href="#Step5-编辑Hadoop配置文件-workers" class="headerlink" title="Step5:编辑Hadoop配置文件 workers"></a>Step5:编辑Hadoop配置文件 workers</h5><pre><code class="highlight plaintext">node1.itcast.cn
node2.itcast.cn
node3.itcast.cn</code></pre>

<h5 id="Step6-分发同步安装包"><a href="#Step6-分发同步安装包" class="headerlink" title="Step6:分发同步安装包"></a>Step6:分发同步安装包</h5><ul>
<li>在node1机器上将Hadoop安装包scp同步到其他机器</li>
</ul>
<h5 id="Step7-配置Hadoop环境变量"><a href="#Step7-配置Hadoop环境变量" class="headerlink" title="Step7:配置Hadoop环境变量"></a>Step7:配置Hadoop环境变量</h5><ul>
<li><p>在node1上配置Hadoop环境变量<br><code>vim /etc/profile</code><br><code>export HADOOP_HOME=hadoop安装路径</code><br><code>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></p>
</li>
<li><p>将修改后的环境变量同步其他机器<br><code>scp /etc/profile root@node2:/etc/</code><br><code>scp /etc/profile root@node3:/etc/</code></p>
</li>
<li><p>重新加载环境变量验证是否生效（3台机器）<br><code>source /etc/profile</code><br><code>hadoop</code> #验证环境变量是否生效</p>
</li>
</ul>
<h5 id="Step8-NameNode-format（格式化操作）"><a href="#Step8-NameNode-format（格式化操作）" class="headerlink" title="Step8:NameNode format（格式化操作）"></a>Step8:NameNode format（格式化操作）</h5><ul>
<li>首次启动HDFS时，必须对其进行格式化操作</li>
<li>format本质上是<strong>初始化工作，进行HDFS清理和准备工作</strong></li>
<li>命令：<br><code>hdfs namenode -format</code></li>
</ul>
<div class="note info modern"><ol>
<li>首次启动之前需要format操作;</li>
<li>format只能进行一次后续不再需要;</li>
<li>如果多次format除了造成数据丢失外，还会导致hdfs集群主从角色之间互不识别。通过删除所有机器hadoop.tmp.dir目录重新format解决</li>
</ol>
</div>

<h4 id="Hadoop集群启停命令、Web-UI"><a href="#Hadoop集群启停命令、Web-UI" class="headerlink" title="Hadoop集群启停命令、Web UI"></a>Hadoop集群启停命令、Web UI</h4><h5 id="手动逐个进程启停"><a href="#手动逐个进程启停" class="headerlink" title="手动逐个进程启停"></a>手动逐个进程启停</h5><p>每台机器上每次手动启动关闭一个角色进程,可以精准控制每个进程启停，避免群起群停。</p>
<ul>
<li><p>HDFS集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">hadoop2.x版本命令</span></span><br><span class="line">hadoop-daemon.sh start|stop namenode|datanode|secondarynamenode</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">hadoop3.x版本命令</span></span><br><span class="line">hdfs --daemon start|stop namenode|datanode|secondarynamenode</span><br></pre></td></tr></table></figure>
</li>
<li><p>YARN集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">hadoop2.x版本命令</span></span><br><span class="line">yarn-daemon.sh start|stop resourcemanager|nodemanager</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">hadoop3.x版本命令</span></span><br><span class="line">yarn --daemon start|stop resourcemanager|nodemanager</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="shell脚本一键启停"><a href="#shell脚本一键启停" class="headerlink" title="shell脚本一键启停"></a>shell脚本一键启停</h5><p>在node1上，使用软件自带的shell脚本一键启动。前提：<strong>配置好机器之间的SSH免密登录和workers文件</strong>。</p>
<ul>
<li><p>HDFS集群<br><code>start-dfs.sh</code><br><code>stop-dfs.sh</code></p>
</li>
<li><p>YARN集群<br><code>start-yarn.sh</code><br><code>stop-yarn.sh</code></p>
</li>
<li><p>Hadoop集群<br><code>start-all.sh</code><br><code>stop-all.sh</code></p>
</li>
</ul>
<h5 id="进程状态、日志查看"><a href="#进程状态、日志查看" class="headerlink" title="进程状态、日志查看"></a>进程状态、日志查看</h5><ul>
<li>启动完毕之后可以使用<strong>jps命令</strong>查看进程是否启动成功</li>
<li>Hadoop启动日志路径：$HADOOP_HOME&#x2F;logs&#x2F;</li>
</ul>
<h5 id="HDFS集群web界面"><a href="#HDFS集群web界面" class="headerlink" title="HDFS集群web界面"></a>HDFS集群web界面</h5><p>地址：<a target="_blank" rel="noopener" href="http://namenode_host:9870/">http://namenode_host:9870</a></p>
<p>其中namenode_host是namenode运行所在机器的主机名或者ip<br>如果使用主机名访问，别忘了在Windows配置hosts<br><img src="/2022/11/12/HadoopBase/2022-11-13-17-27-37.png" alt="HDFS集群web界面"><br><img src="/2022/11/12/HadoopBase/2022-11-13-17-27-57.png" alt="HDFS集群web界面"></p>
<h5 id="YARN集群web界面"><a href="#YARN集群web界面" class="headerlink" title="YARN集群web界面"></a>YARN集群web界面</h5><p>地址：<a target="_blank" rel="noopener" href="http://resourcemanager_host:8088/">http://resourcemanager_host:8088</a></p>
<p>其中resourcemanager_host是resourcemanager运行所在机器的主机名或者ip<br>如果使用主机名访问，别忘了在Windows配置hosts<br><img src="/2022/11/12/HadoopBase/2022-11-13-17-28-12.png" alt="YARN集群web界面"></p>
<h4 id="Hadoop初体验"><a href="#Hadoop初体验" class="headerlink" title="Hadoop初体验"></a>Hadoop初体验</h4><h5 id="HDFS-初体验"><a href="#HDFS-初体验" class="headerlink" title="HDFS 初体验"></a>HDFS 初体验</h5><h6 id="shell命令操作"><a href="#shell命令操作" class="headerlink" title="shell命令操作"></a>shell命令操作</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoopfs-mkdir /itcast</span><br><span class="line">hadoopfs-put zookeeper.out/itcast</span><br><span class="line">hadoopfs-ls/</span><br></pre></td></tr></table></figure>

<h6 id="Web-UI页面操作"><a href="#Web-UI页面操作" class="headerlink" title="Web UI页面操作"></a>Web UI页面操作</h6><p><img src="/2022/11/12/HadoopBase/2022-11-13-17-34-40.png" alt="Web UI页面操作"></p>
<h5 id="MapReduce-YARN初体验"><a href="#MapReduce-YARN初体验" class="headerlink" title="MapReduce+YARN初体验"></a>MapReduce+YARN初体验</h5><p>执行Hadoop官方自带的MapReduce案例，评估圆周率π的值。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/share/hadoop/mapreduce/</span><br><span class="line">hadoop jar hadoop-mapreduce-examples-3.3.0.jar pi 2 4</span><br></pre></td></tr></table></figure>

<p><img src="/2022/11/12/HadoopBase/2022-11-13-17-42-07.png" alt="MapReduce+YARN初体验"></p>
<h3 id="HDFS分布式文件系统基础"><a href="#HDFS分布式文件系统基础" class="headerlink" title="HDFS分布式文件系统基础"></a>HDFS分布式文件系统基础</h3><h4 id="文件系统、分布式文件系统"><a href="#文件系统、分布式文件系统" class="headerlink" title="文件系统、分布式文件系统"></a>文件系统、分布式文件系统</h4><h5 id="文件系统定义"><a href="#文件系统定义" class="headerlink" title="文件系统定义"></a>文件系统定义</h5><ul>
<li>文件系统是一种<strong>存储</strong>和<strong>组织数据</strong>的方法，实现了数据的存储、分级组织、访问和获取等操作，使得用户对文件访问和查找变得容易；</li>
<li>文件系统使用<strong>树形目录</strong>的<strong>抽象逻辑</strong>概念代替了硬盘等物理设备使用数据块的概念，用户不必关心数据底层存在硬盘哪里，只需要记住这个文件的所属目录和文件名即可；</li>
<li>文件系统通常使用硬盘和光盘这样的存储设备，并<strong>维护文件在设备中的物理位置</strong>。<br><img src="/2022/11/12/HadoopBase/2022-11-13-17-56-16.png" alt="文件系统"></li>
</ul>
<h5 id="传统常见的文件系统"><a href="#传统常见的文件系统" class="headerlink" title="传统常见的文件系统"></a>传统常见的文件系统</h5><ul>
<li>所谓传统常见的文件系统更多指的的<strong>单机的文件系统</strong>，也就是<strong>底层不会横跨多台机器</strong>实现。比如windows操作系统上的文件系统、Linux上的文件系统、FTP文件系统等等。</li>
<li>这些文件系统的共同特征包括：<ol>
<li>带有<strong>抽象的目录树结构</strong>，树都是从<strong>/根目录开始</strong>往下蔓延；</li>
<li>树中节点分为两类：<strong>目录</strong>和<strong>文件</strong>；</li>
<li>从根目录开始，节点<strong>路径具有唯一性</strong>。</li>
</ol>
</li>
</ul>
<h5 id="数据、元数据"><a href="#数据、元数据" class="headerlink" title="数据、元数据"></a>数据、元数据</h5><h6 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h6><p>指存储的内容本身，比如文件、视频、图片等，这些<strong>数据底层最终是存储在磁盘</strong>等存储介质上的，一般<strong>用户无需关心</strong>，只需要基于目录树进行增删改查即可，实际针对数据的操作由文件系统完成。</p>
<h6 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h6><p>元数据（metadata）又称之为解释性数据，记录数据的数据；<br>文件系统元数据一般指<strong>文件大小、最后修改时间、底层存储位置、属性、所属用户、权限等信息</strong>。</p>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-18-00-22.png" alt="元数据"></p>
<h5 id="海量数据存储遇到的问题"><a href="#海量数据存储遇到的问题" class="headerlink" title="海量数据存储遇到的问题"></a>海量数据存储遇到的问题</h5><ul>
<li><p><strong>成本高</strong><br>传统存储硬件通用性差，设备投资加上后期维护、<strong>升级扩容的成本非常高</strong>。<br><img src="/2022/11/12/HadoopBase/2022-11-13-18-12-07.png" alt="成本高"></p>
</li>
<li><p>如何支撑高效率的计算分析<br>传统存储方式意味着数据：存储是存储，计算是计算，当<strong>需要处理数据的时候把数据移动过来</strong>。<br>程序和数据存储是属于不同的技术厂商实现，无法有机统一整合在一起。</p>
</li>
<li><p><strong>性能低</strong><br><strong>单节点I&#x2F;O性能瓶</strong>颈无法逾越，难以支撑海量数据的<strong>高并发高吞吐</strong>场景。</p>
</li>
<li><p><strong>可扩展性差</strong><br>无法实现快速部署和弹性扩展，动态扩容、缩容成本高，技术实现难度大。</p>
</li>
</ul>
<h4 id="分布式存储系统的核心属性及功能含义"><a href="#分布式存储系统的核心属性及功能含义" class="headerlink" title="分布式存储系统的核心属性及功能含义"></a>分布式存储系统的核心属性及功能含义</h4><p>分布式存储系统核心属性</p>
<ul>
<li>分布式存储</li>
<li>元数据记录</li>
<li>分块存储</li>
<li>副本机制</li>
</ul>
<h5 id="分布式存储的优点"><a href="#分布式存储的优点" class="headerlink" title="分布式存储的优点"></a>分布式存储的优点</h5><ul>
<li>问题：数据量大，单机存储遇到瓶颈</li>
<li>解决：<br>单机纵向扩展：磁盘不够加磁盘，有上限瓶颈限制<br><strong>多机横向扩展</strong>：机器不够加机器，理论上<strong>无限扩展</strong></li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-18-16-54.png" alt="分布式存储"></p>
<h5 id="元数据记录的功能"><a href="#元数据记录的功能" class="headerlink" title="元数据记录的功能"></a>元数据记录的功能</h5><ul>
<li>问题：文件分布在不同机器上不利于寻找</li>
<li>解决：元数据记录下文件及其存储位置信息，<strong>快速定位文件位置</strong></li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-18-18-30.png" alt="元数据记录的功能"></p>
<h5 id="分块存储好处"><a href="#分块存储好处" class="headerlink" title="分块存储好处"></a>分块存储好处</h5><ul>
<li>问题：文件过大导致单机存不下、上传下载效率低</li>
<li>解决：文件分块存储在不同机器，<strong>针对块并行操作提高效率</strong></li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-18-20-30.png" alt="分块存储好处"></p>
<h5 id="副本机制的作用"><a href="#副本机制的作用" class="headerlink" title="副本机制的作用"></a>副本机制的作用</h5><ul>
<li>问题：硬件故障难以避免，数据易丢失</li>
<li>解决：不同机器设置备份，<strong>冗余存储，保障数据安全</strong></li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-18-22-03.png" alt="副本机制的作用"></p>
<div class="note info modern"><ol>
<li><div class="hide-block"><button type="button" class="hide-button" style>分布式存储的优点是什么？
 </button><div class="hide-content"><p><strong>无限扩展</strong>支撑海量数据存储</p>
</div></div>
</li>
<li><div class="hide-block"><button type="button" class="hide-button" style>元数据记录的功能是什么？
 </button><div class="hide-content"><p>快速<strong>定位文件</strong>位置便于查找</p>
</div></div>
</li>
<li><div class="hide-block"><button type="button" class="hide-button" style>文件分块存储好处是什么？
 </button><div class="hide-content"><p>针对块<strong>并行操作</strong>提高效率</p>
</div></div>
</li>
<li><div class="hide-block"><button type="button" class="hide-button" style>设置副本备份的作用是什么？
 </button><div class="hide-content"><p>冗余存储保障<strong>数据安全</strong></p>
</div></div></li>
</ol>
</div>

<h4 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h4><ul>
<li><p>HDFS（Hadoop Distributed File System ），意为：<strong>Hadoop分布式文件系统</strong>。</p>
</li>
<li><p>是Apache Hadoop核心组件之一，作为<strong>大数据生态圈最底层</strong>的分布式存储服务而存在。也可以说大数据首先要解决的问题就是海量数据的存储问题。<br><img src="/2022/11/12/HadoopBase/2022-11-12-22-38-08.png" alt="广义Hadoop"></p>
</li>
<li><p>HDFS主要是<strong>解决大数据如何存储问题的</strong>。分布式意味着是HDFS是横跨在多台计算机上的存储系统。</p>
</li>
<li><p>HDFS是一种能够在普通硬件上运行的分布式文件系统，它是<strong>高度容错</strong>的，适应于具有大数据集的应用程序，它非常适于存储大型数据(比如TB 和PB)。</p>
</li>
<li><p>HDFS使用多台计算机存储文件, 并且提供<strong>统一的访问接口</strong>, 像是访问一个普通文件系统一样使用分布式文件系统。</p>
</li>
<li><p><img src="/2022/11/12/HadoopBase/2022-11-13-18-38-51.png" alt="HDFS简介"></p>
</li>
</ul>
<h4 id="HDFS起源发展、设计目标"><a href="#HDFS起源发展、设计目标" class="headerlink" title="HDFS起源发展、设计目标"></a>HDFS起源发展、设计目标</h4><h5 id="HDFS起源发展"><a href="#HDFS起源发展" class="headerlink" title="HDFS起源发展"></a>HDFS起源发展</h5><ul>
<li><p><strong>Doug Cutting</strong> 领导<strong>Nutch项目</strong>研发，Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能。</p>
</li>
<li><p>随着爬虫抓取网页数量的增加，遇到了严重的可扩展性问题——<strong>如何解决数十亿网页的存储和索引问题</strong>。</p>
</li>
<li><p>2003年的时候, Google发表的论文为该问题提供了可行的解决方案。<br>《<strong>分布式文件系统（GFS）</strong>，可用于处理海量网页的存储》<br><img src="/2022/11/12/HadoopBase/2022-11-13-19-16-18.png" alt="GFS"></p>
</li>
<li><p>Nutch的开发人员完成了相应的开源实现HDFS，并从Nutch中剥离和MapReduce成为独立项目HADOOP。</p>
</li>
</ul>
<h5 id="HDFS设计目标"><a href="#HDFS设计目标" class="headerlink" title="HDFS设计目标"></a>HDFS设计目标</h5><ul>
<li>硬件故障（Hardware Failure）是常态，HDFS可能有成百上千的服务器组成，每一个组件都有可能出现故障。因此<strong>故障检测和自动快速恢复</strong>是HDFS的核心架构目标。</li>
<li>HDFS上的应用主要是以流式读取数据（Streaming Data Access）。HDFS被设计成用于批处理，而不是用户交互式的。相较于数据访问的反应时间，更<strong>注重数据访问的高吞吐量</strong>。</li>
<li>典型的HDFS文件大小是GB到TB的级别。所以，HDFS被调整成<strong>支持大文件（Large Data Sets）</strong>。它应该提供很高的聚合数据带宽，一个集群中支持数百个节点，一个集群中还应该支持千万级别的文件。</li>
<li>大部分HDFS应用对文件要求的是<strong>write-one-read-many</strong>访问模型。一个文件一旦<strong>创建、写入、关闭之后就不需要修改</strong>了。这一假设简化了数据一致性问题，使高吞吐量的数据访问成为可能。</li>
<li><strong>移动计算的代价比之移动数据的代价低</strong>。一个应用请求的计算，离它操作的数据越近就越高效。将计算移动到数据附近，比之将数据移动到应用所在显然更好。</li>
<li>HDFS被设计为可从一个平台<strong>轻松移植</strong>到另一个平台。这有助于将HDFS广泛用作大量应用程序的首选平台。</li>
</ul>
<h4 id="HDFS应用场景"><a href="#HDFS应用场景" class="headerlink" title="HDFS应用场景"></a>HDFS应用场景</h4><p><img src="/2022/11/12/HadoopBase/2022-11-13-20-17-58.png" alt="HDFS应用场景"></p>
<h4 id="HDFS重要特性"><a href="#HDFS重要特性" class="headerlink" title="HDFS重要特性"></a>HDFS重要特性</h4><blockquote class="pullquote right"><p><img src="/2022/11/12/HadoopBase/2022-11-13-20-19-47.png" alt="HDFS"></p>
</blockquote>

<h5 id="整体概述"><a href="#整体概述" class="headerlink" title="整体概述"></a>整体概述</h5><ul>
<li>主从架构</li>
<li>分块存储</li>
<li>副本机制</li>
<li>元数据记录</li>
<li>抽象统一的目录树结构（namespace）</li>
</ul>
<h5 id="（1）主从架构"><a href="#（1）主从架构" class="headerlink" title="（1）主从架构"></a>（1）主从架构</h5><ul>
<li>HDFS集群是标准的master&#x2F;slave主从架构集群。</li>
<li>一般一个HDFS集群是有一个Namenode和一定数目的Datanode组成。</li>
<li><strong>Namenode是HDFS主节点，Datanode是HDFS从节点，两种角色各司其职，共同协调</strong>完成分布式的文件存储服务。</li>
<li>官方架构图中是<strong>一主五从</strong>模式，其中五个从角色位于两个机架（Rack）的不同服务器上。</li>
</ul>
<h5 id="（2）分块存储"><a href="#（2）分块存储" class="headerlink" title="（2）分块存储"></a>（2）分块存储</h5><ul>
<li>HDFS中的文件在<strong>物理上是分块存储（block）</strong>的，默认大小是128M（134217728），不足128M则本身就是一块。</li>
<li>块的大小可以通过配置参数来规定，参数位于hdfs-default.xml中：dfs.blocksize。</li>
</ul>
<p><img src="/2022/11/12/HadoopBase/2022-11-13-20-30-29.png" alt="分块存储"></p>
<h5 id="（3）副本机制"><a href="#（3）副本机制" class="headerlink" title="（3）副本机制"></a>（3）副本机制</h5><ul>
<li>文件的所有block都会有副本。副本系数可以在文件创建的时候指定，也可以在之后通过命令改变。</li>
<li>副本数由参数dfs.replication控制，<strong>默认值是3</strong>，也就是会<strong>额外再复制2份</strong>，连同本身总共3份副本。</li>
</ul>
<h5 id="（4）元数据管理"><a href="#（4）元数据管理" class="headerlink" title="（4）元数据管理"></a>（4）元数据管理</h5><p>在HDFS中，Namenode管理的元数据具有两种类型：</p>
<ul>
<li><p><strong>文件自身属性信息</strong><br>文件名称、权限，修改时间，文件大小，复制因子，数据块大小。</p>
</li>
<li><p><strong>文件块位置映射信息</strong><br>记录文件块和DataNode之间的映射信息，即哪个块位于哪个节点上。</p>
</li>
</ul>
<h5 id="（5）namespace"><a href="#（5）namespace" class="headerlink" title="（5）namespace"></a>（5）namespace</h5><ul>
<li>HDFS支持传统的<strong>层次型文件组织结构</strong>。用户可以创建目录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数现有的文件系统类似：用户可以创建、删除、移动或重命名文件。</li>
<li>Namenode负责维护文件系统的namespace名称空间，任何对文件系统名称空间或属性的修改都将被Namenode记录下来。</li>
<li>HDFS会给客户端提供一个<strong>统一的抽象目录树</strong>，客户端通过路径来访问文件，形如：hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir-a&#x2F;dir-b&#x2F;dir-c&#x2F;file.data。</li>
</ul>
<h5 id="（6）数据块存储"><a href="#（6）数据块存储" class="headerlink" title="（6）数据块存储"></a>（6）数据块存储</h5><ul>
<li>文件的各个block的<strong>具体存储管理由DataNode节点承担</strong>。</li>
<li>每一个block都可以在多个DataNode上存储。</li>
</ul>
<h3 id="HDFS-shell操作"><a href="#HDFS-shell操作" class="headerlink" title="HDFS shell操作"></a>HDFS shell操作</h3><h4 id="HDFS-shell命令行解释说明"><a href="#HDFS-shell命令行解释说明" class="headerlink" title="HDFS shell命令行解释说明"></a>HDFS shell命令行解释说明</h4><p><strong>命令行界面</strong>（英语：command-line interface，缩写：CLI），是指用户通过键盘输入指令，计算机接收到指令后，予以执行一种人际交互方式。</p>
<p>Hadoop提供了文件系统的shell命令行客户端: <code>hadoop fs [generic options]</code></p>
<h5 id="文件系统协议"><a href="#文件系统协议" class="headerlink" title="文件系统协议"></a>文件系统协议</h5><ul>
<li>HDFS Shell CLI支持操作多种文件系统，包括本地文件系统（file:&#x2F;&#x2F;&#x2F;）、分布式文件系统（hdfs:&#x2F;&#x2F;nn:8020）等</li>
<li>具体操作的是什么文件系统取决于命令中文件路径<strong>URL中的前缀协议</strong>。</li>
<li>如果没有指定前缀，则将会读取环境变量中的<code>fs.defaultFS</code>属性，以该属性值作为默认文件系统。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls file:/// #操作本地文件系统</span><br><span class="line">hadoop fs -ls hdfs://node1:8020/ #操作HDFS分布式文件系统</span><br><span class="line">hadoop fs -ls / #直接根目录，没有指定协议将加载读取fs.defaultFS值</span><br></pre></td></tr></table></figure>

<h5 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h5><ul>
<li>hadoop dfs 只能操作HDFS文件系统（包括与Local FS间的操作），不过已经Deprecated；</li>
<li>hdfs dfs 只能操作HDFS文件系统相关（包括与Local FS间的操作）,常用；</li>
<li><code>hadoop fs</code> 可操作任意文件系统，不仅仅是hdfs文件系统，使用范围更广；</li>
</ul>
<p>目前版本来看，官方最终推荐使用的是hadoop fs。当然hdfs dfs在市面上的使用也比较多。</p>
<h5 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h5><ul>
<li>HDFS文件系统的操作命令很多和Linux类似，因此学习成本相对较低。</li>
<li>可以通过<code>hadoop fs -help</code>命令来查看每个命令的详细用法。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">[-appendToFile&lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">……</span><br><span class="line">-appendToFile&lt;localsrc&gt; ... &lt;dst&gt; :</span><br><span class="line">Appends the contents of all the given local files to the given dst file. The dst</span><br><span class="line">file will be created if it does not exist. If &lt;localSrc&gt; is -, then the input is</span><br><span class="line">read from stdin.</span><br><span class="line">-cat [-ignoreCrc] &lt;src&gt; ... :</span><br><span class="line">Fetch all files that match the file pattern &lt;src&gt; and display their content on</span><br><span class="line">stdout.</span><br></pre></td></tr></table></figure>

<h4 id="HDFS-shell命令行常用操作"><a href="#HDFS-shell命令行常用操作" class="headerlink" title="HDFS shell命令行常用操作"></a>HDFS shell命令行常用操作</h4><h5 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir [-p] &lt;path&gt; ...</span><br></pre></td></tr></table></figure>

<ul>
<li><code>path</code> 为待创建的目</li>
<li><code>-p</code>选项的行为与Unix mkdir -p非常相似，它<strong>会创建路径中的各级父目录</strong>。</li>
</ul>
<h5 id="查看指定目录下内容"><a href="#查看指定目录下内容" class="headerlink" title="查看指定目录下内容"></a>查看指定目录下内容</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls [-h] [-R] [&lt;path&gt; ...]</span><br></pre></td></tr></table></figure>

<ul>
<li><code>path</code> 指定目录路径</li>
<li><code>-h</code> 人性化显示文件size</li>
<li><code>-R</code> 递归查看指定目录及其子目录</li>
</ul>
<h5 id="上传文件到HDFS指定目录下"><a href="#上传文件到HDFS指定目录下" class="headerlink" title="上传文件到HDFS指定目录下"></a>上传文件到HDFS指定目录下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-f</code> 覆盖目标文件（已存在下）</li>
<li><code>-p</code> 保留访问和修改时间，所有权和权限。</li>
<li><code>localsrc</code> 本地文件系统（客户端所在机器）</li>
<li><code>dst</code> 目标文件系统（HDFS）</li>
</ul>
<h5 id="查看HDFS文件内容"><a href="#查看HDFS文件内容" class="headerlink" title="查看HDFS文件内容"></a>查看HDFS文件内容</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat &lt;src&gt; ...</span><br></pre></td></tr></table></figure>

<p>读取指定文件全部内容，显示在标准输出控制台。<br>注意：对于<strong>大文件内容读取，慎重</strong>。</p>
<h5 id="下载HDFS文件"><a href="#下载HDFS文件" class="headerlink" title="下载HDFS文件"></a>下载HDFS文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get [-f] [-p] &lt;src&gt; ... &lt;localdst&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>下载文件到本地文件系统指定目录，localdst必须是目录</li>
<li><code>-f</code> 覆盖目标文件（已存在下）</li>
<li><code>-p</code> 保留访问和修改时间，所有权和权限。</li>
</ul>
<h5 id="拷贝HDFS文件"><a href="#拷贝HDFS文件" class="headerlink" title="拷贝HDFS文件"></a>拷贝HDFS文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp [-f] &lt;src&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-f</code> 覆盖目标文件（已存在下）</li>
</ul>
<h5 id="追加数据到HDFS文件中"><a href="#追加数据到HDFS文件中" class="headerlink" title="追加数据到HDFS文件中"></a>追加数据到HDFS文件中</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -appendToFile&lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>

<p>将所有给定本地文件的内容追加到给定dst文件。<br>dst如果文件不存在，将创建该文件。<br>注意：<strong>appendToFile 是将当地文件内容追加的到 hadoop 上的文件（不能hadoop上的文件1 追加给 hadoop上的文件2）</strong></p>
<h5 id="HDFS数据移动操作"><a href="#HDFS数据移动操作" class="headerlink" title="HDFS数据移动操作"></a>HDFS数据移动操作</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv &lt;src&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>

<p>移动文件到指定文件夹下<br>可以使用该命令移动数据，重命名文件的名称</p>
<h5 id="HDFS-shell其他命令"><a href="#HDFS-shell其他命令" class="headerlink" title="HDFS shell其他命令"></a>HDFS shell其他命令</h5><p>命令官方指导文档<br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/">https://hadoop.apache.org/docs/</a><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.3.4/hadoop-project-dist/hadoop-common/FileSystemShell.html">https://hadoop.apache.org/docs/r3.3.4/hadoop-project-dist/hadoop-common/FileSystemShell.html</a></p>
<p>常见的操作自己最好能够记住，其他操作可以根据需要查询文档使用。<br>命令属于<strong>多用多会，孰能生巧，不用就忘</strong>。</p>
<h3 id="HDFS工作流程与机制"><a href="#HDFS工作流程与机制" class="headerlink" title="HDFS工作流程与机制"></a>HDFS工作流程与机制</h3><h4 id="HDFS集群角色与职责"><a href="#HDFS集群角色与职责" class="headerlink" title="HDFS集群角色与职责"></a>HDFS集群角色与职责</h4><h5 id="官方架构图"><a href="#官方架构图" class="headerlink" title="官方架构图"></a>官方架构图</h5><p><img src="/2022/11/12/HadoopBase/2022-11-13-20-19-47.png" alt="HDFS"></p>
<h5 id="主角色：namenode"><a href="#主角色：namenode" class="headerlink" title="主角色：namenode"></a>主角色：namenode</h5><p><img src="/2022/11/12/HadoopBase/2022-11-17-00-10-53.png" alt="namenode"></p>
<ul>
<li><code>NameNode</code>是Hadoop分布式文件系统的核心，架构中的主角色。</li>
<li><strong>NameNode维护和管理文件系统元数据</strong>，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。</li>
<li>基于此，<strong>NameNode成为了访问HDFS的唯一入口</strong>。</li>
<li>NameNode内部通过<strong>内存</strong>和<strong>磁盘文件</strong>两种方式管理元数据。</li>
<li>其中磁盘上的元数据文件包括Fsimage内存元数据镜像文件和edits log（Journal）编辑日志。</li>
</ul>
<h5 id="从角色：datanode"><a href="#从角色：datanode" class="headerlink" title="从角色：datanode"></a>从角色：datanode</h5><blockquote class="pullquote right"><p><img src="/2022/11/12/HadoopBase/2022-11-17-00-16-51.png" alt="datanode"></p>
</blockquote>

<ul>
<li><code>DataNode</code>是Hadoop HDFS中的从角色，负责<strong>具体的数据块存储</strong>。</li>
<li>DataNode的数量决定了HDFS集群的整体数据存储能力。通过和NameNode配合维护着数据块。</li>
</ul>
<h5 id="主角色辅助角色：secondarynamenode"><a href="#主角色辅助角色：secondarynamenode" class="headerlink" title="主角色辅助角色：secondarynamenode"></a>主角色辅助角色：secondarynamenode</h5><ul>
<li>Secondary NameNode充当NameNode的辅助节点，但不能替代NameNode。</li>
<li>主要是帮助主角色进行元数据文件的合并动作。可以通俗的理解为主角色的“秘书”。</li>
<li><img src="/2022/11/12/HadoopBase/2022-11-17-00-18-47.png" alt="secondarynamenode"></li>
</ul>
<h5 id="namenode职责"><a href="#namenode职责" class="headerlink" title="namenode职责"></a>namenode职责</h5><ul>
<li>NameNode仅<strong>存储HDFS的元数据</strong>：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</li>
<li>NameNode知道HDFS中任何<strong>给定文件的块列表及其位置</strong>。使用此信息NameNode知道如何从块中构建文件。</li>
<li>NameNode<strong>不持久化存储每个文件中各个块所在的datanode的位置信息</strong>，这些信息会在系统启动时从DataNode重建。</li>
<li>NameNode是Hadoop集群中的<strong>单点故障</strong>。</li>
<li>NameNode所在机器通常会配置有<strong>大量内存（RAM）</strong>。</li>
</ul>
<h5 id="datanode职责"><a href="#datanode职责" class="headerlink" title="datanode职责"></a>datanode职责</h5><ul>
<li>DataNode负责<strong>最终数据块block的存储</strong>。是集群的<strong>从角色</strong>，也称为Slave。</li>
<li>DataNode启动时，会将自己<strong>注册</strong>到NameNode并<strong>汇报</strong>自己负责持有的块列表。</li>
<li>当某个DataNode关闭时，不会影响数据的可用性。NameNode将安排由其他DataNode管理的块进行副本复制。</li>
<li>DataNode所在机器通常配置有大量的<strong>硬盘</strong>空间，因为实际数据存储在DataNode中。</li>
</ul>
<h4 id="HDFS写数据流程（上传文件）"><a href="#HDFS写数据流程（上传文件）" class="headerlink" title="HDFS写数据流程（上传文件）"></a>HDFS写数据流程（上传文件）</h4><h5 id="写数据完整流程图"><a href="#写数据完整流程图" class="headerlink" title="写数据完整流程图"></a>写数据完整流程图</h5><p><img src="/2022/11/12/HadoopBase/2022-11-17-00-25-38.png" alt="写数据完整流程图"></p>
<h5 id="核心概念–Pipeline管道"><a href="#核心概念–Pipeline管道" class="headerlink" title="核心概念–Pipeline管道"></a>核心概念–Pipeline管道</h5><ul>
<li><code>Pipeline</code>，中文翻译为管道。这是HDFS在上传文件写数据过程中采用的一种数据传输方式。</li>
<li>客户端将数据块写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，后者保存后将其复制到第三个数据节点。</li>
<li>为什么datanode之间采用pipeline线性传输，而不是一次给三个datanode拓扑式传输呢？</li>
<li>因为数据以管道的方式，<strong>顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时的连接，最小化推送所有数据的延时</strong>。</li>
<li>在线性推送模式下，每台机器所有的出口宽带都用于以最快的速度传输数据，而不是在多个接受者之间分配宽带。</li>
</ul>
<h5 id="核心概念–ACK应答响应"><a href="#核心概念–ACK应答响应" class="headerlink" title="核心概念–ACK应答响应"></a>核心概念–ACK应答响应</h5><p><img src="/2022/11/12/HadoopBase/2022-11-17-00-31-42.png" alt="核心概念"></p>
<ul>
<li>ACK (Acknowledge character）即是确认字符，在数据通信中，接收方发给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。</li>
<li>在HDFS pipeline管道传输数据的过程中，传输的反方向会进行ACK校验，确保数据传输安全。</li>
</ul>
<h5 id="核心概念–默认3副本存储策略"><a href="#核心概念–默认3副本存储策略" class="headerlink" title="核心概念–默认3副本存储策略"></a>核心概念–默认3副本存储策略</h5><ul>
<li>默认副本存储策略是由BlockPlacementPolicyDefault指定。</li>
<li><img src="/2022/11/12/HadoopBase/2022-11-17-00-34-22.png" alt="默认3副本存储策略"></li>
<li>第一块副本：优先客户端本地，否则随机</li>
<li>第二块副本：不同于第一块副本的不同机架。</li>
<li>第三块副本：第二块副本相同机架不同机器。</li>
<li><img src="/2022/11/12/HadoopBase/2022-11-17-00-35-49.png" alt="默认3副本存储策略"></li>
</ul>
<h5 id="写数据完整流程图文字描述"><a href="#写数据完整流程图文字描述" class="headerlink" title="写数据完整流程图文字描述"></a>写数据完整流程图文字描述</h5><ol>
<li>HDFS客户端创建对象实例<code>DistributedFileSystem</code>，该对象中封装了与HDFS文件系统操作的相关方法。</li>
<li>调用DistributedFileSystem对象的create()方法，通过<code>RPC</code>(远程过程调用)请求NameNode创建文件。<br>NameNode执行各种检查判断：目标文件是否存在、父目录是否存在、客户端是否具有创建该文件的权限。检查通过，NameNode就会为本次请求记下一条记录，返回<code>FSDataOutputStream输出流</code>对象给客户端用于写数据。</li>
<li>客户端通过FSDataOutputStream输出流开始写入数据。</li>
<li>客户端写入数据时，将数据分成一个个数据包（<strong>packet 默认64k</strong>）,内部组件<code>DataStreamer</code>请求NameNode挑选出适合存储数据副本的一组DataNode地址，默认是3副本存储。<br>DataStreamer将数据包流式传输到<code>pipeline</code>的第一个DataNode,该DataNode存储数据包并将它发送到pipeline的第二个DataNode。同样，第二个DataNode存储数据包并且发送给第三个（也是最后一个）DataNode。</li>
<li>传输的反方向上，会通过<code>ACK机制</code>校验数据包传输是否成功；</li>
<li>客户端完成数据写入后，在FSDataOutputStream输出流上调用close()方法关闭。</li>
<li>DistributedFileSystem联系NameNode告知其文件写入完成，等待NameNode确认。<br>因为namenode已经知道文件由哪些块组成（DataStream请求分配数据块），因此仅需等待最小复制块即可成功返回。<br>最小复制是由参数dfs.namenode.replication.min指定，默认是1.</li>
</ol>
<h4 id="HDFS读数据流程（下载文件）"><a href="#HDFS读数据流程（下载文件）" class="headerlink" title="HDFS读数据流程（下载文件）"></a>HDFS读数据流程（下载文件）</h4><h5 id="读数据完整流程图"><a href="#读数据完整流程图" class="headerlink" title="读数据完整流程图"></a>读数据完整流程图</h5><p><img src="/2022/11/12/HadoopBase/2022-11-17-00-46-15.png" alt="读数据完整流程图"></p>
<ol>
<li>HDFS客户端创建对象实例<code>DistributedFileSystem</code>，调用该对象的open()方法来打开希望读取的文件。</li>
<li>DistributedFileSystem使用RPC调用namenode来确定<strong>文件中前几个块的块位置（分批次读取）信息</strong>。<br>对于每个块，namenode返回具有该块所有副本的datanode位置地址列表，并且该地址列表是排序好的，与客户端的网络拓扑距离近的排序靠前。</li>
<li>DistributedFileSystem将FSDataInputStream输入流返回到客户端以供其读取数据。</li>
<li>客户端在FSDataInputStream输入流上调用read()方法。然后，已存储DataNode地址的InputStream连接到文件中第一个块的最近的DataNode。数据从DataNode流回客户端，结果客户端可以在流上重复调用read（）。</li>
<li>当该块结束时，FSDataInputStream将关闭与DataNode的连接，然后寻找下一个block块的最佳datanode位置。这些操作对用户来说是透明的。所以用户感觉起来它一直在读取一个连续的流。<br>客户端从流中读取数据时，也会根据需要询问NameNode来<strong>检索下一批数据块的DataNode位置信息</strong>。</li>
<li>一旦客户端完成读取，就对FSDataInputStream调用close()方法。</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://cmwlvip.github.io">Shiqing Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://cmwlvip.github.io/2022/11/12/HadoopBase/">https://cmwlvip.github.io/2022/11/12/HadoopBase/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://cmwlvip.github.io" target="_blank">Ofra Serendipity</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/11/07/TypeScript/"><img class="next-cover" src="/2022/11/07/TypeScript/TypeScript.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">TypeScript</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/10/25/HadoopClusterBuilding3-3-4/" title="Hadoop 3.3.4 集群搭建"><img class="cover" src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-25</div><div class="title">Hadoop 3.3.4 集群搭建</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar001.gif" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Shiqing Huang</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cmwlvip"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cmwlvip" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Apache-Hadoop%E3%80%81HDFS"><span class="toc-number">1.</span> <span class="toc-text">Apache Hadoop、HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Apache-Hadoop%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">Apache Hadoop概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E4%BB%8B%E7%BB%8D%E3%80%81%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2%E3%80%81%E7%8E%B0%E7%8A%B6"><span class="toc-number">1.1.1.</span> <span class="toc-text">Hadoop介绍、发展简史、现状</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">Hadoop介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">Hadoop发展简史</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E7%8E%B0%E7%8A%B6"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">Hadoop现状</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E7%89%B9%E6%80%A7%E4%BC%98%E7%82%B9%E3%80%81%E5%9B%BD%E5%86%85%E5%A4%96%E5%BA%94%E7%94%A8"><span class="toc-number">1.1.2.</span> <span class="toc-text">Hadoop特性优点、国内外应用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E7%89%B9%E6%80%A7%E4%BC%98%E7%82%B9"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">Hadoop特性优点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E5%9B%BD%E5%A4%96%E5%BA%94%E7%94%A8"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">Hadoop国外应用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E5%9B%BD%E5%86%85%E5%BA%94%E7%94%A8"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">Hadoop国内应用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC%E3%80%81%E6%9E%B6%E6%9E%84%E5%8F%98%E8%BF%81"><span class="toc-number">1.1.3.</span> <span class="toc-text">Hadoop发行版本、架构变迁</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">Hadoop发行版本</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E6%9E%B6%E6%9E%84%E5%8F%98%E8%BF%81%EF%BC%881-0-2-0%E5%8F%98%E8%BF%81%EF%BC%89"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">Hadoop架构变迁（1.0-2.0变迁）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E6%9E%B6%E6%9E%84%E5%8F%98%E8%BF%81%EF%BC%883-0%E6%96%B0%E7%89%88%E6%9C%AC%EF%BC%89"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">Hadoop架构变迁（3.0新版本）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Apache-Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">1.2.</span> <span class="toc-text">Apache Hadoop集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">Hadoop集群简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F-%E5%88%86%E5%B8%83%E5%BC%8F-%E5%AE%89%E8%A3%85%EF%BC%88Cluster-mode%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">Hadoop集群模式(分布式)安装（Cluster mode）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Hadoop%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">Hadoop源码编译</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step1-%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2%E8%A7%84%E5%88%92"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">Step1:集群角色规划</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step2-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">Step2:服务器基础环境准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step3-%E4%B8%8A%E4%BC%A0%E5%AE%89%E8%A3%85%E5%8C%85%E3%80%81%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85%E5%8C%85"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">Step3:上传安装包、解压安装包</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step4-Hadoop%E5%AE%89%E8%A3%85%E5%8C%85%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.2.5.</span> <span class="toc-text">Step4:Hadoop安装包目录结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0"><span class="toc-number">1.2.2.6.</span> <span class="toc-text">配置文件概述</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-hadoop-env-sh"><span class="toc-number">1.2.2.7.</span> <span class="toc-text">Step5:编辑Hadoop配置文件 hadoop-env.sh</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-core-site-xml"><span class="toc-number">1.2.2.8.</span> <span class="toc-text">Step5:编辑Hadoop配置文件 core-site.xml</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6hdfs-site-xml"><span class="toc-number">1.2.2.9.</span> <span class="toc-text">Step5:编辑Hadoop配置文件hdfs-site.xml</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-mapred-site-xml"><span class="toc-number">1.2.2.10.</span> <span class="toc-text">Step5:编辑Hadoop配置文件 mapred-site.xml</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-yarn-site-xml"><span class="toc-number">1.2.2.11.</span> <span class="toc-text">Step5:编辑Hadoop配置文件 yarn-site.xml</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step5-%E7%BC%96%E8%BE%91Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-workers"><span class="toc-number">1.2.2.12.</span> <span class="toc-text">Step5:编辑Hadoop配置文件 workers</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step6-%E5%88%86%E5%8F%91%E5%90%8C%E6%AD%A5%E5%AE%89%E8%A3%85%E5%8C%85"><span class="toc-number">1.2.2.13.</span> <span class="toc-text">Step6:分发同步安装包</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step7-%E9%85%8D%E7%BD%AEHadoop%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.2.2.14.</span> <span class="toc-text">Step7:配置Hadoop环境变量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Step8-NameNode-format%EF%BC%88%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%93%8D%E4%BD%9C%EF%BC%89"><span class="toc-number">1.2.2.15.</span> <span class="toc-text">Step8:NameNode format（格式化操作）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E5%90%AF%E5%81%9C%E5%91%BD%E4%BB%A4%E3%80%81Web-UI"><span class="toc-number">1.2.3.</span> <span class="toc-text">Hadoop集群启停命令、Web UI</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E9%80%90%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%81%9C"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">手动逐个进程启停</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#shell%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">shell脚本一键启停</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E3%80%81%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">进程状态、日志查看</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS%E9%9B%86%E7%BE%A4web%E7%95%8C%E9%9D%A2"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">HDFS集群web界面</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#YARN%E9%9B%86%E7%BE%A4web%E7%95%8C%E9%9D%A2"><span class="toc-number">1.2.3.5.</span> <span class="toc-text">YARN集群web界面</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E5%88%9D%E4%BD%93%E9%AA%8C"><span class="toc-number">1.2.4.</span> <span class="toc-text">Hadoop初体验</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS-%E5%88%9D%E4%BD%93%E9%AA%8C"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">HDFS 初体验</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#shell%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.4.1.1.</span> <span class="toc-text">shell命令操作</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Web-UI%E9%A1%B5%E9%9D%A2%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.4.1.2.</span> <span class="toc-text">Web UI页面操作</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#MapReduce-YARN%E5%88%9D%E4%BD%93%E9%AA%8C"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">MapReduce+YARN初体验</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80"><span class="toc-number">1.3.</span> <span class="toc-text">HDFS分布式文件系统基础</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.3.1.</span> <span class="toc-text">文件系统、分布式文件系统</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9A%E4%B9%89"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">文件系统定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E5%B8%B8%E8%A7%81%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">传统常见的文件系统</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E3%80%81%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">数据、元数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.1.3.1.</span> <span class="toc-text">数据</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.1.3.2.</span> <span class="toc-text">元数据</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">海量数据存储遇到的问题</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B1%9E%E6%80%A7%E5%8F%8A%E5%8A%9F%E8%83%BD%E5%90%AB%E4%B9%89"><span class="toc-number">1.3.2.</span> <span class="toc-text">分布式存储系统的核心属性及功能含义</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">分布式存储的优点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E8%AE%B0%E5%BD%95%E7%9A%84%E5%8A%9F%E8%83%BD"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">元数据记录的功能</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%9D%97%E5%AD%98%E5%82%A8%E5%A5%BD%E5%A4%84"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">分块存储好处</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">副本机制的作用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E7%AE%80%E4%BB%8B"><span class="toc-number">1.3.3.</span> <span class="toc-text">HDFS简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E8%B5%B7%E6%BA%90%E5%8F%91%E5%B1%95%E3%80%81%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87"><span class="toc-number">1.3.4.</span> <span class="toc-text">HDFS起源发展、设计目标</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS%E8%B5%B7%E6%BA%90%E5%8F%91%E5%B1%95"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">HDFS起源发展</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">HDFS设计目标</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.3.5.</span> <span class="toc-text">HDFS应用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E9%87%8D%E8%A6%81%E7%89%B9%E6%80%A7"><span class="toc-number">1.3.6.</span> <span class="toc-text">HDFS重要特性</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%A6%82%E8%BF%B0"><span class="toc-number">1.3.6.1.</span> <span class="toc-text">整体概述</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.6.2.</span> <span class="toc-text">（1）主从架构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%88%86%E5%9D%97%E5%AD%98%E5%82%A8"><span class="toc-number">1.3.6.3.</span> <span class="toc-text">（2）分块存储</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.6.4.</span> <span class="toc-text">（3）副本机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86"><span class="toc-number">1.3.6.5.</span> <span class="toc-text">（4）元数据管理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%885%EF%BC%89namespace"><span class="toc-number">1.3.6.6.</span> <span class="toc-text">（5）namespace</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E6%95%B0%E6%8D%AE%E5%9D%97%E5%AD%98%E5%82%A8"><span class="toc-number">1.3.6.7.</span> <span class="toc-text">（6）数据块存储</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS-shell%E6%93%8D%E4%BD%9C"><span class="toc-number">1.4.</span> <span class="toc-text">HDFS shell操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS-shell%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E9%87%8A%E8%AF%B4%E6%98%8E"><span class="toc-number">1.4.1.</span> <span class="toc-text">HDFS shell命令行解释说明</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">文件系统协议</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8C%BA%E5%88%AB"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">参数说明</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS-shell%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">1.4.2.</span> <span class="toc-text">HDFS shell命令行常用操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">创建文件夹</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%86%85%E5%AE%B9"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">查看指定目录下内容</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0HDFS%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">上传文件到HDFS指定目录下</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8BHDFS%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9"><span class="toc-number">1.4.2.4.</span> <span class="toc-text">查看HDFS文件内容</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDHDFS%E6%96%87%E4%BB%B6"><span class="toc-number">1.4.2.5.</span> <span class="toc-text">下载HDFS文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8B%B7%E8%B4%9DHDFS%E6%96%87%E4%BB%B6"><span class="toc-number">1.4.2.6.</span> <span class="toc-text">拷贝HDFS文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%BD%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%88%B0HDFS%E6%96%87%E4%BB%B6%E4%B8%AD"><span class="toc-number">1.4.2.7.</span> <span class="toc-text">追加数据到HDFS文件中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS%E6%95%B0%E6%8D%AE%E7%A7%BB%E5%8A%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">1.4.2.8.</span> <span class="toc-text">HDFS数据移动操作</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#HDFS-shell%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4"><span class="toc-number">1.4.2.9.</span> <span class="toc-text">HDFS shell其他命令</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%9C%BA%E5%88%B6"><span class="toc-number">1.5.</span> <span class="toc-text">HDFS工作流程与机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2%E4%B8%8E%E8%81%8C%E8%B4%A3"><span class="toc-number">1.5.1.</span> <span class="toc-text">HDFS集群角色与职责</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%98%E6%96%B9%E6%9E%B6%E6%9E%84%E5%9B%BE"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">官方架构图</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E8%A7%92%E8%89%B2%EF%BC%9Anamenode"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">主角色：namenode</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8E%E8%A7%92%E8%89%B2%EF%BC%9Adatanode"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">从角色：datanode</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E8%A7%92%E8%89%B2%E8%BE%85%E5%8A%A9%E8%A7%92%E8%89%B2%EF%BC%9Asecondarynamenode"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">主角色辅助角色：secondarynamenode</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#namenode%E8%81%8C%E8%B4%A3"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">namenode职责</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#datanode%E8%81%8C%E8%B4%A3"><span class="toc-number">1.5.1.6.</span> <span class="toc-text">datanode职责</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%EF%BC%89"><span class="toc-number">1.5.2.</span> <span class="toc-text">HDFS写数据流程（上传文件）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%99%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">写数据完整流程图</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E2%80%93Pipeline%E7%AE%A1%E9%81%93"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">核心概念–Pipeline管道</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E2%80%93ACK%E5%BA%94%E7%AD%94%E5%93%8D%E5%BA%94"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">核心概念–ACK应答响应</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E2%80%93%E9%BB%98%E8%AE%A43%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5"><span class="toc-number">1.5.2.4.</span> <span class="toc-text">核心概念–默认3副本存储策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%99%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%E5%9B%BE%E6%96%87%E5%AD%97%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.5.2.5.</span> <span class="toc-text">写数据完整流程图文字描述</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%EF%BC%89"><span class="toc-number">1.5.3.</span> <span class="toc-text">HDFS读数据流程（下载文件）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">读数据完整流程图</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/11/12/HadoopBase/" title="Hadoop 生态"><img src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hadoop 生态"/></a><div class="content"><a class="title" href="/2022/11/12/HadoopBase/" title="Hadoop 生态">Hadoop 生态</a><time datetime="2022-11-12T13:31:16.000Z" title="发表于 2022-11-12 21:31:16">2022-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/07/TypeScript/" title="TypeScript"><img src="/2022/11/07/TypeScript/TypeScript.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TypeScript"/></a><div class="content"><a class="title" href="/2022/11/07/TypeScript/" title="TypeScript">TypeScript</a><time datetime="2022-11-07T08:34:19.000Z" title="发表于 2022-11-07 16:34:19">2022-11-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/03/HexoTagPlugins/" title="Hexo Built-in Tag Plugins (Hexo内置标签外挂)"><img src="https://pic1.imgdb.cn/item/6364a40416f2c2beb1303eee.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo Built-in Tag Plugins (Hexo内置标签外挂)"/></a><div class="content"><a class="title" href="/2022/11/03/HexoTagPlugins/" title="Hexo Built-in Tag Plugins (Hexo内置标签外挂)">Hexo Built-in Tag Plugins (Hexo内置标签外挂)</a><time datetime="2022-11-03T06:08:31.000Z" title="发表于 2022-11-03 14:08:31">2022-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/03/KeyboardShutcut/" title="实用快捷键"><img src="https://pic1.imgdb.cn/item/636637e316f2c2beb1011a65.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="实用快捷键"/></a><div class="content"><a class="title" href="/2022/11/03/KeyboardShutcut/" title="实用快捷键">实用快捷键</a><time datetime="2022-11-02T16:49:59.000Z" title="发表于 2022-11-03 00:49:59">2022-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/27/TheCharmOfMarkdown/" title="了不起的 Markdown"><img src="https://pic1.imgdb.cn/item/63676da116f2c2beb11fa14e.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="了不起的 Markdown"/></a><div class="content"><a class="title" href="/2022/10/27/TheCharmOfMarkdown/" title="了不起的 Markdown">了不起的 Markdown</a><time datetime="2022-10-27T07:15:43.000Z" title="发表于 2022-10-27 15:15:43">2022-10-27</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Shiqing Huang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>