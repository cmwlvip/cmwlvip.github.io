<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka | Ofra Serendipity</title><meta name="author" content="Shiqing Huang"><meta name="copyright" content="Shiqing Huang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka命令行操作  Kafka 概述Kafka定义 Kafka传统定义：Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（MessageQueue），主要应用于大数据实时处理领域。 发布&#x2F;订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息。 Kafka最新定义： Kafka 是一个开源的分布式事件流平台（ Event Streami">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="https://www.huangshiqing.website/2023/05/08/kafka3-4-0/index.html">
<meta property="og:site_name" content="Ofra Serendipity">
<meta property="og:description" content="Kafka命令行操作  Kafka 概述Kafka定义 Kafka传统定义：Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（MessageQueue），主要应用于大数据实时处理领域。 发布&#x2F;订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息。 Kafka最新定义： Kafka 是一个开源的分布式事件流平台（ Event Streami">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg">
<meta property="article:published_time" content="2023-05-08T00:01:28.000Z">
<meta property="article:modified_time" content="2023-05-15T00:00:00.000Z">
<meta property="article:author" content="Shiqing Huang">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg"><link rel="shortcut icon" href="/img/favicon01.png"><link rel="canonical" href="https://www.huangshiqing.website/2023/05/08/kafka3-4-0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"bottom","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: Shiqing Huang","link":"链接: ","source":"来源: Ofra Serendipity","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-15 00:00:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 8 || hour >= 20
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "/img/loading.gif" data-lazy-src="/img/avatar001.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart-pulse"></i><span> Fun</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book-open"></i><span> Book</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fab fa-steam"></i><span> Game</span></a></li><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i><span> Song</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-headphones"></i><span> Music</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/translation/"><i class="fa-fw fas fa-language"></i><span> Translation</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i><span> Reference</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/2023/02/26/acwing/"><i class="fa-fw fas fa-arrow-right"></i><span> Acwing</span></a></li><li><a class="site-page child" href="/2022/11/03/KeyboardShutcut/"><i class="fa-fw fas fa-arrow-right"></i><span> 实用快捷键</span></a></li><li><a class="site-page child" href="/2022/10/27/TheCharmOfMarkdown/"><i class="fa-fw fas fa-arrow-right"></i><span> 了不起的 Markdown</span></a></li><li><a class="site-page child" href="/2022/11/03/HexoTagPlugins/"><i class="fa-fw fas fa-arrow-right"></i><span> Hexo Built-in Tag Plugins</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Ofra Serendipity"><span class="site-name">Ofra Serendipity</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart-pulse"></i><span> Fun</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book-open"></i><span> Book</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fab fa-steam"></i><span> Game</span></a></li><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i><span> Song</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-headphones"></i><span> Music</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-wrench"></i><span> Tools</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/translation/"><i class="fa-fw fas fa-language"></i><span> Translation</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i><span> Reference</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/2023/02/26/acwing/"><i class="fa-fw fas fa-arrow-right"></i><span> Acwing</span></a></li><li><a class="site-page child" href="/2022/11/03/KeyboardShutcut/"><i class="fa-fw fas fa-arrow-right"></i><span> 实用快捷键</span></a></li><li><a class="site-page child" href="/2022/10/27/TheCharmOfMarkdown/"><i class="fa-fw fas fa-arrow-right"></i><span> 了不起的 Markdown</span></a></li><li><a class="site-page child" href="/2022/11/03/HexoTagPlugins/"><i class="fa-fw fas fa-arrow-right"></i><span> Hexo Built-in Tag Plugins</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-08T00:01:28.000Z" title="发表于 2023-05-08 00:01:28">2023-05-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-15T00:00:00.000Z" title="更新于 2023-05-15 00:00:00">2023-05-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>50分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="Kafka"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note default modern"><p><a href="#Kafka命令行操作">Kafka命令行操作</a></p>
</div>
<h2 id="Kafka-概述"><a href="#Kafka-概述" class="headerlink" title="Kafka 概述"></a>Kafka 概述</h2><h3 id="Kafka定义"><a href="#Kafka定义" class="headerlink" title="Kafka定义"></a>Kafka定义</h3><ul>
<li>Kafka传统定义：Kafka是一个<strong>分布式</strong>的基于<strong>发布/订阅模式</strong>的<strong>消息队列</strong>（MessageQueue），主要应用于<strong>大数据实时处理领域</strong>。</li>
<li>发布/订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是<strong>将发布的消息分为不同的类别</strong>，订阅者<strong>只接收感兴趣的消息</strong>。</li>
<li>Kafka最新定义： Kafka 是一个开源的<strong>分布式事件流平台</strong>（ Event StreamingPlatform），被数千家公司用于<strong>高性能数据管道、流分析、数据集成和关键任务应用</strong>。</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-32-43.png" alt="双十一购物"><br><div class="note info modern"><p>为了更好理解，就拿双十一购物来说，数据量太大，Hadoop一时间处理不了，需要时间去缓冲，Kafka的作用就体现出来了</p>
</div></p>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>目前企业中比较常见的消息队列产品主要有Kafka 、ActiveMQ、RabbitMQ、RocketMQ 等</p>
<p>在大数据场景主要采用<code>Kafka</code>作为消息队列。在JavaEE 开发中主要采用ActiveMQ、RabbitMQ、RocketMQ</p>
<h4 id="传统消息队列的应用场景"><a href="#传统消息队列的应用场景" class="headerlink" title="传统消息队列的应用场景"></a>传统消息队列的应用场景</h4><p>传统的消息队列的主要应用场景包括：<strong>缓存/消峰</strong>、<strong>解耦</strong>和<strong>异步通信</strong>。</p>
<div class="tabs" id="kafka"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="kafka-1">缓存/消峰</button><button type="button" class="tab " data-href="kafka-2">解耦</button><button type="button" class="tab " data-href="kafka-3">异步通信</button></ul><div class="tab-contents"><div class="tab-item-content active" id="kafka-1"><p><strong>缓冲/消峰</strong>：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-49-38.png" alt="缓冲/消峰"></p></div><div class="tab-item-content" id="kafka-2"><p><strong>解耦</strong>：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-50-16.png" alt="解耦"></p></div><div class="tab-item-content" id="kafka-3"><p><strong>异步通信</strong>：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-51-00.png" alt="异步通信"></p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div>
<h4 id="消息队列的两种模式"><a href="#消息队列的两种模式" class="headerlink" title="消息队列的两种模式"></a>消息队列的两种模式</h4><div class="tabs" id="twopattern"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="twopattern-1">点对点模式</button><button type="button" class="tab " data-href="twopattern-2">发布/订阅模式</button></ul><div class="tab-contents"><div class="tab-item-content active" id="twopattern-1"><ul>
<li>消费者主动拉取数据，消息收到后清除消息</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-53-19.png" alt="点对点模式"></p></div><div class="tab-item-content" id="twopattern-2"><ul>
<li>可以有多个topic主题（浏览、点赞、收藏、评论等）</li>
<li>消费者消费数据之后，不删除数据</li>
<li>每个消费者相互独立，都可以消费到数据</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-00-56-19.png" alt="发布/订阅模式"></p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div>
<h3 id="Kafka基础架构"><a href="#Kafka基础架构" class="headerlink" title="Kafka基础架构"></a>Kafka基础架构</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-01-00-49.png" alt="Kafka基础架构"></p>
<ol>
<li><code>Producer</code>：消息生产者，就是向Kafka broker 发消息的客户端。</li>
<li><code>Consumer</code>：消息消费者，向Kafka broker 取消息的客户端。</li>
<li><code>Consumer Group（CG）</code>：消费者组，由多个consumer 组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。</strong>所有的消费者都属于某个消费者组，即<strong>消费者组是逻辑上的一个订阅者</strong>。</li>
<li><code>Broker</code>：一台Kafka 服务器就是一个broker。一个集群由多个broker 组成。一个broker 可以容纳多个topic。</li>
<li><code>Topic</code>：可以理解为一个队列，<strong>生产者和消费者面向的都是一个topic</strong>。</li>
<li><code>Partition</code>：为了实现扩展性，一个非常大的topic 可以分布到多个broker（即服务器）上，<strong>一个topic可以分为多个partition</strong>，每个partition 是<strong>一个有序的队列</strong>。</li>
<li><code>Replica</code>：副本。一个topic 的每个分区都有若干个副本，一个<code>Leader</code>和若干个<code>Follower</code>。</li>
<li><code>Leader</code>：每个分区多个<strong>副本的“主”</strong>，生产者发送数据的对象，以及消费者消费数据的对象都是Leader。</li>
<li><code>Follower</code>：每个分区多个<strong>副本中的“从”</strong>，实时从Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个Follower 会成为新的Leader。</li>
</ol>
<h2 id="Kafka快速入门"><a href="#Kafka快速入门" class="headerlink" title="Kafka快速入门"></a>Kafka快速入门</h2><h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h3><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><ul>
<li>Zookeeper: 3.8.1</li>
<li>Kafka：3.4.0</li>
</ul>
<h4 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h4><div class="table-container">
<table>
<thead>
<tr>
<th>hsq01</th>
<th>hsq02</th>
<th>hsq03</th>
</tr>
</thead>
<tbody>
<tr>
<td>zk</td>
<td>zk</td>
<td>zk</td>
</tr>
<tr>
<td>kafka</td>
<td>kafka</td>
<td>kafka</td>
</tr>
</tbody>
</table>
</div>
<h4 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h4><h5 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h5><p>从<a target="_blank" rel="noopener" href="https://kafka.apache.org/">Kafka</a>官网下载好安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.12-3.4.0.tgz -C /mysoft/</span><br></pre></td></tr></table></figure>
<h5 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h5><figure class="highlight sh"><figcaption><span>vi /etc/profile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Kafka enviroment variables</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_HOME=/mysoft/kafka_2.12-3.4.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>使环境变量生效</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<h5 id="配置server-properties"><a href="#配置server-properties" class="headerlink" title="配置server.properties"></a>配置<code>server.properties</code></h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $KAFKA_HOME</span><br><span class="line">cd config/</span><br><span class="line">vi server.properties</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker 的全局唯一编号，不能重复，只能是数字。</span></span><br><span class="line marked">broker.id=0</span><br><span class="line"><span class="comment">#处理网络请求的线程数量</span></span><br><span class="line">num.network.threads=3</span><br><span class="line"><span class="comment">#用来处理磁盘 IO 的线程数量</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"><span class="comment">#发送套接字的缓冲区大小</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"><span class="comment">#接收套接字的缓冲区大小</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"><span class="comment">#请求套接字的缓冲区大小</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"><span class="comment">#kafka 运行日志数据存放的路径 ，路径不需要提前创建kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用“,”分隔开</span></span><br><span class="line marked">log.dirs=/mysoft/kafka_2.12-3.4.0/data</span><br><span class="line"><span class="comment">#topic 在当前 broker 上的分区个数</span></span><br><span class="line">num.partitions=1</span><br><span class="line"><span class="comment">#用来恢复和清理 data 下数据的线程数量</span></span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"><span class="comment">#每个 topic 创建时的副本数，默认时 1 个副本</span></span><br><span class="line">offsets.topic.replication.factor=1</span><br><span class="line"><span class="comment">#segment 文件保留的最长时间，超时将被删除</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="comment">#每个 segment 文件 的大小，默认最大 1G</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="comment">#检查过期数据的时间，默认 5 分钟检查一次是否数据过期</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="comment">#配置连接 Zookeeper 集群地址（在 zk 根目录下创建 kafka ，方便管理）</span></span><br><span class="line marked">zookeeper.connect=hsq01:2181,hsq02:2181,hsq03:2181/kafka</span><br></pre></td></tr></table></figure>
<h5 id="将Kafka目录及Kafka环境分发到其他主机"><a href="#将Kafka目录及Kafka环境分发到其他主机" class="headerlink" title="将Kafka目录及Kafka环境分发到其他主机"></a>将Kafka目录及Kafka环境分发到其他主机</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for i in &#123;2..3&#125;; do scp -r /mysoft/kafka_2.12-3.4.0/ hsq0$i:/mysoft/;done</span><br><span class="line">for i in &#123;2..3&#125;; do scp /etc/profile hsq0$i:/etc/profile;done</span><br></pre></td></tr></table></figure>
<h5 id="修改另外两台虚拟机server-properties文件"><a href="#修改另外两台虚拟机server-properties文件" class="headerlink" title="修改另外两台虚拟机server.properties文件"></a>修改另外两台虚拟机<code>server.properties</code>文件</h5><ul>
<li>02虚拟机<code>broker.id=1</code></li>
<li>03虚拟机<code>broker.id=2</code></li>
</ul>
<div class="note warning modern"><p><code>broker.id</code>不得重复 ，整个集群中唯一</p>
</div>
<h5 id="使环境变量生效"><a href="#使环境变量生效" class="headerlink" title="使环境变量生效"></a>使环境变量生效</h5><p>每台虚拟机分别执行<code>source /etc/profile</code></p>
<h5 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h5><ul>
<li><p>先启动Zookeeper集群</p>
<div class="note info modern"><p>Zookeeper集群部署请前往 <a href="/2023/03/27/zookeeper3-8-1/" title="Zookeeper部署">Zookeeper部署</a></p>
</div>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xzk.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后启动Kafka集群，依次在 <code>hsq01</code> <code>hsq02</code> <code>hsq03</code> 节点上启动 Kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $KAFKA_HOME</span><br><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure>
<div class="note warning modern"><p><code>-daemon</code>指定<code>server .properties</code>参数时，一定要能够从当前路径到<code>server .properties</code>路径，否则Kafka不能成功开启<br><code>jps</code>出现Kafka</p>
</div>
</li>
<li><p>关闭Kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-stop.sh</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="启动和关闭Kafka集群脚本"><a href="#启动和关闭Kafka集群脚本" class="headerlink" title="启动和关闭Kafka集群脚本"></a>启动和关闭Kafka集群脚本</h5><p>启动和关闭<code>Kafka</code>集群需要在每台虚拟机上启动和关闭<code>Kafka</code>服务器。如果使用的虚拟机很多，效率会非常低。<br>为了方便的使用 Zookeeper 集群，可以编写启动脚本<code>kf.sh</code>。</p>
<p><strong>(1)在虚拟机<code>hsq01</code>的目录<code>/usr/local/bin/</code>下新建<code>kf.sh</code>脚本文件</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/bin/kf.sh</span><br></pre></td></tr></table></figure></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hsq01 hsq02 hsq03</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        tput setaf 5</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;============ start <span class="variable">$i</span> Kafka ============&quot;</span></span><br><span class="line">        tput setaf 9</span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;source /etc/profile ; kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hsq01 hsq02 hsq03</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        tput setaf 1</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;============ stop <span class="variable">$i</span> Kafka ============&quot;</span></span><br><span class="line">        tput setaf 9</span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;source /etc/profile ; kafka-server-stop.sh&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>
<p><strong>(2)为<code>kf.sh</code>脚本添加执行权限</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/bin/</span><br><span class="line">chmod u+x kf.sh</span><br></pre></td></tr></table></figure></p>
<p><strong>(3)通过<code>kf.sh</code>脚本的<code>start</code>和<code>stop</code>命令，就可以在虚拟机01上同时启动和关闭所有虚拟机的Kafka</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kf.sh start</span><br><span class="line">kf.sh stop</span><br></pre></td></tr></table></figure><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-08-23-41-55.png" alt="同过脚本启动与关闭"></p>
<div class="note warning modern"><p>停止Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。</p>
</div>
<h3 id="Kafka命令行操作"><a href="#Kafka命令行操作" class="headerlink" title="Kafka命令行操作"></a>Kafka命令行操作</h3><h4 id="主题命令行操作"><a href="#主题命令行操作" class="headerlink" title="主题命令行操作"></a>主题命令行操作</h4><p><strong>1)查看操作主题命令参数</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh</span><br></pre></td></tr></table></figure></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--bootstrap-server &lt;String: server to connect to&gt;</code></td>
<td>连接的 Kafka Broker主机名称和端口号</td>
</tr>
<tr>
<td><code>--topic &lt;String: topic&gt;</code></td>
<td>操作的topic名称</td>
</tr>
<tr>
<td><code>--create</code></td>
<td>创建主题</td>
</tr>
<tr>
<td><code>--delete</code></td>
<td>删除主题</td>
</tr>
<tr>
<td><code>--alter</code></td>
<td>修改主题</td>
</tr>
<tr>
<td><code>--ist</code></td>
<td>查看所有主题</td>
</tr>
<tr>
<td><code>--describe</code></td>
<td>查看主题详细描述</td>
</tr>
<tr>
<td><code>--partitions &lt;Integer: # of partitions&gt;</code></td>
<td>设置分区数</td>
</tr>
<tr>
<td><code>--replication-factor &lt;Integer: replication factor&gt;</code></td>
<td>设置分区副本</td>
</tr>
<tr>
<td><code>--config &lt;String: name=value&gt;</code></td>
<td>更新系统默认的配置</td>
</tr>
</tbody>
</table>
</div>
<p><strong>2)查看当前服务器中的所有topic</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --list</span><br></pre></td></tr></table></figure></p>
<p><strong>3)创建<code>first</code>topic</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --create --partitions 1 --replication-factor 3 --topic first</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>--topic</code>定义 topic 名</li>
<li><code>--replication-factor</code> 定义副本数，不指定默认为1</li>
<li><code>--partitions</code> 定义分区数，不指定默认为1</li>
</ul>
<p><strong>4)查看<code>first</code>主题的详情</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --describe --topic first</span><br></pre></td></tr></table></figure></p>
<p><strong>5)修改分区数</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --alter --topic first --partitions 3</span><br></pre></td></tr></table></figure></p>
<p>修改后再次查看详情可观察变化</p>
<div class="note warning modern"><p>分区数只能增加，不能减少</p>
</div>
<p><strong>6)删除topic</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --delete --topic first</span><br></pre></td></tr></table></figure></p>
<h4 id="生产者命令行操作"><a href="#生产者命令行操作" class="headerlink" title="生产者命令行操作"></a>生产者命令行操作</h4><p><strong>1)查看操作生产者命令参数</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh</span><br></pre></td></tr></table></figure></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--bootstrap-server&lt;String: server to connect to&gt;</code></td>
<td>连接的 Kafka Broker主机名称和端口号</td>
</tr>
<tr>
<td><code>--topic &lt;String: topic&gt;</code></td>
<td>操作的topic名称</td>
</tr>
</tbody>
</table>
</div>
<p><strong>2)发送消息</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --bootstrap-server hsq01:9092 --topic first</span><br></pre></td></tr></table></figure></p>
<h4 id="消费者命令行操作"><a href="#消费者命令行操作" class="headerlink" title="消费者命令行操作"></a>消费者命令行操作</h4><p><strong>查看操作消费者命令参数</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh</span><br></pre></td></tr></table></figure></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--bootstrap-server&lt;String: server to connect to&gt;</code></td>
<td>连接的 Kafka Broker主机名称和端口号</td>
</tr>
<tr>
<td><code>--topic &lt;String: topic&gt;</code></td>
<td>操作的topic名称</td>
</tr>
<tr>
<td><code>--from-beginning</code></td>
<td>从头开始消费</td>
</tr>
<tr>
<td><code>--group &lt;String: consumer group id&gt;</code></td>
<td>指定消费者组名称</td>
</tr>
</tbody>
</table>
</div>
<p><strong>1)消费<code>first</code>主题中的数据</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server hsq01:9092 --topic first</span><br></pre></td></tr></table></figure></p>
<p><strong>2)把主题中所有的数据都读取出来（包括历史数据）</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server hsq01:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure></p>
<h2 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h2><h3 id="生产者消息发送流程"><a href="#生产者消息发送流程" class="headerlink" title="生产者消息发送流程"></a>生产者消息发送流程</h3><h4 id="发送原理"><a href="#发送原理" class="headerlink" title="发送原理"></a>发送原理</h4><p>在消息发送的过程中，涉及到<strong>两个线程——<code>main</code>线程和<code>Sender</code>线程</strong>。在<code>main</code>线程中创建了一个<strong>双端队列<code>RecordAccumulator</code></strong>。main 线程将消息发送给RecordAccumulator，Sender 线程不断从RecordAccumulator中拉取消息发送到Kafka Broker。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-11-54-45.png" alt="发送流程"></p>
<h4 id="生产者重要参数列表"><a href="#生产者重要参数列表" class="headerlink" title="生产者重要参数列表"></a>生产者重要参数列表</h4><div class="table-container">
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bootstrap.servers</code></td>
<td>生产者连接集群所需的broker地址清单。例如hsq01:9092,hsq02:9092,hsq03:9092，可以设置1 个或者多个，中间用逗号隔开(不需要所有的broker地址，因为生产者从给定的 broker 里查找到其他 broker 信息)</td>
</tr>
<tr>
<td><code>key.serializer</code> 和 <code>value.serializer</code></td>
<td>指定发送消息的 key 和 value 的序列化类型，一定要写全类名</td>
</tr>
<tr>
<td><code>buffer.memory</code></td>
<td>RecordAccumulator缓冲区总大小，<strong>默认32m</strong></td>
</tr>
<tr>
<td><code>batch.size</code></td>
<td>缓冲区一批数据最大值，<strong>默认16k</strong>，适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加</td>
</tr>
<tr>
<td><code>linger.ms</code></td>
<td>如果数据迟迟未达到batch.size，sender等待 linger.time 之后就会发送数据，单位 ms ，<strong>默认值是0ms</strong> ，表示没有延迟。 生产环境建议该值大小为 5—100ms 之间</td>
</tr>
<tr>
<td><code>acks</code></td>
<td>0：生产者发送过来的数据，不需要等数据落盘应答<br>1：生产者发送过来的数据 Leader 收到数据后应答<br>-1 (all)：生产者发送过来的数据 Leader+ 和 isr 队列里面的所有节点收齐数据后应答<br> <strong>默认值是-1</strong> ，<strong>-1和all是等价的</strong></td>
</tr>
<tr>
<td><code>max.in.flight.requests.per.connection</code></td>
<td>允许最多没有返回 ack 的次数，<strong>默认为5</strong>，开启幂等性要保证该值是1-5的数字</td>
</tr>
<tr>
<td><code>retries</code></td>
<td>当消息发送出现错误的时候，系统会重发消息，retries表示重试次数，<strong>默认是int最大值：2147483647</strong>，如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1，否则在重试此失败消息的时候，其他的消息可能发送成功了</td>
</tr>
<tr>
<td><code>retry.backoff.ms</code></td>
<td>两次重试之间的时间间隔，默认是 100ms</td>
</tr>
<tr>
<td><code>enable.idempotence</code></td>
<td>是否开启幂等性，<strong>默认true</strong></td>
</tr>
<tr>
<td><code>compression.type</code></td>
<td>生产者发送的所有数据的压缩方式，<strong>默认是none</strong>，也就是不压缩<br>支持压缩类型:<code>none</code>、<code>gzip</code>、<code>snappy</code>、<code>lz4</code>和<code>zstd</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="异步发送API"><a href="#异步发送API" class="headerlink" title="异步发送API"></a>异步发送API</h3><h4 id="普通异步发送"><a href="#普通异步发送" class="headerlink" title="普通异步发送"></a>普通异步发送</h4><p><strong>需求：</strong>创建 Kafka 生产者，采用异步的方式发送到 Kafka Broker</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-14-13-34.png" alt="异步发送流程"></p>
<blockquote><p>代码编写</p>
</blockquote>
<p>1.创建Maven项目<br>2.导入依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>3.创建包名：<code>com.hsq.kafka.producer</code><br>4.编写不带回调函数的API代码<br><figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br></pre></td></tr></table></figure><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//1. 创建kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        String topicName=<span class="string">&quot;first&quot;</span>;</span><br><span class="line">        <span class="comment">//2. 给kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        <span class="comment">//连接集群 bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hsq01:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value 序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        <span class="comment">//指定对应的key和value的序列化类型 key.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">//properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer .class.getName());//和上面语句等价，一般使用这种形式</span></span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">//3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">//4. 调用 send 方法发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName,<span class="string">&quot;test\t&quot;</span>+i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote><p>测试结果</p>
</blockquote>
<p>①在hsq02上开启 Kafka 消费者<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server hsq01:9092 --topic first</span><br></pre></td></tr></table></figure></p>
<p>②在 IDEA 中执行代码，观察hsq02控制台中是否接收到消息<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-14-48-00.png" alt="收到消息"></p>
<h4 id="带回调函数的异步发送"><a href="#带回调函数的异步发送" class="headerlink" title="带回调函数的异步发送"></a>带回调函数的异步发送</h4><p>回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息（ RecordMetadata 和 异常信息（ Exception ）），如果 Exception 为 null ，说明消息发送成功，如果 Exception 不为 null ，说明消息发送失败。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-14-55-16.png" alt="带回调函数的异步发送流程"><br><div class="note warning modern"><p>消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p>
</div></p>
<blockquote><p>编写代码</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//4. 调用 send 方法发送消息</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName, <span class="string">&quot;test\t&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e==<span class="literal">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;主题：&quot;</span>+recordMetadata.topic()+<span class="string">&quot;分区：&quot;</span>+recordMetadata.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;s</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote><p>测试结果</p>
</blockquote>
<p>①在hsq02上开启 Kafka 消费者<br>②在IDEA 中执行代码，观察hsq02控制台中是否接收到消息<br>③在IDEA 控制台观察回调信息<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-15-00-12.png" alt="IDEA 控制台观察回调信息"></p>
<h3 id="同步发送API"><a href="#同步发送API" class="headerlink" title="同步发送API"></a>同步发送API</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-15-05-02.png" alt="同步发送流程"></p>
<div class="note info modern"><p>只需在异步发送的基础上，再调用一下get()方法即可，并添加异常处理即可。</p>
</div>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//4. 调用 send 方法发送消息</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line marked">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName,<span class="string">&quot;test\t&quot;</span>+i)).get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div class="note info modern"><p>结果于表面并无区别</p>
</div>
<h3 id="生产者分区"><a href="#生产者分区" class="headerlink" title="生产者分区"></a>生产者分区</h3><h4 id="分区好处"><a href="#分区好处" class="headerlink" title="分区好处"></a>分区好处</h4><ul>
<li><strong>便于合理使用存储资源</strong>，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现<strong>负载均衡</strong>的效果。</li>
<li><strong>提高并行度</strong>，生产者可以以分区为单位<strong>发送数据</strong>；消费者可以以分区为单位进行<strong>消费数据</strong>。</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-15-14-30.png" alt="分区"></p>
<h4 id="生产者发送消息的分区策略"><a href="#生产者发送消息的分区策略" class="headerlink" title="生产者发送消息的分区策略"></a>生产者发送消息的分区策略</h4><h5 id="默认的分区器DefaultPartitioner"><a href="#默认的分区器DefaultPartitioner" class="headerlink" title="默认的分区器DefaultPartitioner"></a>默认的分区器DefaultPartitioner</h5><ul>
<li>If a partition is specified in the record, use it</li>
<li>If no partition is specified but a key is present choose a partition based on a hash of the key</li>
<li>If no partition or key is present choose the sticky partition that changes when the batch is full.</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-15-34-17.png" alt="默认的分区器"></p>
<div class="tabs" id="defaultpartitioner"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="defaultpartitioner-1">测试一</button><button type="button" class="tab " data-href="defaultpartitioner-2">测试二</button></ul><div class="tab-contents"><div class="tab-item-content active" id="defaultpartitioner-1"><p><strong>将数据发往指定partition</strong>的情况下，例如，将所有数据发往分区1 中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//4. 调用 send 方法发送消息</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line">    <span class="comment">// 指定数据发送到 1 号分区， key 为空 IDEA 中 ctrl + p 查看参数）</span></span><br><span class="line marked">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName,<span class="number">1</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;test\t&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e==<span class="literal">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;主题：&quot;</span>+recordMetadata.topic()+<span class="string">&quot;分区：&quot;</span>+recordMetadata.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-11-15-42-55.png" alt="结果"></p></div><div class="tab-item-content" id="defaultpartitioner-2"><p><strong>没有指明partition值但有key的情况下</strong>，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//4. 调用 send 方法发送消息</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line">    <span class="comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1 、 2 、 0</span></span><br><span class="line marked">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;test\t&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e==<span class="literal">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;主题：&quot;</span>+recordMetadata.topic()+<span class="string">&quot;分区：&quot;</span>+recordMetadata.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>key=&quot;a&quot;</code>时，在控制台查看结果<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first分区：1</span><br><span class="line">主题：first分区：1</span><br><span class="line">主题：first分区：1</span><br><span class="line">主题：first分区：1</span><br><span class="line">主题：first分区：1</span><br></pre></td></tr></table></figure></li>
<li><code>key=&quot;b&quot;</code>时，在控制台查看结果<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first分区：2</span><br><span class="line">主题：first分区：2</span><br><span class="line">主题：first分区：2</span><br><span class="line">主题：first分区：2</span><br><span class="line">主题：first分区：2</span><br></pre></td></tr></table></figure></li>
<li><code>key=&quot;f&quot;</code>时，在控制台查看结果<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first分区：0</span><br><span class="line">主题：first分区：0</span><br><span class="line">主题：first分区：0</span><br><span class="line">主题：first分区：0</span><br><span class="line">主题：first分区：0</span><br></pre></td></tr></table></figure>
</li>
</ul></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div>
<h4 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a>自定义分区器</h4><p>可以根据需求，重新实现分区器。</p>
<blockquote><p>需求</p>
</blockquote>
<p>实现一个分区器实现，发送过来的数据中如果包含test，就发往0号分区，不包含test，就发往1号分区。</p>
<blockquote><p>编写代码</p>
</blockquote>
<ul>
<li>定义类实现Partitioner接口</li>
<li>重写partition方法</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsq.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="comment">//topic 主题</span></span><br><span class="line">    <span class="comment">//key 消息的 key</span></span><br><span class="line">    <span class="comment">//keyBytes 消息的 key 序列化后的字节数组</span></span><br><span class="line">    <span class="comment">//value 消息的 value</span></span><br><span class="line">    <span class="comment">//valueBytes 消息的 value 序列化后的字节数组</span></span><br><span class="line">    <span class="comment">//cluster 集群元数据可以查看分区信息</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取消息</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">msgValue</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="comment">// 创建 partition</span></span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="comment">// 判断消息是否包含test</span></span><br><span class="line">        <span class="keyword">if</span>(msgValue.contains(<span class="string">&quot;test&quot;</span>))&#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            partition=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 返回分区号</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 关闭资源</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 配置方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote><p>使用分区器的方法 ，在生产者的配置中添加分 区器参数</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加自定义分区器</span></span><br><span class="line">properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,MyPartitioner.class);</span><br></pre></td></tr></table></figure>
<h3 id="生产经验——生产者如何提高吞吐量"><a href="#生产经验——生产者如何提高吞吐量" class="headerlink" title="生产经验——生产者如何提高吞吐量"></a>生产经验——生产者如何提高吞吐量</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-00-00-35.png" alt="生产者如何提高吞吐量"></p>
<figure class="highlight java"><figcaption><span>可添加入下配置项</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RecordAccumulator：缓冲区大小，默认32M：buffer.memory</span></span><br><span class="line">properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,<span class="number">33554432</span>);</span><br><span class="line"><span class="comment">// batch.size：批次大小，默认16K</span></span><br><span class="line">properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"><span class="comment">// linger.ms：等待时间，默认0</span></span><br><span class="line">properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// compression.type 压缩，默认 none ，可配置值 gzip 、 snappy 、lz4 和 zstd</span></span><br><span class="line">properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,<span class="string">&quot;snappy&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="生产经验——数据可靠性"><a href="#生产经验——数据可靠性" class="headerlink" title="生产经验——数据可靠性"></a>生产经验——数据可靠性</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-00-12-17.png" alt="ACK应答级别"></p>
<div class="note pink icon-padding modern"><i class="note-icon fas fa-question"></i><p>Leader收到数据，所有Follower都开始同步数据，但有一个Follower，因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢？</p>
</div>
<div class="note blue icon-padding modern"><i class="note-icon fas fa-comment"></i><p><strong>Leader维护了一个动态的in-sync replica set（ISR），意为和Leader保持同步的Follower+Leader集合(leader：0，isr:0,1,2)</strong>。<br>如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由<strong>replica.lag.time.max.ms参数设定，默认30s</strong>。例如2超时，(leader:0, isr:0,1)。<br><strong>这样就不用等长期联系不上或者已经故障的节点。</strong></p>
</div>
<p>数据可靠性分析：</p>
<p>如果分区副本设置为1个，或者ISR里应答的最小副本数量（min.insync.replicas 默认为1）设置为1，和ack=1的效果是一样的，仍然有丢数的风险<code>（leader：0，isr:0）</code>。</p>
<div class="note info modern"><p><strong>数据完全可靠条件= ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</strong></p>
</div>
<p>可靠性总结：</p>
<ul>
<li>acks=0，生产者发送过来数据就不管了，可靠性差，效率高；</li>
<li>acks=1，生产者发送过来数据Leader应答，可靠性中等，效率中等；</li>
<li>acks=-1，生产者发送过来数据Leader和ISR队列里面所有Follwer应答，可靠性高，效率低；在生产环境中，acks=0很少使用；acks=1，一般用于传输普通日志，允许丢个别数据；acks=-1，一般用于传输和钱相关的数据，对可靠性要求比较高的场景。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 acks</span></span><br><span class="line">properties.put(ProducerConfig.ACKS_CONFIG , <span class="string">&quot;all&quot;</span>);</span><br><span class="line"><span class="comment">// 重试次数 retries ，默认是 int 最大值， 2147483647</span></span><br><span class="line">properties.put( ProducerConfig.RETRIES_CONFIG ,<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p>数据重复分析：</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-00-55-41.png" alt="数据重复分析"></p>
<h3 id="生产经验——数据去重"><a href="#生产经验——数据去重" class="headerlink" title="生产经验——数据去重"></a>生产经验——数据去重</h3><h4 id="数据传递语义"><a href="#数据传递语义" class="headerlink" title="数据传递语义"></a>数据传递语义</h4><ul>
<li>至少一次（At Least Once）=<strong>ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</strong></li>
<li>最多一次（AtMost Once）= <strong>ACK级别设置为0</strong></li>
<li>总结：<ul>
<li>At Least Once可以保证数据不丢失，但是<strong>不能保证数据不重复</strong></li>
<li>At Most Once可以保证数据不重复，但是<strong>不能保证数据不丢失</strong></li>
</ul>
</li>
<li>精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据<strong>既不能重复也不丢失</strong></li>
</ul>
<div class="note info modern"><p>Kafka 0.11版本以后，引入了一项重大特性：<strong>幂等性</strong>和<strong>事务</strong>。</p>
</div>
<h4 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h4><h5 id="幂等性原理"><a href="#幂等性原理" class="headerlink" title="幂等性原理"></a>幂等性原理</h5><p><strong>幂等性</strong>就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。<br><div class="note info modern"><p>精确一次（Exactly Once） = 幂等性+ 至少一次（ ack=-1 + 分区副本数&gt;=2 + ISR最小副本数量&gt;=2）</p>
</div></p>
<p><strong>重复数据的判断标准</strong>：具有<code>&lt;PID, Partition, SeqNumber&gt;</code>相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。<br>所以幂等性<strong>只能保证的是在单分区单会话内不重复</strong>。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-01-31-23.png" alt="幂等性"></p>
<h5 id="如何使用幂等性"><a href="#如何使用幂等性" class="headerlink" title="如何使用幂等性"></a>如何使用幂等性</h5><p>开启参数<code>enable.idempotence</code>默认为<code>true</code>，<code>false</code>关闭。</p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><h5 id="Kafka事务原理"><a href="#Kafka事务原理" class="headerlink" title="Kafka事务原理"></a>Kafka事务原理</h5><div class="note warning modern"><p>开启事务，必须开启幂等性。</p>
</div>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-01-34-07.png" alt="Kafka事务原理"></p>
<div class="note info modern"><p>幂等性不能跨多个分区运作，而事务可以弥补这个缺陷。<br>事务可以保证对多个分区写入操作的原子性（要么全部成功，要么全部失败）。<br>从生产者角度，通过事务，Kafka可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复</p>
</div>
<h5 id="如何开启事务"><a href="#如何开启事务" class="headerlink" title="如何开启事务"></a>如何开启事务</h5><p><strong>Kafka 的事务一共有如下5 个API</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="生产经验——数据有序"><a href="#生产经验——数据有序" class="headerlink" title="生产经验——数据有序"></a>生产经验——数据有序</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-01-36-40.png" alt="数据有序"></p>
<h3 id="生产经验——数据乱序"><a href="#生产经验——数据乱序" class="headerlink" title="生产经验——数据乱序"></a>生产经验——数据乱序</h3><ol>
<li>kafka在1.x版本之前保证数据单分区有序，条件如下：<br><code>max.in.flight.requests.per.connection=1</code>（不需要考虑是否开启幂等性）</li>
<li>kafka在1.x及以后版本保证数据单分区有序，条件如下：<ul>
<li>未开启幂等性<br><code>max.in.flight.requests.per.connection</code>需要设置为1</li>
<li>开启幂等性<br><code>max.in.flight.requests.per.connection</code>需要设置小于等于5<br>原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-12-01-37-43.png" alt="原因说明"></li>
</ul>
</li>
</ol>
<h2 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h2><h2 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h2><h3 id="Kafka消费方式"><a href="#Kafka消费方式" class="headerlink" title="Kafka消费方式"></a>Kafka消费方式</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-23-58.png" alt="Kafka消费方式"></p>
<ul>
<li>pull（拉）模式：consumer采用从broker中主动拉取数据。<strong>Kafka采用这种方式</strong>。</li>
<li>push（推）模式：Kafka没有采用这种方式，因为由broker决定消息发送速率，很难适应所有消费者的消费速率。例如推送的速度是50m/s，Consumer1、Consumer2就来不及处理消息。</li>
</ul>
<div class="note info modern"><p>pull模式不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据。</p>
</div>
<h3 id="Kafka消费者工作流程"><a href="#Kafka消费者工作流程" class="headerlink" title="Kafka消费者工作流程"></a>Kafka消费者工作流程</h3><h4 id="消费者总体工作流程"><a href="#消费者总体工作流程" class="headerlink" title="消费者总体工作流程"></a>消费者总体工作流程</h4><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-26-08.png" alt="消费者总体工作流程"></p>
<h4 id="消费者组原理"><a href="#消费者组原理" class="headerlink" title="消费者组原理"></a>消费者组原理</h4><p>Consumer Group（CG）：消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。</p>
<ul>
<li><strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费</strong>。</li>
<li>如果向消费组中添加更多的消费者，<strong>超过主题分区数量，则有一部分消费者就会闲置，不会接收任何消息</strong>。</li>
<li><strong>消费者组之间互不影响</strong>。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-29-34.png" alt="消费者组"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-32-26.png" alt="消费者组"></p>
<p>coordinator：辅助实现消费者组的初始化和分区的分配。<br>coordinator节点选择 = <strong>groupid的hashcode值 % 50（ __consumer_offsets的分区数量）</strong><br>例如： groupid的hashcode值 = 1，1% 50 = 1，那么 __consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-36-34.png" alt="消费者组初始化流程"></p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-10-40-49.png" alt="消费者组详细消费流程"></p>
<h4 id="消费者重要参数"><a href="#消费者重要参数" class="headerlink" title="消费者重要参数"></a>消费者重要参数</h4><div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bootstrap.servers</code></td>
<td>向Kafka集群建立初始连接用到的host/port列表</td>
</tr>
<tr>
<td><code>key.deserializer</code><br><code>value.deserializer</code></td>
<td>指定接收消息的 key 和 value 的反序列化类型，一定要写全类名</td>
</tr>
<tr>
<td><code>group.id</code></td>
<td>标记消费者所属的消费者组</td>
</tr>
<tr>
<td><code>enable.auto.commit</code></td>
<td><strong>默认值为true</strong>，消费者会自动周期性地向服务器提交偏移量</td>
</tr>
<tr>
<td><code>auto.commit.interval.ms</code></td>
<td>如果设置了enable.auto.commit的值为 true， 则该值定义了消费者偏移量向 Kafka 提交的频率，默认<strong>5s</strong></td>
</tr>
<tr>
<td><code>auto.offset.reset</code></td>
<td>当Kafka中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？<br>earliest：自动重置偏移量到最早的偏移量<br><strong>latest：默认，自动重置偏移量为最新的偏移量</strong><br>none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常<br>anything：向消费者抛异常</td>
</tr>
<tr>
<td><code>offsets.topic.num.partitions</code></td>
<td><code>__consumer_offsets</code>的分区数，<strong>默认是50个分区</strong></td>
</tr>
<tr>
<td><code>heartbeat.interval.ms</code></td>
<td>Kafka 消费者和 coordinator 之间的心跳时间，默认3s。该条目的值必须小于<code>session.timeout.ms</code> ，也不应该高于<code>session.timeout.ms</code>的1/3。</td>
</tr>
<tr>
<td><code>session.timeout.ms</code></td>
<td>Kafka 消费者和 coordinator 之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡</td>
</tr>
<tr>
<td><code>max.poll.interval.ms</code></td>
<td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该消费者被移除，消费者组执行再平衡</td>
</tr>
<tr>
<td><code>fetch.min.bytes</code></td>
<td><strong>默认1个字节</strong>。消费者获取服务器端一批消息最小的字节数</td>
</tr>
<tr>
<td><code>fetch.max.wait.ms</code></td>
<td><strong>默认500ms</strong>。如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据</td>
</tr>
<tr>
<td><code>fetch.max.bytes</code></td>
<td><strong>默认Default: 52428800（50 m）</strong>。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对 最 大 值 。 一 批 次 的 大 小 受 <strong>message.max.bytes （ broker config）</strong> or <strong>max.message.bytes （topic config）</strong>影响</td>
</tr>
<tr>
<td><code>max.poll.records</code></td>
<td>一次 poll 拉取数据返回消息的最大条数，<strong>默认是500条</strong></td>
</tr>
</tbody>
</table>
</div>
<h3 id="消费者API"><a href="#消费者API" class="headerlink" title="消费者API"></a>消费者API</h3><h4 id="独立消费者案例（订阅主题）"><a href="#独立消费者案例（订阅主题）" class="headerlink" title="独立消费者案例（订阅主题）"></a>独立消费者案例（订阅主题）</h4><p><strong>需求：</strong>创建一个独立消费者，消费first主题中数据。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-16-22-39.png" alt="独立消费者（订阅主题）"></p>
<div class="note warning modern"><p>在消费者API代码中必须配置消费者组id。命令行启动消费者不填写消费者组id会被自动填写随机的消费者组id。</p>
</div>
<blockquote><p>代码编写</p>
</blockquote>
<p>创建包名：<code>com.hsq.kafka.consumer</code><br><figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsq.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">    <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">    <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">    properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hsq01:9092&quot;</span>);</span><br><span class="line">    <span class="comment">// 配置序列化 必须</span></span><br><span class="line">    properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">    properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">    <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">    properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">    <span class="comment">// 创建消费者对象</span></span><br><span class="line">    KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class="line">    <span class="comment">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class="line">    ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">    kafkaConsumer.subscribe(topics);</span><br><span class="line">    <span class="comment">// 拉取数据打印</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">        ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">        <span class="comment">// 打印消费到的数据</span></span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">            System.out.println(consumerRecord);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote><p>测试</p>
</blockquote>
<p>1.在IDEA中执行消费者程序。<br>2.在Kafka集群控制台，创建Kafka生产者，并输入数据。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --bootstrap-server hsq01:9092 --topic first</span><br></pre></td></tr></table></figure><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-16-48-10.png" alt="创建Kafka生产者"><br>3.在IDEA控制台观察接收到的数据。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-16-49-16.png" alt="收到数据"></p>
<h4 id="独立消费者案例（订阅分区）"><a href="#独立消费者案例（订阅分区）" class="headerlink" title="独立消费者案例（订阅分区）"></a>独立消费者案例（订阅分区）</h4><p><strong>需求：</strong>创建一个独立消费者，消费<code>first</code>主题<code>0</code>号分区的数据。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-16-51-07.png" alt="独立消费者案例（订阅分区）"></p>
<blockquote><p>代码实现</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 消费某个主题的某个分区数据</span></span><br><span class="line">        ArrayList&lt;TopicPartition&gt; topicPartitions = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topicPartitions.add(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;first&quot;</span>, <span class="number">0</span>));</span><br><span class="line">        kafkaConsumer.assign(topicPartitions);</span><br><span class="line">        <span class="comment">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class="line"><span class="comment">//        ArrayList&lt;String&gt; topics = new ArrayList&lt;&gt;();</span></span><br><span class="line"><span class="comment">//        topics.add(&quot;first&quot;);</span></span><br><span class="line"><span class="comment">//        kafkaConsumer.subscribe(topics);</span></span><br></pre></td></tr></table></figure>
<blockquote><p>测试</p>
</blockquote>
<p>1.在IDEA中执行消费者程序。<br>2.在 IDEA 中执行生产者程序<code>CustomProducerCallbackPartitions()</code>在控制台观察生成几个0号分区的数据和几个其他区数据。<br>3.在 IDEA 控制台，观察接收到的数据，只能消费到 0 号分区数据表示正确。</p>
<h4 id="消费者组案例"><a href="#消费者组案例" class="headerlink" title="消费者组案例"></a>消费者组案例</h4><p><strong>需求：</strong>测试同一个主题的分区数据只能由一个消费者组中的一个消费。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-17-31-27.png" alt="消费者组案例"></p>
<p>复制一份基础消费者(CustomConsumer)的代码(CustomConsumer1)，在 IDEA 中同时启动，即可启动同一个消费者组中的两个消费者。<br>启动代码中的生产者发送消息(3个不同分区)，在 IDEA 控制台即可看到两个消费者在消费不同分区的数据<br>如果重新发送到一个全新的主题中，由于默认创建的主题分区数为 1，可以看到只能有一个消费者消费到数据。</p>
<h3 id="生产经验——分区的分配以及再平衡"><a href="#生产经验——分区的分配以及再平衡" class="headerlink" title="生产经验——分区的分配以及再平衡"></a>生产经验——分区的分配以及再平衡</h3><ol>
<li>一个consumer group中有多个consumer组成，一个 topic有多个partition组成，现在的问题是，<strong>到底由哪个consumer来消费哪个partition的数据</strong>。</li>
<li>Kafka有四种主流的分区分配策略： <code>Range</code>、<code>RoundRobin</code>、<code>Sticky</code>、<code>CooperativeSticky</code>。<br>可以通过配置参数<code>partition.assignment.strategy</code>，修改分区的分配策略。默认策略是<code>Range + CooperativeSticky</code>。Kafka可以同时使用多个分区分配策略。</li>
</ol>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-21-19-36.png" alt="分区的分配"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>heartbeat.interval.ms</code></td>
<td>Kafka 消费者和 coordinator 之间的心跳时间，<strong>默认3s</strong>。该条目的值必须小于<code>session.timeout.ms</code>，也不应该高于<code>session.timeout.ms</code>的1/3</td>
</tr>
<tr>
<td><code>session.timeout.ms</code></td>
<td>Kafka 消费者和 coordinator 之间连接超时时间，<strong>默认45s</strong>。超过该值，该消费者被移除，消费者组执行再平衡</td>
</tr>
<tr>
<td><code>max.poll.interval.ms</code></td>
<td>消费者处理消息的最大时长，<strong>默认是5分钟</strong>。超过该值，该消费者被移除，消费者组执行再平衡</td>
</tr>
<tr>
<td><code>partition.assignment.strategy</code></td>
<td>消费者分分配策略，默认策略是<code>Range + CooperativeSticky</code>。Kafka 可以同时使用多个分区分配策略。可以选择的策略包括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Range以及再平衡"><a href="#Range以及再平衡" class="headerlink" title="Range以及再平衡"></a>Range以及再平衡</h4><blockquote><p>Range分区策略原理</p>
</blockquote>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-21-30-11.png" alt="分区分配策略之Range"></p>
<ul>
<li><p>Range 是对每个 topic 而言的。<br>首先对同一个 topic 里面的<strong>分区按照序号进行排序</strong>，并对<strong>消费者按照字母顺序进行排序</strong>。<br>假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。</p>
</li>
<li><p>通过<strong>partitions数/consumer数</strong>来决定每个消费者应该消费几个分区。<strong>如果除不尽，那么前面几个消费者将会多消费1个分区。</strong><br>例如，7/3 = 2 余 1 ，除不尽，那么消费者C0便会多消费一个分区。 8/3=2余2，除不尽，那么C0和C1分别多消费一个。</p>
</li>
<li><p><strong>注意</strong>：如果只是针对1个topic而言，C0消费者多消费1个分区影响不是很大。但是如果有N多个topic，那么针对每个topic，消费者C0都将多消费1个分区，topic越多，C0消费的分区会比其他消费者明显多消费N个分区。<br><strong>容易产生数据倾斜！</strong></p>
</li>
</ul>
<blockquote><p>Range分区分配策略案例</p>
</blockquote>
<p>1.修改主题<code>first</code>为7个分区<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hsq01:9092 --alter --topic first --partitions 7</span><br></pre></td></tr></table></figure></p>
<p>2.复制<code>CustomConsumer</code>类，这样可以由三个消费者<code>CustomConsumer</code>、<code>CustomConsumer1</code>、<code>CustomConsumer2</code> 组成消费者组，组名都为“test”，同时启动 3 个消费者。</p>
<p>3.启动<code>CustomProducerCallbackPartitions</code>生产者，发送500条消息，随机发送到不同的分区。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">500</span>;i++)&#123;</span><br><span class="line marked">    <span class="type">int</span> num=(<span class="type">int</span>)(Math.random()*<span class="number">7</span>);</span><br><span class="line">    <span class="comment">// 指定数据发送到随机分区</span></span><br><span class="line marked">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topicName,num,<span class="string">&quot;&quot;</span>,<span class="string">&quot;test\t&quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e==<span class="literal">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;主题：&quot;</span>+recordMetadata.topic()+<span class="string">&quot;分区：&quot;</span>+recordMetadata.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line marked">    Thread.sleep(<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>4.观察3个消费者分别消费哪些分区的数据。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-05-07.png" alt="消费0，1，2"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-06-09.png" alt="消费3，4"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-05-50.png" alt="消费5，6"></p>
<blockquote><p>Range分区分配再平衡案例</p>
</blockquote>
<p><strong>1.停止掉 0 号消费者，快速重新发送消息观看结果（45s以内，越快越好）。</strong><br>2号消费者：消费 3、4 号分区数据。<br>1号消费者：消费 5、6 号分区数据。<br>0号消费者的任务会<strong>整体被分配</strong>到 1 号消费者或者 2 号消费者。</p>
<div class="note info modern"><p>0号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
</div>
<p><strong>2.再次重新发送消息观看结果（45s 以后）。</strong><br>1号消费者：消费 0、1、2、3 号分区数据。<br>2号消费者：消费 4、5、6 号分区数据。</p>
<div class="note info modern"><p>消费者 0 已经被踢出消费者组，所以重新按照 range 方式分配</p>
</div>
<h4 id="RoundRobin以及再平衡"><a href="#RoundRobin以及再平衡" class="headerlink" title="RoundRobin以及再平衡"></a>RoundRobin以及再平衡</h4><blockquote><p>RoundRobin分区策略原理</p>
</blockquote>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-18-04.png" alt="分区分配策略之RoundRobin"></p>
<ul>
<li>RoundRobin 针对集群中<strong>所有Topic而言</strong>。</li>
<li>RoundRobin 轮询分区策略，是<strong>把所有的partition和所有的consumer都列出来</strong>，然后<strong>按照hashcode进行排序</strong>，最后通过<strong>轮询算法</strong>来分配partition 给到各个消费者。</li>
</ul>
<blockquote><p>RoundRobin分区分配策略案例</p>
</blockquote>
<p>1.依次在<code>CustomConsumer</code>、<code>CustomConsumer1</code>、<code>CustomConsumer2</code> 三个消费者代码中修改分区分配策略为<strong>RoundRobin</strong>，同时消费者组id改为<code>test1</code>。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test1&quot;</span>);</span><br><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;</span>);</span><br></pre></td></tr></table></figure></p>
<p>2.重启 3 个消费者，重复发送消息的步骤，观察分区结果。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-27-51.png" alt="消费0，3，6"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-28-20.png" alt="消费1，4"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-22-29-06.png" alt="消费2，5"></p>
<blockquote><p>RoundRobin分区分配再平衡案例</p>
</blockquote>
<p><strong>1.停止掉0号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</strong><br>1 号消费者：消费 1、4 号分区数据<br>2 号消费者：消费 2、5 号分区数据<br>0 号消费者的任务会<strong>按照 RoundRobin 的方式，把数据轮询分成 <code>0 、6</code> 和 <code>3</code> 号分区数据，分别</strong>由 1 号消费者或者 2 号消费者消费。</p>
<div class="note info modern"><p>0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
</div>
<p><strong>2.再次重新发送消息观看结果（45s 以后）。</strong><br>1 号消费者：消费 0、2、4、6 号分区数据<br>2 号消费者：消费 1、3、5 号分区数据</p>
<div class="note info modern"><p>消费者 0 已经被踢出消费者组，所以重新按照 RoundRobin 方式分配</p>
</div>
<h4 id="Sticky以及再平衡"><a href="#Sticky以及再平衡" class="headerlink" title="Sticky以及再平衡"></a>Sticky以及再平衡</h4><p><strong>粘性分区定义：</strong>可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p>
<p>粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，<strong>首先会尽量均衡的放置分区到消费者上面</strong>，在出现同一消费者组内消费者出现问题的时候，会<strong>尽量保持原有分配的分区不变化</strong>。</p>
<blockquote><p>Sticky分区分配策略案例</p>
</blockquote>
<p>1.依次在<code>CustomConsumer</code>、<code>CustomConsumer1</code>、<code>CustomConsumer2</code> 三个消费者代码中修改分区分配策略为<strong>Sticky</strong>，同时消费者组id改为<code>test2</code>。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test2&quot;</span>);</span><br><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">ArrayList&lt;String&gt; strategies = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">strategies.add(<span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br><span class="line">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, strategies);</span><br></pre></td></tr></table></figure></p>
<p>2.重启 3 个消费者，重复发送消息的步骤，观察分区结果。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-23-42-10.png" alt="消费1，0"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-23-42-47.png" alt="消费4，5，6"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-23-43-15.png" alt="消费2，3"></p>
<div class="note warning modern"><p>有点像随机的Range分区分配策略，但是是均匀分配，哪个消费者具体消费哪个分区不确定，这里仅仅是一次实验结果</p>
</div>
<blockquote><p>Sticky分区分配再平衡案例</p>
</blockquote>
<p><strong>1.停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</strong><br>1 号消费者：消费 4、5、6 号分区数据。<br>2 号消费者：消费 2、3 号分区数据。<br>0 号消费者的任务会<strong>按照粘性规则，尽可能均衡的随机分成 0 和 1 号分区数据，分别由</strong> 1 号消费者或者 2 号消费者消费。</p>
<div class="note info modern"><p>0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
</div>
<p><strong>2.再次重新发送消息观看结果（45s 以后）。</strong><br>1 号消费者：消费 4、5、6、1 号分区数据。<br>2 号消费者：消费 2、3、0 号分区数据。</p>
<div class="note info modern"><p>消费者 0 已经被踢出消费者组，所以重新按照粘性方式分配。</p>
</div>
<h3 id="offset位移"><a href="#offset位移" class="headerlink" title="offset位移"></a>offset位移</h3><h4 id="offset的默认维护位置"><a href="#offset的默认维护位置" class="headerlink" title="offset的默认维护位置"></a>offset的默认维护位置</h4><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-15-23-56-53.png" alt="offset的默认维护位置"></p>
<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+分区号，value 就是当前 offset 的值。每隔一段时间，kafka 内部会对这个 topic 进行compact，也就是每个 <code>group.id+topic+分区号</code> 就保留最新数据。</p>
<mark class="hl-label pink">消费offset案例</mark> 
<p>0) <strong>思想：</strong><code>__consumer_offsets</code> 为 Kafka 中的 topic，那就可以通过消费者进行消费。</p>
<p>1) 官网中<code>exclude.internal.topics</code>默认为<code>true</code>,是这样描述的(It is always possible to explicitly subscribe to an internal topic.)也就是<strong>始终可以显式订阅内部主题。</strong></p>
<p>2) 查看消费者消费主题<code>__consumer_offsets</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server hsq01:9092 --consumer.config config/consumer.properties --formatter&quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</span><br></pre></td></tr></table></figure><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-00-35-28.png" alt="可以查看到之前的消费情况"></p>
<h4 id="自动提交offset"><a href="#自动提交offset" class="headerlink" title="自动提交offset"></a>自动提交offset</h4><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。<br>自动提交offset的相关参数：</p>
<ul>
<li><code>enable.auto.commit</code>：是否开启自动提交offset功能消，费者会自动周期性地向服务器提交偏移量，默认是true</li>
<li><code>auto.commit.interval.ms</code>：定义了消费者偏移量向Kafka提交的频率，默认是5s</li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-00-40-30.png" alt="自动提交offset"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 是否自动提交 offset</span></span><br><span class="line">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">true</span>);</span><br><span class="line"><span class="comment">// 提交 offset 的时间周期 1 000 ms ，默认 5s</span></span><br><span class="line">properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br></pre></td></tr></table></figure>
<h4 id="手动提交offset"><a href="#手动提交offset" class="headerlink" title="手动提交offset"></a>手动提交offset</h4><p>虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。<br>手动提交offset的方法有两种：分别是<strong>commitSync（同步提交）</strong>和<strong>commitAsync（异步提交）</strong>。两者的相同点是，都会<strong>将本次提交的一批数据最高的偏移量提交</strong>；不同点是，<strong>同步提交阻塞当前线程</strong>，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而<strong>异步提交则没有失败重试机制，故有可能提交失败</strong>。</p>
<ul>
<li>commitSync（同步提交）：<strong>必须等待offset提交完毕，再去消费下一批数据</strong></li>
<li>commitAsync（异步提交） ：<strong>发送完提交offset请求后，就开始消费下一批数据了</strong></li>
</ul>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-00-51-51.png" alt="手动提交offset"></p>
<div class="tabs" id="customconsumerbyhand"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="customconsumerbyhand-1">commitSync（同步提交）</button><button type="button" class="tab " data-href="customconsumerbyhand-2">commitAsync（异步提交）</button></ul><div class="tab-contents"><div class="tab-item-content active" id="customconsumerbyhand-1"><p>由于同步提交offset 有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 是否自动提交 offset</span></span><br><span class="line marked">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 拉取数据打印</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"><span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">    ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">    <span class="comment">// 打印消费到的数据</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">        System.out.println(consumerRecord);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 同步提交 offset</span></span><br><span class="line marked">    kafkaConsumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="tab-item-content" id="customconsumerbyhand-2"><p>虽然同步提交offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 是否自动提交 offset</span></span><br><span class="line marked">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 拉取数据打印</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"><span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">    ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">    <span class="comment">// 打印消费到的数据</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">        System.out.println(consumerRecord);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 同步提交 offset</span></span><br><span class="line marked">    kafkaConsumer.commitAsync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div>
<h4 id="指定Offset消费"><a href="#指定Offset消费" class="headerlink" title="指定Offset消费"></a>指定Offset消费</h4><p><code>auto.offset.reset</code> = <code>earliest | latest | none</code> <strong>默认是 latest</strong>。<br>当 Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办？</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-14-09-10.png" alt="偏移量"></p>
<ol>
<li><code>earliest</code>：自动将偏移量重置为最早的偏移量，<code>--from-beginning</code>。</li>
<li><code>latest</code>（默认值）：自动将偏移量重置为最新偏移量。</li>
<li><code>none</code>：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</li>
<li>任意指定 offset 位移开始消费</li>
</ol>
<figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsq.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerSeek</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hsq01:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 配置序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;demo&quot;</span>);</span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line marked">        Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line marked">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line marked">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line marked">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line marked">            assignment = kafkaConsumer.assignment();</span><br><span class="line marked">        &#125;</span><br><span class="line marked">        <span class="comment">// 遍历所有分区，并指定 offset 从 700 的位置开始消费</span></span><br><span class="line marked">        <span class="keyword">for</span> (TopicPartition tp: assignment) &#123;</span><br><span class="line marked">            kafkaConsumer.seek(tp, <span class="number">700</span>);</span><br><span class="line marked">        &#125;</span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div class="note warning modern"><p>每次执行完，需要修改消费者组名</p>
</div>
<h4 id="指定时间消费"><a href="#指定时间消费" class="headerlink" title="指定时间消费"></a>指定时间消费</h4><p><strong>需求</strong>：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据，怎么处理？</p>
<figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsq.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerForTime</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hsq01:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 配置序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;demo1&quot;</span>);</span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        <span class="comment">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line marked">        Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line marked">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line marked">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line marked">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line marked">            assignment = kafkaConsumer.assignment();</span><br><span class="line marked">        &#125;</span><br><span class="line marked">        HashMap&lt;TopicPartition, Long&gt; timestampToSearch = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line marked">        <span class="comment">// 封装集合存储，每个分区对应一天前的数据</span></span><br><span class="line marked">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line marked">            timestampToSearch.put(topicPartition, System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>);</span><br><span class="line marked">        &#125;</span><br><span class="line marked">        <span class="comment">// 获取从 1 天前开始消费的每个分区的 offset</span></span><br><span class="line marked">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = kafkaConsumer.offsetsForTimes(timestampToSearch);</span><br><span class="line marked">        <span class="comment">// 遍历每个分区，对每个分区设置消费时间。</span></span><br><span class="line marked">        <span class="keyword">for</span> (TopicPartition topicPartition: assignment) &#123;</span><br><span class="line marked">            <span class="type">OffsetAndTimestamp</span> <span class="variable">offsetAndTimestamp</span> <span class="operator">=</span> offsets.get(topicPartition);</span><br><span class="line marked">            <span class="comment">// 根据时间指定开始消费的位置</span></span><br><span class="line marked">            <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>) &#123;</span><br><span class="line marked">                kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());</span><br><span class="line marked">            &#125;</span><br><span class="line marked">        &#125;</span><br><span class="line">        <span class="comment">// 3.（消费）拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="漏消费和重复消费"><a href="#漏消费和重复消费" class="headerlink" title="漏消费和重复消费"></a>漏消费和重复消费</h4><p><strong>重复消费：</strong>已经消费了数据，但是offset没提交。<br><strong>漏消费：</strong>先提交offset后消费，有可能会造成数据的漏消费。</p>
<div class="tabs" id="consumerproblem"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="consumerproblem-1">重复消费</button><button type="button" class="tab " data-href="consumerproblem-2">漏消费</button></ul><div class="tab-contents"><div class="tab-item-content active" id="consumerproblem-1"><p>自动提交offset引起。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-14-43-23.png" alt="重复消费"></p></div><div class="tab-item-content" id="consumerproblem-2"><p>设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-14-44-29.png" alt="漏消费"></p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div>
<p>思考：怎么能做到既不漏消费也不重复消费呢？详看消费者事务</p>
<h3 id="生产经验——消费者事务"><a href="#生产经验——消费者事务" class="headerlink" title="生产经验——消费者事务"></a>生产经验——消费者事务</h3><p>如果想完成Consumer端的精准一次性消费，那么需要<strong>Kafka消费端将消费过程和提交offset过程做原子绑定</strong> 。此时我们需要将 Kafka 的 offset 保存到支持事务的自定义介质（比如MySQL）。<br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-14-47-35.png" alt="消费者事务"></p>
<h3 id="生产经验——数据积压（消费者如何提高吞吐量）"><a href="#生产经验——数据积压（消费者如何提高吞吐量）" class="headerlink" title="生产经验——数据积压（消费者如何提高吞吐量）"></a>生产经验——数据积压（消费者如何提高吞吐量）</h3><ol>
<li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，<strong>消费者数=分区数</strong>。（两者缺一不可）</li>
<li>如果是下游的数据处理不及时：<strong>提高每批次拉取的数量</strong>。批次拉取数据过少（拉取数据/处理时间 &lt; 生产速度），使处理的数据小于生产的数据，也会造成数据积压。</li>
</ol>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-14-50-33.png" alt="消费者如何提高吞吐量"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fetch.max.bytes</code></td>
<td>默认<strong>Default: 52428800（50 m）</strong>。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受<code>message.max.bytes</code>（broker config）or <code>max.message.bytes</code>（topic config）影响</td>
</tr>
<tr>
<td><code>max.poll.records</code></td>
<td>一次poll 拉取数据返回消息的最大条数，<strong>默认是 500 条</strong></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Kafka-Eagle监控"><a href="#Kafka-Eagle监控" class="headerlink" title="Kafka-Eagle监控"></a>Kafka-Eagle监控</h2><p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。</p>
<h3 id="MySQL环境准备"><a href="#MySQL环境准备" class="headerlink" title="MySQL环境准备"></a>MySQL环境准备</h3><p>Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。</p>
<h3 id="Kafka环境准备"><a href="#Kafka环境准备" class="headerlink" title="Kafka环境准备"></a>Kafka环境准备</h3><p>1.Kafka集群处于关闭状态</p>
<p>2.修改<code>$KAFKA_HOME/bin/kafka-server-start.sh</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi $KAFKA_HOME/bin/kafka-server-start.sh</span><br></pre></td></tr></table></figure></p>
<figure class="highlight sh"><figcaption><span>找到如下部分</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;x<span class="variable">$KAFKA_HEAP_OPTS</span>&quot;</span> = <span class="string">&quot;x&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">&quot;-Xmx1G -Xms1G&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>修改为</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then</span><br><span class="line">    export KAFKA_HEAP_OPTS=&quot;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;</span><br><span class="line">    export JMX_PORT=&quot;9999&quot;</span><br><span class="line">    #export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>3.分发到其他节点<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;2..3&#125;; <span class="keyword">do</span> scp -r /mysoft/kafka_2.12-3.4.0/bin/kafka-server-start.sh hsq0<span class="variable">$i</span>:/mysoft/kafka_2.12-3.4.0/bin/kafka-server-start.sh;<span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Kafka-Eagle安装"><a href="#Kafka-Eagle安装" class="headerlink" title="Kafka-Eagle安装"></a>Kafka-Eagle安装</h3><h4 id="下载Kafka-Eagle并解压"><a href="#下载Kafka-Eagle并解压" class="headerlink" title="下载Kafka-Eagle并解压"></a>下载Kafka-Eagle并解压</h4><p>从<a target="_blank" rel="noopener" href="https://www.kafka-eagle.org/">Kafka-Eagle</a>官网下载好安装包</p>
<p>版本：3.0.1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka-eagle-bin-3.0.1.tar.gz -C /mysoft/</span><br><span class="line">cd kafka-eagle-bin-3.0.1/</span><br><span class="line">tar -zxvf efak-web-3.0.1-bin.tar.gz -C /mysoft/</span><br></pre></td></tr></table></figure>
<h4 id="配置Kafka-Eagle环境变量"><a href="#配置Kafka-Eagle环境变量" class="headerlink" title="配置Kafka-Eagle环境变量"></a>配置Kafka-Eagle环境变量</h4><figure class="highlight shell"><figcaption><span>vi /etc/profile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Kafka-Eagle enviroment variables</span></span><br><span class="line">export KE_HOME=/mysoft/efak-web-3.0.1/</span><br><span class="line">export PATH=$PATH:$KE_HOME/bin</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>使环境变量生效</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<h4 id="修改配置文件system-config-properties"><a href="#修改配置文件system-config-properties" class="headerlink" title="修改配置文件system-config.properties"></a>修改配置文件<code>system-config.properties</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $KE_HOME</span><br><span class="line">cd config/</span><br><span class="line">vi system-config.properties</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#multi zookeeper &amp; kafka cluster list</span></span><br><span class="line"><span class="comment">#Settings prefixed with &#x27;kafka.eagle.&#x27; will be deprecated, use &#x27;efak.&#x27;instead</span></span><br><span class="line"><span class="comment">#####################################</span></span><br><span class="line marked">efak.zk.cluster.alias=cluster1</span><br><span class="line marked">cluster1.zk.list=hsq01:2181,hsq02:2181,hsq03:2181/kafka</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#zookeeper enable acl</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster1.zk.acl.enable=<span class="literal">false</span></span><br><span class="line">cluster1.zk.acl.schema=digest</span><br><span class="line">cluster1.zk.acl.username=<span class="built_in">test</span></span><br><span class="line">cluster1.zk.acl.password=test123</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#broker size online list</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster1.efak.broker.size=20</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#zk client thread limit</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">kafka.zk.limit.size=32</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#EFAK webui port</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line marked">efak.webui.port=8048</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka jmx acl and ssl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster1.efak.jmx.acl=<span class="literal">false</span></span><br><span class="line marked">cluster1.efak.jmx.user=keadmin</span><br><span class="line">cluster1.efak.jmx.password=keadmin123</span><br><span class="line">cluster1.efak.jmx.ssl=<span class="literal">false</span></span><br><span class="line">cluster1.efak.jmx.truststore.location=/data/ssl/certificates/kafka.truststore</span><br><span class="line marked">cluster1.efak.jmx.truststore.password=ke123456</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka offset storage</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#offset 保存在 kafka</span></span><br><span class="line">cluster1.efak.offset.storage=kafka</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka jmx uri</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster1.efak.jmx.uri=service:jmx:rmi:///jndi/rmi://%s/jmxrmi</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka metrics, 15 days by default</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">efak.metrics.charts=<span class="literal">true</span></span><br><span class="line">efak.metrics.retain=15</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka sql topic records max</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">efak.sql.topic.records.max=5000</span><br><span class="line">efak.sql.topic.preview.records.max=10</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#delete kafka topic token</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">efak.topic.token=keadmin</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka sasl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster1.efak.sasl.enable=<span class="literal">false</span></span><br><span class="line">cluster1.efak.sasl.protocol=SASL_PLAINTEXT</span><br><span class="line">cluster1.efak.sasl.mechanism=SCRAM-SHA-256</span><br><span class="line">cluster1.efak.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=<span class="string">&quot;kafka&quot;</span> password=<span class="string">&quot;kafka-eagle&quot;</span>;</span><br><span class="line">cluster1.efak.sasl.client.id=</span><br><span class="line">cluster1.efak.blacklist.topics=</span><br><span class="line">cluster1.efak.sasl.cgroup.enable=<span class="literal">false</span></span><br><span class="line">cluster1.efak.sasl.cgroup.topics=</span><br><span class="line">cluster2.efak.sasl.enable=<span class="literal">false</span></span><br><span class="line">cluster2.efak.sasl.protocol=SASL_PLAINTEXT</span><br><span class="line">cluster2.efak.sasl.mechanism=PLAIN</span><br><span class="line">cluster2.efak.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=<span class="string">&quot;kafka&quot;</span> password=<span class="string">&quot;kafka-eagle&quot;</span>;</span><br><span class="line">cluster2.efak.sasl.client.id=</span><br><span class="line">cluster2.efak.blacklist.topics=</span><br><span class="line">cluster2.efak.sasl.cgroup.enable=<span class="literal">false</span></span><br><span class="line">cluster2.efak.sasl.cgroup.topics=</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka ssl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line">cluster3.efak.ssl.enable=<span class="literal">false</span></span><br><span class="line">cluster3.efak.ssl.protocol=SSL</span><br><span class="line">cluster3.efak.ssl.truststore.location=</span><br><span class="line">cluster3.efak.ssl.truststore.password=</span><br><span class="line">cluster3.efak.ssl.keystore.location=</span><br><span class="line">cluster3.efak.ssl.keystore.password=</span><br><span class="line">cluster3.efak.ssl.key.password=</span><br><span class="line">cluster3.efak.ssl.endpoint.identification.algorithm=https</span><br><span class="line">cluster3.efak.blacklist.topics=</span><br><span class="line">cluster3.efak.ssl.cgroup.enable=<span class="literal">false</span></span><br><span class="line">cluster3.efak.ssl.cgroup.topics=</span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka sqlite jdbc driver address</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#配置 mysql 连接</span></span><br><span class="line marked">efak.driver=com.mysql.jdbc.Driver</span><br><span class="line marked">efak.url=jdbc:mysql://hsq01:3306/ke?useUnicode=<span class="literal">true</span>&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line marked">efak.username=root</span><br><span class="line marked">efak.password=hadoop <span class="comment">#(mysql密码)</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#kafka mysql jdbc driver address</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#efak.driver=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="comment">#efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span><br><span class="line"><span class="comment">#efak.username=root</span></span><br><span class="line"><span class="comment">#efak.password=123456</span></span><br></pre></td></tr></table></figure>
<h4 id="启动Kafka-Eagle"><a href="#启动Kafka-Eagle" class="headerlink" title="启动Kafka-Eagle"></a>启动Kafka-Eagle</h4><div class="note warning modern"><p>启动之前需要先启动 <strong>Zookeeper集群</strong> 以及 <strong>Kafka集群</strong></p>
</div>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ke.sh start</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-16-30-03.png" alt="成功启动"></p>
<h4 id="停止Kafka-Eagle"><a href="#停止Kafka-Eagle" class="headerlink" title="停止Kafka-Eagle"></a>停止Kafka-Eagle</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ke.sh stop</span><br></pre></td></tr></table></figure>
<h3 id="Kafka-Eagle页面操作"><a href="#Kafka-Eagle页面操作" class="headerlink" title="Kafka-Eagle页面操作"></a>Kafka-Eagle页面操作</h3><h4 id="登录页面查看监控数据"><a href="#登录页面查看监控数据" class="headerlink" title="登录页面查看监控数据"></a>登录页面查看监控数据</h4><p>使用如下端口号进行查看<a target="_blank" rel="noopener" href="http://hsq01:8048">http://hsq01:8048</a><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-16-15-05.png" alt="登录"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-16-12-10.png" alt="http://hsq01:8048/tv"><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-16-14-19.png" alt="dashboard"></p>
<h2 id="Kafka-Kraft模式"><a href="#Kafka-Kraft模式" class="headerlink" title="Kafka-Kraft模式"></a>Kafka-Kraft模式</h2><h3 id="Kafka-Kraft架构"><a href="#Kafka-Kraft架构" class="headerlink" title="Kafka-Kraft架构"></a>Kafka-Kraft架构</h3><p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-08-40-00.png" alt="Kafka-Kraft架构"></p>
<p>左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由 controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。<br>这样做的好处有以下几个：</p>
<ul>
<li>Kafka 不再依赖外部框架，而是能够独立运行；</li>
<li>controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升；</li>
<li>由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制；</li>
<li>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强 controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</li>
</ul>
<h3 id="Kafka-Kraft集群部署"><a href="#Kafka-Kraft集群部署" class="headerlink" title="Kafka-Kraft集群部署"></a>Kafka-Kraft集群部署</h3><p><strong>1.再次解压一份 kafka 安装包</strong><br><div class="note warning modern"><p>第一次解压kafka安装包没有更改目录名的需要先更改(<code>mv kafka_2.12-3.4.0/ tempname</code>)，然后（<strong>第二次解压重名后</strong>）再改回去(<code>mv tempname/ kafka_2.12-3.4.0</code>)，不然会覆盖之前kafka目录，需要特别注意！！！</p>
</div></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.12-3.4.0.tgz -C /mysoft/</span><br></pre></td></tr></table></figure>
<p><strong>2.重命名为 <code>kafka2</code></strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /mysoft/</span><br><span class="line">mv kafka_2.12-3.4.0/ kafka2</span><br></pre></td></tr></table></figure></p>
<p><strong>3.配置 <code>server.properties</code></strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /mysoft/kafka2/config/kraft/server.properties</span><br></pre></td></tr></table></figure></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功能）</span></span><br><span class="line marked">process.roles=broker, controller</span><br><span class="line"><span class="comment">#节点 ID</span></span><br><span class="line marked">node.id=1</span><br><span class="line"><span class="comment">#全 Controller 列表</span></span><br><span class="line marked">controller.quorum.voters=1@hsq01:9093,2@hsq02:9093,3@hsq03:9093</span><br><span class="line"><span class="comment">#不同服务器绑定的端口</span></span><br><span class="line">listeners=PLAINTEXT://:9092,CONTROLLER://:9093</span><br><span class="line"><span class="comment">#broker 服务协议别名</span></span><br><span class="line">inter.broker.listener.name=PLAINTEXT</span><br><span class="line"><span class="comment">#broker 对外暴露的地址</span></span><br><span class="line marked">advertised.Listeners=PLAINTEXT://hsq01:9092</span><br><span class="line"><span class="comment">#controller 服务协议别名</span></span><br><span class="line">controller.listener.names=CONTROLLER</span><br><span class="line"><span class="comment">#协议别名到安全协议的映射</span></span><br><span class="line">listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span><br><span class="line"><span class="comment">#kafka 数据存储目录</span></span><br><span class="line marked">log.dirs=/mysoft/kafka2/data</span><br></pre></td></tr></table></figure>
<p><strong>4.分发<code>kafka2</code></strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in &#123;2..3&#125;; do scp -r /mysoft/kafka2/ hsq0$i:/mysoft/;done</span><br></pre></td></tr></table></figure></p>
<p><strong>5.修改另外两台虚拟机/kraft/目录下<code>server.properties</code>文件</strong></p>
<ul>
<li>02虚拟机<code>node.id=2</code>(值需要和<code>controller.quorum.voters</code>对应)</li>
<li>03虚拟机<code>node.id=3</code></li>
<li>修改相应的<code>advertised.Listeners</code>地址</li>
</ul>
<p><strong>6.初始化集群数据目录</strong><br>①首先生成存储目录唯一ID。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /mysoft/kafka2/</span><br><span class="line">bin/kafka-storage.sh random-uuid</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生成的ID</span></span><br><span class="line">PGJfeKfaSC62jnDsnFV6VQ</span><br></pre></td></tr></table></figure></p>
<p>②用该ID格式化kafka存储目录（<strong>三台节点</strong>）。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-storage.sh format -t PGJfeKfaSC62jnDsnFV6VQ -c /mysoft/kafka2/config/kraft/server.properties</span><br></pre></td></tr></table></figure><br><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-09-41-56.png" alt="用该ID格式化kafka存储目录"></p>
<p><strong>7.启动kafka集群（三台节点）</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh -daemon config/kraft/server.properties</span><br></pre></td></tr></table></figure></p>
<p><strong>8.停止kafka集群</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure></p>
<h3 id="Kafka-Kraft集群启动停止脚本"><a href="#Kafka-Kraft集群启动停止脚本" class="headerlink" title="Kafka-Kraft集群启动停止脚本"></a>Kafka-Kraft集群启动停止脚本</h3><p><strong>(1) 在虚拟机<code>hsq01</code>的目录<code>/usr/local/bin/</code>下新建<code>kf2.sh</code>脚本文件</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/bin/kf2.sh</span><br></pre></td></tr></table></figure></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hsq01 hsq02 hsq03</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        tput setaf 5</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;============ start <span class="variable">$i</span> Kafka-Kraft集群 ============&quot;</span></span><br><span class="line">        tput setaf 9</span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;source /etc/profile ; /mysoft/kafka2/bin/kafka-server-start.sh -daemon /mysoft/kafka2/config/kraft/server.properties&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hsq01 hsq02 hsq03</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        tput setaf 1</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;============ stop <span class="variable">$i</span> Kafka-Kraft集群 ============&quot;</span></span><br><span class="line">        tput setaf 9</span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;source /etc/profile ; /mysoft/kafka2/bin/kafka-server-stop.sh&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>
<p><strong>(2)为<code>kf2.sh</code>脚本添加执行权限</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/bin/</span><br><span class="line">chmod u+x kf2.sh</span><br></pre></td></tr></table></figure></p>
<p><strong>(3)启动集群命令</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kf2.sh start</span><br></pre></td></tr></table></figure></p>
<p><strong>(4)关闭集群命令</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kf2.sh stop</span><br></pre></td></tr></table></figure></p>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/05/08/kafka3-4-0/2023-05-16-10-34-51.png" alt="启动与关闭集群"></p>
<div class="note danger modern"><p>（因为之前配置过kafka环境变量，指令易冲突，需要特别注意，注意执行<code>cd /mysoft/kafka2</code>再使用<code>bin/</code>+指令）两种模式都部署就容易出现问题，所以两种模式部署一种即可</p>
</div>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.huangshiqing.website">Shiqing Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.huangshiqing.website/2023/05/08/kafka3-4-0/">https://www.huangshiqing.website/2023/05/08/kafka3-4-0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.huangshiqing.website" target="_blank">Ofra Serendipity</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/Kafka/">Kafka</a></div><div class="post_share"><div class="social-share" data-image="https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/27/zookeeper3-8-1/" title="Zookeeper部署"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/642156eda682492fcc8b5b4e.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Zookeeper部署</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/09/java-home/" title="Java环境变量配置（多版本）"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic2.imgdb.cn/item/645b35d50d2dde5777454474.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java环境变量配置（多版本）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/11/12/HadoopBase/" title="Hadoop 生态"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-12</div><div class="title">Hadoop 生态</div></div></a></div><div><a href="/2022/10/25/HadoopClusterBuilding3-3-4/" title="Hadoop 3.3.4 集群搭建"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-25</div><div class="title">Hadoop 3.3.4 集群搭建</div></div></a></div><div><a href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-27</div><div class="title">Hadoop生态综合案例</div></div></a></div><div><a href="/2023/03/23/hadoop-java/" title="Java与Hadoop"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-23</div><div class="title">Java与Hadoop</div></div></a></div><div><a href="/2023/03/15/hbase-install/" title="HBase三种搭建方式"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64120132ebf10e5d533c6ba9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-15</div><div class="title">HBase三种搭建方式</div></div></a></div><div><a href="/2023/03/27/zookeeper3-8-1/" title="Zookeeper部署"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/642156eda682492fcc8b5b4e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-27</div><div class="title">Zookeeper部署</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="comment-switch"><span class="first-comment">Twikoo</span><span id="switch-btn"></span><span class="second-comment">Waline</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "/img/loading.gif" data-lazy-src="/img/avatar001.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Shiqing Huang</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cmwlvip"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cmwlvip" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://gitee.com/cmwlvip" target="_blank" title="Gitee"><i class="fab fa-git"></i></a><a class="social-icon" href="mailto:2689050828@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">Kafka 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.</span> <span class="toc-text">Kafka定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">1.2.</span> <span class="toc-text">消息队列</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.2.1.</span> <span class="toc-text">传统消息队列的应用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.2.2.</span> <span class="toc-text">消息队列的两种模式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">Kafka基础架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"><span class="toc-number">2.</span> <span class="toc-text">Kafka快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">2.1.</span> <span class="toc-text">安装部署</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">2.1.1.</span> <span class="toc-text">环境准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="toc-number">2.1.2.</span> <span class="toc-text">集群规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">2.1.3.</span> <span class="toc-text">集群部署</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Kafka"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">安装Kafka</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">配置环境变量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEserver-properties"><span class="toc-number">2.1.3.3.</span> <span class="toc-text">配置server.properties</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86Kafka%E7%9B%AE%E5%BD%95%E5%8F%8AKafka%E7%8E%AF%E5%A2%83%E5%88%86%E5%8F%91%E5%88%B0%E5%85%B6%E4%BB%96%E4%B8%BB%E6%9C%BA"><span class="toc-number">2.1.3.4.</span> <span class="toc-text">将Kafka目录及Kafka环境分发到其他主机</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%8F%A6%E5%A4%96%E4%B8%A4%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BAserver-properties%E6%96%87%E4%BB%B6"><span class="toc-number">2.1.3.5.</span> <span class="toc-text">修改另外两台虚拟机server.properties文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%94%9F%E6%95%88"><span class="toc-number">2.1.3.6.</span> <span class="toc-text">使环境变量生效</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">2.1.3.7.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%92%8C%E5%85%B3%E9%97%ADKafka%E9%9B%86%E7%BE%A4%E8%84%9A%E6%9C%AC"><span class="toc-number">2.1.3.8.</span> <span class="toc-text">启动和关闭Kafka集群脚本</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">2.2.</span> <span class="toc-text">Kafka命令行操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">2.2.1.</span> <span class="toc-text">主题命令行操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">2.2.2.</span> <span class="toc-text">生产者命令行操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">2.2.3.</span> <span class="toc-text">消费者命令行操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">3.</span> <span class="toc-text">Kafka生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">生产者消息发送流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.1.</span> <span class="toc-text">发送原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8"><span class="toc-number">3.1.2.</span> <span class="toc-text">生产者重要参数列表</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81API"><span class="toc-number">3.2.</span> <span class="toc-text">异步发送API</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="toc-number">3.2.1.</span> <span class="toc-text">普通异步发送</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%A6%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E7%9A%84%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="toc-number">3.2.2.</span> <span class="toc-text">带回调函数的异步发送</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81API"><span class="toc-number">3.3.</span> <span class="toc-text">同步发送API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%88%86%E5%8C%BA"><span class="toc-number">3.4.</span> <span class="toc-text">生产者分区</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84"><span class="toc-number">3.4.1.</span> <span class="toc-text">分区好处</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">3.4.2.</span> <span class="toc-text">生产者发送消息的分区策略</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E7%9A%84%E5%88%86%E5%8C%BA%E5%99%A8DefaultPartitioner"><span class="toc-number">3.4.2.1.</span> <span class="toc-text">默认的分区器DefaultPartitioner</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E5%99%A8"><span class="toc-number">3.4.3.</span> <span class="toc-text">自定义分区器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F"><span class="toc-number">3.5.</span> <span class="toc-text">生产经验——生产者如何提高吞吐量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">3.6.</span> <span class="toc-text">生产经验——数据可靠性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D"><span class="toc-number">3.7.</span> <span class="toc-text">生产经验——数据去重</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92%E8%AF%AD%E4%B9%89"><span class="toc-number">3.7.1.</span> <span class="toc-text">数据传递语义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">3.7.2.</span> <span class="toc-text">幂等性</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7%E5%8E%9F%E7%90%86"><span class="toc-number">3.7.2.1.</span> <span class="toc-text">幂等性原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">3.7.2.2.</span> <span class="toc-text">如何使用幂等性</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="toc-number">3.7.3.</span> <span class="toc-text">生产者事务</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Kafka%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86"><span class="toc-number">3.7.3.1.</span> <span class="toc-text">Kafka事务原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF%E4%BA%8B%E5%8A%A1"><span class="toc-number">3.7.3.2.</span> <span class="toc-text">如何开启事务</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F"><span class="toc-number">3.8.</span> <span class="toc-text">生产经验——数据有序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F"><span class="toc-number">3.9.</span> <span class="toc-text">生产经验——数据乱序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Broker"><span class="toc-number">4.</span> <span class="toc-text">Kafka Broker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">5.</span> <span class="toc-text">Kafka消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F"><span class="toc-number">5.1.</span> <span class="toc-text">Kafka消费方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">5.2.</span> <span class="toc-text">Kafka消费者工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">5.2.1.</span> <span class="toc-text">消费者总体工作流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%8E%9F%E7%90%86"><span class="toc-number">5.2.2.</span> <span class="toc-text">消费者组原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0"><span class="toc-number">5.2.3.</span> <span class="toc-text">消费者重要参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85API"><span class="toc-number">5.3.</span> <span class="toc-text">消费者API</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9%E8%80%85%E6%A1%88%E4%BE%8B%EF%BC%88%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98%EF%BC%89"><span class="toc-number">5.3.1.</span> <span class="toc-text">独立消费者案例（订阅主题）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9%E8%80%85%E6%A1%88%E4%BE%8B%EF%BC%88%E8%AE%A2%E9%98%85%E5%88%86%E5%8C%BA%EF%BC%89"><span class="toc-number">5.3.2.</span> <span class="toc-text">独立消费者案例（订阅分区）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%A1%88%E4%BE%8B"><span class="toc-number">5.3.3.</span> <span class="toc-text">消费者组案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">5.4.</span> <span class="toc-text">生产经验——分区的分配以及再平衡</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Range%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">5.4.1.</span> <span class="toc-text">Range以及再平衡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RoundRobin%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">5.4.2.</span> <span class="toc-text">RoundRobin以及再平衡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Sticky%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">5.4.3.</span> <span class="toc-text">Sticky以及再平衡</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#offset%E4%BD%8D%E7%A7%BB"><span class="toc-number">5.5.</span> <span class="toc-text">offset位移</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#offset%E7%9A%84%E9%BB%98%E8%AE%A4%E7%BB%B4%E6%8A%A4%E4%BD%8D%E7%BD%AE"><span class="toc-number">5.5.1.</span> <span class="toc-text">offset的默认维护位置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4offset"><span class="toc-number">5.5.2.</span> <span class="toc-text">自动提交offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4offset"><span class="toc-number">5.5.3.</span> <span class="toc-text">手动提交offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E5%AE%9AOffset%E6%B6%88%E8%B4%B9"><span class="toc-number">5.5.4.</span> <span class="toc-text">指定Offset消费</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E6%97%B6%E9%97%B4%E6%B6%88%E8%B4%B9"><span class="toc-number">5.5.5.</span> <span class="toc-text">指定时间消费</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BC%8F%E6%B6%88%E8%B4%B9%E5%92%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="toc-number">5.5.6.</span> <span class="toc-text">漏消费和重复消费</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="toc-number">5.6.</span> <span class="toc-text">生产经验——消费者事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%89"><span class="toc-number">5.7.</span> <span class="toc-text">生产经验——数据积压（消费者如何提高吞吐量）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Eagle%E7%9B%91%E6%8E%A7"><span class="toc-number">6.</span> <span class="toc-text">Kafka-Eagle监控</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">6.1.</span> <span class="toc-text">MySQL环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">6.2.</span> <span class="toc-text">Kafka环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Eagle%E5%AE%89%E8%A3%85"><span class="toc-number">6.3.</span> <span class="toc-text">Kafka-Eagle安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDKafka-Eagle%E5%B9%B6%E8%A7%A3%E5%8E%8B"><span class="toc-number">6.3.1.</span> <span class="toc-text">下载Kafka-Eagle并解压</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEKafka-Eagle%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">6.3.2.</span> <span class="toc-text">配置Kafka-Eagle环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6system-config-properties"><span class="toc-number">6.3.3.</span> <span class="toc-text">修改配置文件system-config.properties</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Kafka-Eagle"><span class="toc-number">6.3.4.</span> <span class="toc-text">启动Kafka-Eagle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%9C%E6%AD%A2Kafka-Eagle"><span class="toc-number">6.3.5.</span> <span class="toc-text">停止Kafka-Eagle</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Eagle%E9%A1%B5%E9%9D%A2%E6%93%8D%E4%BD%9C"><span class="toc-number">6.4.</span> <span class="toc-text">Kafka-Eagle页面操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%99%BB%E5%BD%95%E9%A1%B5%E9%9D%A2%E6%9F%A5%E7%9C%8B%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.1.</span> <span class="toc-text">登录页面查看监控数据</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Kraft%E6%A8%A1%E5%BC%8F"><span class="toc-number">7.</span> <span class="toc-text">Kafka-Kraft模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Kraft%E6%9E%B6%E6%9E%84"><span class="toc-number">7.1.</span> <span class="toc-text">Kafka-Kraft架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Kraft%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">7.2.</span> <span class="toc-text">Kafka-Kraft集群部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Kraft%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E5%81%9C%E6%AD%A2%E8%84%9A%E6%9C%AC"><span class="toc-number">7.3.</span> <span class="toc-text">Kafka-Kraft集群启动停止脚本</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/06/10/virtualBox/" title="VirtualBox虚拟机磁盘扩容"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/648456981ddac507cc049e1e.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VirtualBox虚拟机磁盘扩容"/></a><div class="content"><a class="title" href="/2023/06/10/virtualBox/" title="VirtualBox虚拟机磁盘扩容">VirtualBox虚拟机磁盘扩容</a><time datetime="2023-06-10T19:35:23.000Z" title="发表于 2023-06-10 19:35:23">2023-06-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/02/dataStructure/" title="数据结构"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/6484545f1ddac507cc022402.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构"/></a><div class="content"><a class="title" href="/2023/06/02/dataStructure/" title="数据结构">数据结构</a><time datetime="2023-06-02T21:12:25.000Z" title="发表于 2023-06-02 21:12:25">2023-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例"><img src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hadoop生态综合案例"/></a><div class="content"><a class="title" href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例">Hadoop生态综合案例</a><time datetime="2023-05-27T14:32:15.000Z" title="发表于 2023-05-27 14:32:15">2023-05-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/17/rdd/" title="RDD"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64219d12a682492fcc086ebb.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RDD"/></a><div class="content"><a class="title" href="/2023/05/17/rdd/" title="RDD">RDD</a><time datetime="2023-05-17T09:43:41.000Z" title="发表于 2023-05-17 09:43:41">2023-05-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/09/java-home/" title="Java环境变量配置（多版本）"><img src= "/img/loading.gif" data-lazy-src="https://pic2.imgdb.cn/item/645b35d50d2dde5777454474.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java环境变量配置（多版本）"/></a><div class="content"><a class="title" href="/2023/05/09/java-home/" title="Java环境变量配置（多版本）">Java环境变量配置（多版本）</a><time datetime="2023-05-09T23:29:03.000Z" title="发表于 2023-05-09 23:29:03">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Shiqing Huang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.huangshiqing.website/',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.huangshiqing.website/',
      region: 'ap-shanghai',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><script>(() => {
  let initFn = window.walineFn || null

  const initWaline = (Fn) => {
    const waline = Fn(Object.assign({
      el: '#waline-wrap',
      serverURL: 'https://waline.huangshiqing.website/',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      path: window.location.pathname,
      comment: false,
    }, null))

    const destroyWaline = () => {
      waline.destroy()
    }

    btf.addGlobalFn('pjax', destroyWaline, 'destroyWaline')
  }

  const loadWaline = async () => {
    if (initFn) initWaline(initFn)
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css')
      const { init } = await import('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js')
      initFn = init || Waline.init
      initWaline(initFn)
      window.walineFn = initFn
    }
  }

  if ('Twikoo' === 'Waline' || !false) {
    if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
    else setTimeout(loadWaline, 0)
  } else {
    window.loadOtherComment = loadWaline
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.huangshiqing.website/',
        region: 'ap-shanghai',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script>(() => {
  const isChatBtn = true
  const isChatHideShow = false

  if (isChatBtn) {
    const close = () => {
      Chatra('minimizeWidget')
      Chatra('hide')
    }

    const open = () => {
      Chatra('openChat', true)
      Chatra('show')
    }

    window.ChatraSetup = {
      startHidden: true
    }
  
    window.chatBtnFn = () => {
      const isShow = document.getElementById('chatra').classList.contains('chatra--expanded')
      isShow ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        Chatra('hide')
      },
      show: () => {
        Chatra('show')
      }
    }
  }

  (function(d, w, c) {
    w.ChatraID = 'pyiEKDCMK4hBnRffY'
    var s = d.createElement('script')
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments)
    }
    s.async = true
    s.src = 'https://call.chatra.io/chatra.js'
    if (d.head) d.head.appendChild(s)
  })(document, window, 'Chatra')

})()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/movies/"]):not([href="/books/"]):not([href="/games/"]):not([href="/songs/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>