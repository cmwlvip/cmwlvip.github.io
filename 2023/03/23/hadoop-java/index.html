<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Java与Hadoop | Ofra Serendipity</title><meta name="author" content="Shiqing Huang"><meta name="copyright" content="Shiqing Huang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="通过Java API使用Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Java与Hadoop">
<meta property="og:url" content="https://www.huangshiqing.website/2023/03/23/hadoop-java/index.html">
<meta property="og:site_name" content="Ofra Serendipity">
<meta property="og:description" content="通过Java API使用Hadoop">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png">
<meta property="article:published_time" content="2023-03-23T20:28:48.000Z">
<meta property="article:modified_time" content="2023-03-27T00:00:00.000Z">
<meta property="article:author" content="Shiqing Huang">
<meta property="article:tag" content="Git">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="IDEA">
<meta property="article:tag" content="Java">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png"><link rel="shortcut icon" href="/img/favicon01.png"><link rel="canonical" href="https://www.huangshiqing.website/2023/03/23/hadoop-java/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: Shiqing Huang","link":"链接: ","source":"来源: Ofra Serendipity","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Java与Hadoop',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-27 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "/img/loading.gif" data-lazy-src="/img/avatar002.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart-pulse"></i><span> Fun</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book-open"></i><span> Book</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fab fa-steam"></i><span> Game</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i><span> Reference</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/2023/02/26/acwing/"><i class="fa-fw fas fa-arrow-right"></i><span> Acwing</span></a></li><li><a class="site-page child" href="/2022/11/03/KeyboardShutcut/"><i class="fa-fw fas fa-arrow-right"></i><span> 实用快捷键</span></a></li><li><a class="site-page child" href="/2022/10/27/TheCharmOfMarkdown/"><i class="fa-fw fas fa-arrow-right"></i><span> 了不起的 Markdown</span></a></li><li><a class="site-page child" href="/2022/11/03/HexoTagPlugins/"><i class="fa-fw fas fa-arrow-right"></i><span> Hexo Built-in Tag Plugins</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ofra Serendipity</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-heart-pulse"></i><span> Fun</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book-open"></i><span> Book</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fab fa-steam"></i><span> Game</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-star"></i><span> Reference</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/2023/02/26/acwing/"><i class="fa-fw fas fa-arrow-right"></i><span> Acwing</span></a></li><li><a class="site-page child" href="/2022/11/03/KeyboardShutcut/"><i class="fa-fw fas fa-arrow-right"></i><span> 实用快捷键</span></a></li><li><a class="site-page child" href="/2022/10/27/TheCharmOfMarkdown/"><i class="fa-fw fas fa-arrow-right"></i><span> 了不起的 Markdown</span></a></li><li><a class="site-page child" href="/2022/11/03/HexoTagPlugins/"><i class="fa-fw fas fa-arrow-right"></i><span> Hexo Built-in Tag Plugins</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Java与Hadoop</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-23T20:28:48.000Z" title="发表于 2023-03-23 20:28:48">2023-03-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-27T00:00:00.000Z" title="更新于 2023-03-27 00:00:00">2023-03-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>25分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="Java与Hadoop"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Git在IDEA中的使用"><a href="#Git在IDEA中的使用" class="headerlink" title="Git在IDEA中的使用"></a>Git在IDEA中的使用</h2><p>所建立的项目不在根目录下，可如下配置仓库根目录<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-23-02-06.png" alt="git配置"></p>
<h2 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h2><p><code>Maven</code>是通过项目对象模型文件<code>pom.xml</code>来管理项目的构建、报告和文档的工具。<br><strong>Maven是一种项目管理工具。</strong></p>
<h3 id="IDEA新建Maven项目"><a href="#IDEA新建Maven项目" class="headerlink" title="IDEA新建Maven项目"></a>IDEA新建Maven项目</h3><ol>
<li><p>创建新项目（新建的项目下就是一个模块）<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-20-40-48.png" alt="新建项目"><br>新建的<code>Maven</code>项目有一个<code>pom.xml</code>文件，内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>javaHadoop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>新建模块并进行相关设置<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-20-46-17.png" alt="右键单击项目名称"><br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-20-51-46.png" alt="新建模块"><br>创建模块完成后会在模块下新生成一个<code>pom.xml</code>文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>javaHadoop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.qf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>testHDFS<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Java程序使用HDFS"><a href="#Java程序使用HDFS" class="headerlink" title="Java程序使用HDFS"></a>Java程序使用HDFS</h2><h3 id="新建项目并配置pom-xml文件"><a href="#新建项目并配置pom-xml文件" class="headerlink" title="新建项目并配置pom.xml文件"></a>新建项目并配置pom.xml文件</h3><p>如果已有<code>Maven</code>项目，可新建模块，并配置模块下<code>pom.xml</code>文件，也可以直接新建项目，配置项目下的<code>pom.xml</code>文件。</p>
<p>（这里）新建<code>testHDFS</code>模块，并配置模块下<code>pom.xml</code>文件。<br><figure class="highlight xml"><figcaption><span>添加如下配置项</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.qf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>           <span class="comment">&lt;!--组织名--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>testHDFS<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>   <span class="comment">&lt;!--项目名--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hadoop客户端依赖，该依赖包含HDFS的相关依赖 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 单元测试的依赖 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.13.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><br>点击构建按钮进行构建即可。<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-21-28-08.png" alt="构建"></p>
<p>新建Java类<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-21-36-30.png" alt="新建Java类目录结构"></p>
<h3 id="基本功能实现"><a href="#基本功能实现" class="headerlink" title="基本功能实现"></a>基本功能实现</h3><figure class="highlight java"><figcaption><span>用到的包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br></pre></td></tr></table></figure>
<h4 id="将数据写入HDFS文件"><a href="#将数据写入HDFS文件" class="headerlink" title="将数据写入HDFS文件"></a>将数据写入HDFS文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将数据写入HDFS文件</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span>  <span class="keyword">void</span> <span class="title function_">writeToHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//创建配置文件对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//给配置文件设置HDFS文件默认入口</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        <span class="comment">//通过传入的配置参数得到FileSystem</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="comment">//获取HDFS上的 /1.txt 的绝对路径，/1.txt 是存在的也可以是不存在的</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">p</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/1.txt&quot;</span>);</span><br><span class="line">        <span class="comment">//FileSystem 通过 create() 方法获得输出流（FSDataOutputStream）</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> fs.create(p, <span class="literal">true</span>, <span class="number">1024</span>);</span><br><span class="line">        <span class="comment">//通过输出流将内容写入 1.txt 文件</span></span><br><span class="line">        fos.write(<span class="string">&quot;这是我在window用java API下写入的&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//关闭输出流</span></span><br><span class="line">        fos.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>在web界面查看，若文件内容一致，则操作成功<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-21-52-06.png" alt="web界面查看"></p>
<h4 id="读取HDFS文件"><a href="#读取HDFS文件" class="headerlink" title="读取HDFS文件"></a>读取HDFS文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读取HDFS文件</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">readHDFSFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//创建配置对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//设置HDFS文件系统的网络地址和端口号</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        <span class="comment">//通过配置获取文件系统</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="comment">//获取HDFS上的 /1.txt 的绝对路径</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">p</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/1.txt&quot;</span>);</span><br><span class="line">        <span class="comment">//通过 FileSystem 的open() 方法获得数据输入流</span></span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(p);</span><br><span class="line">        <span class="comment">//分配 1024 字节的内存给 buf （分配1024个字节的缓冲区）</span></span><br><span class="line">        <span class="type">byte</span>[] buf = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//循环读取文件到内容到缓冲区，读到文件末尾结束（结束标识符为-1）</span></span><br><span class="line">        <span class="keyword">while</span> ((len = fis.read(buf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">//输出读取的文件内容到控制台</span></span><br><span class="line">            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(buf, <span class="number">0</span>, len));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-21-58-08.png" alt="运行成功"></p>
<h4 id="从Windows系统下上传文件到HDFS"><a href="#从Windows系统下上传文件到HDFS" class="headerlink" title="从Windows系统下上传文件到HDFS"></a>从Windows系统下上传文件到HDFS</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//上传文件到HDFS</span></span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">putFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException&#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        FileSystem fs=FileSystem.get(conf);</span><br><span class="line">        <span class="comment">//文件上传到HDFS上的位置</span></span><br><span class="line">        Path p=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">        <span class="comment">//待上传文件1.sh在Windows系统的绝对路径，此处需要提前在Windows系统下D盘下新建1.sh文件，并写入 “文件上传成功！”</span></span><br><span class="line">        Path p2=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;file:///D:/1.sh&quot;</span>);</span><br><span class="line">        <span class="comment">//从本地（Windows系统）上传文件到HDFS</span></span><br><span class="line">        fs.copyFromLocalFile(p2,p);</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-23-22-02-18.png" alt="运行成功"></p>
<h2 id="Java与MapReduce"><a href="#Java与MapReduce" class="headerlink" title="Java与MapReduce"></a>Java与MapReduce</h2><h3 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h3><p>MapReduce编程的一般思路</p>
<ol>
<li>输入一系列键值对<code>(K1,V1)</code>。</li>
<li>通过<code>map()</code>方法和<code>reduce()</code>方法处理输入的键值对。<ol>
<li>用<code>map()</code>方法将<code>(K1,V1)</code>处理成<code>list(K2,V2)</code>的形式。</li>
<li>用<code>reduce()</code>方法将<code>(K2,list(V2))</code>处理成<code>list(K3,V3)</code>的形式。</li>
</ol>
</li>
</ol>
<p><strong>(1)实现Mapper</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span> ... &#123;</span><br><span class="line">    <span class="comment">//重写 map() 方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>(2)实现Reducer</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span> ... &#123;</span><br><span class="line">    <span class="comment">//重写 reduce() 方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>(3)创建MapReduce作业</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyApp</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="comment">//1.新建配置对象，为 配置对象设置文件系统</span></span><br><span class="line">        Configuration conf=<span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);<span class="comment">//通过构建jar包实现，这行可以不要</span></span><br><span class="line">        <span class="comment">//2.设置Job属性</span></span><br><span class="line">        Job job=Job.getInstance(conf);  <span class="comment">//通过Configuration获得Job实例</span></span><br><span class="line">        job.setJobName(<span class="string">&quot;MyApp&quot;</span>);    <span class="comment">//为Job命名</span></span><br><span class="line">        job.setJarByClass(MyApp.class); <span class="comment">//为Job运行设置主类</span></span><br><span class="line">        <span class="comment">//3.设置数据输入路径</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">inPath</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileInputFormat.addInputPath(job,inPath);</span><br><span class="line">        <span class="comment">//4.设置Job执行的Mapper类和输出K-V类型</span></span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">//5.设置执行的Reducer类和输出K-V类型</span></span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">//6.设置数据输出路径</span></span><br><span class="line">        Path outPath=<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job,outPath);</span><br><span class="line">        <span class="comment">//7.MepReduce作业完成后退出系统</span></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="MapReduce编程案例——WordCount"><a href="#MapReduce编程案例——WordCount" class="headerlink" title="MapReduce编程案例——WordCount"></a>MapReduce编程案例——WordCount</h3><p><strong>(1)配置MapReduce开发环境</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hadoop客户端依赖，该依赖包含HDFS的相关依赖 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 单元测试的依赖 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.13.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>(2)实现Mapper</strong><br><figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf.words;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br></pre></td></tr></table></figure><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable,Text,Text, IntWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.以行为单位，对数据进行处理</span></span><br><span class="line">        String line=value.toString();</span><br><span class="line">        <span class="comment">//2.以空格为分隔符，对单词进行拆分</span></span><br><span class="line">        String[] words=line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="comment">//3.迭代数组，将输出的K-V对存入context</span></span><br><span class="line">        <span class="keyword">for</span> (String s:words)&#123;</span><br><span class="line">            word.set(s);</span><br><span class="line">            context.write(word,one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>(3)实现Reducer</strong><br><figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf.words;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br></pre></td></tr></table></figure><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable,Text,IntWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key,Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.定义一个计数器</span></span><br><span class="line">        <span class="type">Integer</span> <span class="variable">counter</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//2.迭代数组，将输出的K-V对存入context</span></span><br><span class="line">        <span class="keyword">for</span> (IntWritable value:values)&#123;</span><br><span class="line">            counter+=value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key,<span class="keyword">new</span> <span class="title class_">IntWritable</span>(counter));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>(4)创建MapReduce作业</strong><br><figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf.words;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br></pre></td></tr></table></figure><br><figure class="highlight java"><figcaption><span>WordCountApp.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountApp</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">if</span> (args==<span class="literal">null</span> || args.length&lt;<span class="number">2</span>)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;参数不足，需要两个参数&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//1.新建配置对象，为 配置对象设置文件系统</span></span><br><span class="line">        Configuration conf=<span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//2.设置Job属性</span></span><br><span class="line">        Job job=Job.getInstance(conf,<span class="string">&quot;WordCountApp&quot;</span>);  <span class="comment">//通过Configuration获得Job实例</span></span><br><span class="line">        job.setJarByClass(WordCountApp.class); <span class="comment">//为Job运行设置主类</span></span><br><span class="line">        <span class="comment">//3.设置数据输入路径</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">inPath</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileInputFormat.addInputPath(job,inPath);</span><br><span class="line">        <span class="comment">//4.设置Job执行的Mapper类和输出K-V类型</span></span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">//5.设置执行的Reducer类和输出K-V类型</span></span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">//6.设置数据输出路径</span></span><br><span class="line">        Path outPath=<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job,outPath);</span><br><span class="line">        <span class="comment">//7.MepReduce作业完成后退出系统</span></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="将程序打包成jar包"><a href="#将程序打包成jar包" class="headerlink" title="将程序打包成jar包"></a>将程序打包成jar包</h4><p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-10-52-50.png" alt="打包成jar包"></p>
<div class="note info modern"><p>点击<code>package</code>即可实现程序打包，如果需要重新打包，则先点击<code>clean</code></p>
</div>
<figure class="highlight plaintext"><figcaption><span>执行日志</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">D:\ProgramFiles\Java1.8\bin\java.exe -Dmaven.multiModuleProjectDirectory=D:\Code\Code\Java\javaHadoop\testHDFS &quot;-Dmaven.home=D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\plugins\maven\lib\maven3&quot; &quot;-Dclassworlds.conf=D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\plugins\maven\lib\maven3\bin\m2.conf&quot; &quot;-Dmaven.ext.class.path=D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\plugins\maven\lib\maven-event-listener.jar&quot; &quot;-javaagent:D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\lib\idea_rt.jar=58341:D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin&quot; -Dfile.encoding=UTF-8 -classpath &quot;D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\plugins\maven\lib\maven3\boot\plexus-classworlds-2.6.0.jar;D:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\plugins\maven\lib\maven3\boot\plexus-classworlds.license&quot; org.codehaus.classworlds.Launcher -Didea.version=2022.2.1 package</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --------------------------&lt; com.qf:testHDFS &gt;---------------------------</span><br><span class="line">[INFO] Building testHDFS 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ testHDFS ---</span><br><span class="line">[INFO] Using &#x27;UTF-8&#x27; encoding to copy filtered resources.</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ testHDFS ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[INFO] Compiling 6 source files to D:\Code\Code\Java\javaHadoop\testHDFS\target\classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ testHDFS ---</span><br><span class="line">[INFO] Using &#x27;UTF-8&#x27; encoding to copy filtered resources.</span><br><span class="line">[INFO] skip non existing resourceDirectory D:\Code\Code\Java\javaHadoop\testHDFS\src\test\resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ testHDFS ---</span><br><span class="line">[INFO] Nothing to compile - all classes are up to date</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ testHDFS ---</span><br><span class="line">[INFO] No tests to run.</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ testHDFS ---</span><br><span class="line">[INFO] Building jar: D:\Code\Code\Java\javaHadoop\testHDFS\target\testHDFS-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time:  3.541 s</span><br><span class="line">[INFO] Finished at: 2023-03-26T10:54:56+08:00</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">进程已结束,退出代码0</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-10-57-30.png" alt="打包后的jar包出现在target文件夹下"></p>
<p>更改jar包名称(本案例中可改为<code>wordCount.jar</code>)将jar包拖至虚拟机(hsq01)中。</p>
<figure class="highlight shell"><figcaption><span>运行MapReduce作业常用格式</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar jar Jar包 完整包名类名 待处理HDFS上绝对路径 文件处理后在HDFS上存放的路径</span><br></pre></td></tr></table></figure>
<figure class="highlight txt"><figcaption><span>测试文件word.txt</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop hive</span><br><span class="line">hive hbase</span><br><span class="line">flume sqoop</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>启动Hadoop集群上传测试文件至HDFS</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put word.txt /</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><figcaption><span>在本案例中</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar wordCount.jar com.qf.words.WordCountApp /word.txt /outdata</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><figcaption><span>程序执行日志</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">[root@hsq01 ~]# hadoop jar wordCount.jar com.qf.words.WordCountApp /word.txt /outdata</span><br><span class="line">2023-03-26 11:15:07,520 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at hsq01/192.168.56.201:8032</span><br><span class="line">2023-03-26 11:15:08,412 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</span><br><span class="line">2023-03-26 11:15:08,488 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1679800440436_0001</span><br><span class="line">2023-03-26 11:15:08,900 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">2023-03-26 11:15:09,054 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">2023-03-26 11:15:09,439 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1679800440436_0001</span><br><span class="line">2023-03-26 11:15:09,439 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2023-03-26 11:15:09,667 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2023-03-26 11:15:09,667 INFO resource.ResourceUtils: Unable to find &#x27;resource-types.xml&#x27;.</span><br><span class="line">2023-03-26 11:15:10,205 INFO impl.YarnClientImpl: Submitted application application_1679800440436_0001</span><br><span class="line">2023-03-26 11:15:10,267 INFO mapreduce.Job: The url to track the job: http://hsq01:8088/proxy/application_1679800440436_0001/</span><br><span class="line">2023-03-26 11:15:10,268 INFO mapreduce.Job: Running job: job_1679800440436_0001</span><br><span class="line">2023-03-26 11:15:21,570 INFO mapreduce.Job: Job job_1679800440436_0001 running in uber mode : false</span><br><span class="line">2023-03-26 11:15:21,571 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2023-03-26 11:15:30,025 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2023-03-26 11:15:38,160 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2023-03-26 11:15:39,184 INFO mapreduce.Job: Job job_1679800440436_0001 completed successfully</span><br><span class="line">2023-03-26 11:15:39,315 INFO mapreduce.Job: Counters: 54</span><br><span class="line">        File System Counters</span><br><span class="line">                FILE: Number of bytes read=77</span><br><span class="line">                FILE: Number of bytes written=552231</span><br><span class="line">                FILE: Number of read operations=0</span><br><span class="line">                FILE: Number of large read operations=0</span><br><span class="line">                FILE: Number of write operations=0</span><br><span class="line">                HDFS: Number of bytes read=126</span><br><span class="line">                HDFS: Number of bytes written=40</span><br><span class="line">                HDFS: Number of read operations=8</span><br><span class="line">                HDFS: Number of large read operations=0</span><br><span class="line">                HDFS: Number of write operations=2</span><br><span class="line">                HDFS: Number of bytes read erasure-coded=0</span><br><span class="line">        Job Counters</span><br><span class="line">                Launched map tasks=1</span><br><span class="line">                Launched reduce tasks=1</span><br><span class="line">                Data-local map tasks=1</span><br><span class="line">                Total time spent by all maps in occupied slots (ms)=5825</span><br><span class="line">                Total time spent by all reduces in occupied slots (ms)=5549</span><br><span class="line">                Total time spent by all map tasks (ms)=5825</span><br><span class="line">                Total time spent by all reduce tasks (ms)=5549</span><br><span class="line">                Total vcore-milliseconds taken by all map tasks=5825</span><br><span class="line">                Total vcore-milliseconds taken by all reduce tasks=5549</span><br><span class="line">                Total megabyte-milliseconds taken by all map tasks=5964800</span><br><span class="line">                Total megabyte-milliseconds taken by all reduce tasks=5682176</span><br><span class="line">        Map-Reduce Framework</span><br><span class="line">                Map input records=3</span><br><span class="line">                Map output records=6</span><br><span class="line">                Map output bytes=59</span><br><span class="line">                Map output materialized bytes=77</span><br><span class="line">                Input split bytes=91</span><br><span class="line">                Combine input records=0</span><br><span class="line">                Combine output records=0</span><br><span class="line">                Reduce input groups=5</span><br><span class="line">                Reduce shuffle bytes=77</span><br><span class="line">                Reduce input records=6</span><br><span class="line">                Reduce output records=5</span><br><span class="line">                Spilled Records=12</span><br><span class="line">                Shuffled Maps =1</span><br><span class="line">                Failed Shuffles=0</span><br><span class="line">                Merged Map outputs=1</span><br><span class="line">                GC time elapsed (ms)=203</span><br><span class="line">                CPU time spent (ms)=1120</span><br><span class="line">                Physical memory (bytes) snapshot=339787776</span><br><span class="line">                Virtual memory (bytes) snapshot=5115379712</span><br><span class="line">                Total committed heap usage (bytes)=165810176</span><br><span class="line">                Peak Map Physical memory (bytes)=217137152</span><br><span class="line">                Peak Map Virtual memory (bytes)=2553217024</span><br><span class="line">                Peak Reduce Physical memory (bytes)=122650624</span><br><span class="line">                Peak Reduce Virtual memory (bytes)=2562162688</span><br><span class="line">        Shuffle Errors</span><br><span class="line">                BAD_ID=0</span><br><span class="line">                CONNECTION=0</span><br><span class="line">                IO_ERROR=0</span><br><span class="line">                WRONG_LENGTH=0</span><br><span class="line">                WRONG_MAP=0</span><br><span class="line">                WRONG_REDUCE=0</span><br><span class="line">        File Input Format Counters</span><br><span class="line">                Bytes Read=35</span><br><span class="line">        File Output Format Counters</span><br><span class="line">                Bytes Written=40</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-11-18-46.png" alt="HDFS系统中出现输出目录"><br>下载<code>part-r-00000</code>查看结果<br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-11-21-39.png" alt="查看结果"><br><figure class="highlight plaintext"><figcaption><span>part-r-00000</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">flume	1</span><br><span class="line">hadoop	1</span><br><span class="line">hbase	1</span><br><span class="line">hive	2</span><br><span class="line">sqoop	1</span><br></pre></td></tr></table></figure><br><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-11-16-45.png" alt="yarn集群Web界面查看"></p>
<h2 id="项目——气象数据分析"><a href="#项目——气象数据分析" class="headerlink" title="项目——气象数据分析"></a>项目——气象数据分析</h2><h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0169501360999992018010100004+52970+122530FM-12+043399999V0201401N00101026001C9004700199-02041-02321102941ADDAA124001531AJ100003100000099GA1081+026001101GA2999+999999101GA3999+999999101GE19MSL   +99999+99999GF108991081999026001999999MA1999999097051MD1210061-0101REMSYN004BUFR</span><br><span class="line">0165501360999992018010103004+52970+122530FM-12+043399999V0201101N0010122000199004900199-01651-02051102921ADDAJ100079100070099AY171031AY201031GA1021+026001101GA2999+999999101GA3999+999999101GE19MSL   +99999+99999GF102991021999026001999999MD1210021+9999MW1001REMSYN004BUFR</span><br></pre></td></tr></table></figure>
<h2 id="项目——交通卡口表"><a href="#项目——交通卡口表" class="headerlink" title="项目——交通卡口表"></a>项目——交通卡口表</h2><h3 id="卡口表数据格式"><a href="#卡口表数据格式" class="headerlink" title="卡口表数据格式"></a>卡口表数据格式</h3><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">道路编号,设备编号,设备名称,部门编码,部门名称,x坐标,y坐标,启用时间,,</span><br><span class="line">600312009000,42050006500001000503,高新-大连路汕头路口南向北,420500060000,宜昌支队高新区大队,111.33272,30.70787,2020-04-15,,</span><br><span class="line">600312009000,42050006500002000503,高新-大连路汕头路口南向北卡口,420500060000,宜昌支队高新区大队,111.33273,30.70791,2020-04-15,,</span><br></pre></td></tr></table></figure>
<h3 id="JavaAPI操作Hbase"><a href="#JavaAPI操作Hbase" class="headerlink" title="JavaAPI操作Hbase"></a>JavaAPI操作Hbase</h3><h4 id="新建项目并配置pom-xml文件-1"><a href="#新建项目并配置pom-xml文件-1" class="headerlink" title="新建项目并配置pom.xml文件"></a>新建项目并配置pom.xml文件</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.qf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>testHbase<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 单元测试的依赖 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.13.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><figcaption><span>导包</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.qf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line"><span class="comment">//import org.apache.hadoop.hbase.HColumnDescriptor;//已弃用</span></span><br><span class="line"><span class="comment">//import org.apache.hadoop.hbase.HTableDescriptor;</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br></pre></td></tr></table></figure>
<h4 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">//创建Hbase连接对象</span></span><br><span class="line">        Configuration conf= HBaseConfiguration.create();</span><br><span class="line">        <span class="comment">//获取zookeeper配置</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;192.168.56.201,192.168.56.202,192.168.56.203&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">//建立与Hbase的连接</span></span><br><span class="line">            <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> ConnectionFactory.createConnection(conf);</span><br><span class="line">            Admin admin=conn.getAdmin();</span><br><span class="line">            <span class="comment">//设置表名称</span></span><br><span class="line">            TableName tableName=TableName.valueOf(<span class="string">&quot;test&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;连接：&quot;</span> + conn + <span class="string">&quot;-HMaster:&quot;</span>+admin);</span><br><span class="line">            <span class="comment">//判断表是否存在，如果存在就删除</span></span><br><span class="line">            <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">                <span class="keyword">if</span>(admin.isTableEnabled(tableName))&#123;</span><br><span class="line">                    admin.disableTable(tableName);</span><br><span class="line">                &#125;</span><br><span class="line">                admin.deleteTable(tableName);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//创建HTableDescriptor对象，并添加表名称</span></span><br><span class="line">            <span class="comment">//`org.apache.hadoop.hbase.HTableDescriptor&#x27; 已被弃用</span></span><br><span class="line"><span class="comment">//        HTableDescriptor table= new HTableDescriptor(tableName);</span></span><br><span class="line">            <span class="comment">//创建HColumnDescriptor对象，并添加列簇名称</span></span><br><span class="line">            <span class="comment">//&#x27;org.apache.hadoop.hbase.HColumnDescriptor&#x27; 已被弃用</span></span><br><span class="line"><span class="comment">//        HColumnDescriptor cf1=new HColumnDescriptor(&quot;cf1&quot;);</span></span><br><span class="line"><span class="comment">//        HColumnDescriptor cf2=new HColumnDescriptor(&quot;cf2&quot;);</span></span><br><span class="line">            ColumnFamilyDescriptor columnFamily1= ColumnFamilyDescriptorBuilder</span><br><span class="line">                    .newBuilder(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>))</span><br><span class="line">                    .build();</span><br><span class="line">            ColumnFamilyDescriptor columnFamily2=ColumnFamilyDescriptorBuilder</span><br><span class="line">                    .newBuilder(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>))</span><br><span class="line">                    .build();</span><br><span class="line">            TableDescriptor table=TableDescriptorBuilder</span><br><span class="line">                    .newBuilder(tableName)</span><br><span class="line">                    .setColumnFamily(columnFamily1)</span><br><span class="line">                    .setColumnFamily(columnFamily2)</span><br><span class="line">                    .build();</span><br><span class="line">            <span class="comment">//创建表</span></span><br><span class="line">            admin.createTable(table);</span><br><span class="line">            TableName[] tableNames=admin.listTableNames();</span><br><span class="line">            <span class="comment">//查看所有的表</span></span><br><span class="line">            <span class="keyword">for</span> (TableName tablesName:tableNames)&#123;</span><br><span class="line">                System.out.println(tablesName);</span><br><span class="line">            &#125;</span><br><span class="line">            conn.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="写数据"><a href="#写数据" class="headerlink" title="写数据"></a>写数据</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addData</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">//获取Hadoop相关配置</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">hadoopConf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    hadoopConf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">    <span class="comment">//获取zookeeper配置</span></span><br><span class="line">    conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">    conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;192.168.56.201,192.168.56.202,192.168.56.203&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        FileSystem fs=FileSystem.get(hadoopConf);</span><br><span class="line">        Path path=<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/transport/transport.csv&quot;</span>);</span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span>fs.open(path);</span><br><span class="line">        BufferedReader br=<span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(in,<span class="string">&quot;GBK&quot;</span>));</span><br><span class="line"><span class="comment">//            BufferedReader br=new BufferedReader(new InputStreamReader(in));</span></span><br><span class="line">        String line;</span><br><span class="line">        <span class="comment">// 配置HBase连接</span></span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> ConnectionFactory.createConnection(conf);</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> conn.getTable(TableName.valueOf(<span class="string">&quot;transport&quot;</span>));</span><br><span class="line">        br.readLine();<span class="comment">//读取第一行</span></span><br><span class="line">        <span class="type">int</span> n=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>((line=br.readLine())!=<span class="literal">null</span>)&#123;</span><br><span class="line">            String[] arr=line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">            <span class="comment">// 创建一个Put实例</span></span><br><span class="line">            <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(String.valueOf(n)));</span><br><span class="line">            <span class="comment">// 添加列族和列名、值</span></span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>), Bytes.toBytes(<span class="string">&quot;roadId&quot;</span>), Bytes.toBytes(arr[<span class="number">0</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>), Bytes.toBytes(<span class="string">&quot;deviceId&quot;</span>), Bytes.toBytes(arr[<span class="number">1</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>), Bytes.toBytes(<span class="string">&quot;deviceName&quot;</span>), Bytes.toBytes(arr[<span class="number">2</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>), Bytes.toBytes(<span class="string">&quot;departmentId&quot;</span>), Bytes.toBytes(arr[<span class="number">3</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf1&quot;</span>), Bytes.toBytes(<span class="string">&quot;departmentName&quot;</span>), Bytes.toBytes(arr[<span class="number">4</span>]));</span><br><span class="line"></span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>), Bytes.toBytes(<span class="string">&quot;x&quot;</span>), Bytes.toBytes(arr[<span class="number">5</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>), Bytes.toBytes(<span class="string">&quot;y&quot;</span>), Bytes.toBytes(arr[<span class="number">6</span>]));</span><br><span class="line">            put.addColumn(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>), Bytes.toBytes(<span class="string">&quot;time&quot;</span>), Bytes.toBytes(arr[<span class="number">7</span>]));</span><br><span class="line">            <span class="keyword">try</span>&#123;</span><br><span class="line">                put.addColumn(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>), Bytes.toBytes(<span class="string">&quot;other&quot;</span>), Bytes.toBytes(arr[<span class="number">8</span>]));</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                put.addColumn(Bytes.toBytes(<span class="string">&quot;cf2&quot;</span>), Bytes.toBytes(<span class="string">&quot;other&quot;</span>), Bytes.toBytes(<span class="string">&quot;null&quot;</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            table.put(put);</span><br><span class="line">            n++;</span><br><span class="line">            System.out.println(arr[<span class="number">0</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">1</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">2</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">3</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">4</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">5</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">6</span>]+<span class="string">&quot;\t&quot;</span>+arr[<span class="number">7</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        table.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="读数据"><a href="#读数据" class="headerlink" title="读数据"></a>读数据</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">readData</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">//获取Hadoop相关配置</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">hadoopConf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        hadoopConf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">        <span class="comment">//获取zookeeper配置</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.56.201:9000&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;192.168.56.201,192.168.56.202,192.168.56.203&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="comment">// 配置HBase连接</span></span><br><span class="line">            <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> ConnectionFactory.createConnection(conf);</span><br><span class="line">            <span class="comment">//获取表对象</span></span><br><span class="line">            <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> conn.getTable(TableName.valueOf(<span class="string">&quot;transport&quot;</span>));</span><br><span class="line">            <span class="comment">//创建Scan对象</span></span><br><span class="line">            Scan scan=<span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            <span class="comment">//通过扫描器得到结果集</span></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">rs</span> <span class="operator">=</span>table.getScanner(scan);</span><br><span class="line"><span class="comment">//            //得到迭代器</span></span><br><span class="line"><span class="comment">//            Iterator&lt;Result&gt; it= rs.iterator();</span></span><br><span class="line"><span class="comment">//            printData(it);</span></span><br><span class="line">            printNeedData(rs, <span class="string">&quot;cf2&quot;</span>.getBytes(),Bytes.toBytes(<span class="string">&quot;time&quot;</span>));</span><br><span class="line">            table.close();</span><br><span class="line">            conn.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><figcaption><span>迭代读取</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//迭代输出每行的所有数据</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printData</span><span class="params">(Iterator&lt;Result&gt; it)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext())&#123;</span><br><span class="line">        Result next=it.next();</span><br><span class="line">        List&lt;Cell&gt; cells=next.listCells();</span><br><span class="line">        <span class="keyword">for</span> (Cell cell:cells)&#123;</span><br><span class="line">            String row=Bytes.toString(CellUtil.cloneRow(cell));</span><br><span class="line">            String cf=Bytes.toString(CellUtil.cloneFamily(cell));</span><br><span class="line">            String qualifier=Bytes.toString(CellUtil.cloneQualifier(cell));</span><br><span class="line">            String value=Bytes.toString(CellUtil.cloneValue(cell));</span><br><span class="line">            System.out.println(row+<span class="string">&quot;,&quot;</span>+cf+<span class="string">&quot;:&quot;</span>+qualifier+<span class="string">&quot;,&quot;</span>+value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><figcaption><span>读取指定簇与列</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//输出指定簇、列</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">printNeedData</span><span class="params">(ResultScanner rs,<span class="type">byte</span>[] columnFamily, <span class="type">byte</span>[] qualifier)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> rs.next(); result != <span class="literal">null</span>; result = rs.next()) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">date</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(result.getValue(columnFamily, qualifier));</span><br><span class="line">        System.out.println(date);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><div class="note waring modern"><p>Hbase建表报错:<code>ERROR: org.apache.hadoop.hbase.PleaseHoldException: Master is initializing</code></p>
</div>
<p><img src= "/img/loading.gif" data-lazy-src="/2023/03/23/hadoop-java/2023-03-26-16-16-26.png" alt="ERROR"></p>
<p>解决办法：</p>
<ol>
<li>删除HDFS中存在的Hbase(Hbase配置中<code>hbase.rootdir</code>路径)</li>
<li>删除zookeeper中存在的Hbase<ol>
<li>zkCli.sh</li>
<li>deleteall /hbase(rmr /hbase)</li>
</ol>
</li>
</ol>
<div class="note info modern"><p>如果在使用ZooKeeper客户端命令行界面时，输入 <code>rmr /hbase</code> 出现 rmr 命令不存在的情况，可能是因为当前版本的ZooKeeper已经将 rmr 命令从命令行界面中删除。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://www.huangshiqing.website">Shiqing Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.huangshiqing.website/2023/03/23/hadoop-java/">https://www.huangshiqing.website/2023/03/23/hadoop-java/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.huangshiqing.website" target="_blank">Ofra Serendipity</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Git/">Git</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/IDEA/">IDEA</a><a class="post-meta__tags" href="/tags/Java/">Java</a></div><div class="post_share"><div class="social-share" data-image="https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "/img/loading.gif" data-lazy-src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/15/hbase-install/"><img class="prev-cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64120132ebf10e5d533c6ba9.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HBase三种搭建方式</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/27/spark3-3-2/"><img class="next-cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64219d12a682492fcc086ebb.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Spark部署与快速入门</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/12/03/Git/" title="Git"><img class="cover" src= "/img/loading.gif" data-lazy-src="/2022/12/03/Git/git.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-03</div><div class="title">Git</div></div></a></div><div><a href="/2022/10/25/HadoopClusterBuilding3-3-4/" title="Hadoop 3.3.4 集群搭建"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-25</div><div class="title">Hadoop 3.3.4 集群搭建</div></div></a></div><div><a href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-27</div><div class="title">Hadoop生态综合案例</div></div></a></div><div><a href="/2023/03/15/hbase-install/" title="HBase三种搭建方式"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64120132ebf10e5d533c6ba9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-15</div><div class="title">HBase三种搭建方式</div></div></a></div><div><a href="/2023/03/27/zookeeper3-8-1/" title="Zookeeper部署"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/642156eda682492fcc8b5b4e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-27</div><div class="title">Zookeeper部署</div></div></a></div><div><a href="/2023/05/08/kafka3-4-0/" title="Kafka"><img class="cover" src= "/img/loading.gif" data-lazy-src="https://pic2.imgdb.cn/item/645a5d440d2dde57777f32d1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-08</div><div class="title">Kafka</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Waline</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "/img/loading.gif" data-lazy-src="/img/avatar002.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Shiqing Huang</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cmwlvip"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cmwlvip" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://gitee.com/cmwlvip" target="_blank" title="Gitee"><i class="fab fa-git"></i></a><a class="social-icon" href="mailto:2689050828@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Git%E5%9C%A8IDEA%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.</span> <span class="toc-text">Git在IDEA中的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maven"><span class="toc-number">2.</span> <span class="toc-text">Maven</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#IDEA%E6%96%B0%E5%BB%BAMaven%E9%A1%B9%E7%9B%AE"><span class="toc-number">2.1.</span> <span class="toc-text">IDEA新建Maven项目</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java%E7%A8%8B%E5%BA%8F%E4%BD%BF%E7%94%A8HDFS"><span class="toc-number">3.</span> <span class="toc-text">Java程序使用HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE%E5%B9%B6%E9%85%8D%E7%BD%AEpom-xml%E6%96%87%E4%BB%B6"><span class="toc-number">3.1.</span> <span class="toc-text">新建项目并配置pom.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.</span> <span class="toc-text">基本功能实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5HDFS%E6%96%87%E4%BB%B6"><span class="toc-number">3.2.1.</span> <span class="toc-text">将数据写入HDFS文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96HDFS%E6%96%87%E4%BB%B6"><span class="toc-number">3.2.2.</span> <span class="toc-text">读取HDFS文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8EWindows%E7%B3%BB%E7%BB%9F%E4%B8%8B%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0HDFS"><span class="toc-number">3.2.3.</span> <span class="toc-text">从Windows系统下上传文件到HDFS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java%E4%B8%8EMapReduce"><span class="toc-number">4.</span> <span class="toc-text">Java与MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">MapReduce编程模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E7%BC%96%E7%A8%8B%E6%A1%88%E4%BE%8B%E2%80%94%E2%80%94WordCount"><span class="toc-number">4.2.</span> <span class="toc-text">MapReduce编程案例——WordCount</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85%E6%88%90jar%E5%8C%85"><span class="toc-number">4.2.1.</span> <span class="toc-text">将程序打包成jar包</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">5.</span> <span class="toc-text">项目——气象数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.1.</span> <span class="toc-text">数据格式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E4%BA%A4%E9%80%9A%E5%8D%A1%E5%8F%A3%E8%A1%A8"><span class="toc-number">6.</span> <span class="toc-text">项目——交通卡口表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%A1%E5%8F%A3%E8%A1%A8%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="toc-number">6.1.</span> <span class="toc-text">卡口表数据格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JavaAPI%E6%93%8D%E4%BD%9CHbase"><span class="toc-number">6.2.</span> <span class="toc-text">JavaAPI操作Hbase</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE%E5%B9%B6%E9%85%8D%E7%BD%AEpom-xml%E6%96%87%E4%BB%B6-1"><span class="toc-number">6.2.1.</span> <span class="toc-text">新建项目并配置pom.xml文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="toc-number">6.2.2.</span> <span class="toc-text">创建表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.3.</span> <span class="toc-text">写数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.4.</span> <span class="toc-text">读数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">6.3.</span> <span class="toc-text">问题</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/09/hello-world/" title="Hello World"><img src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/63676da116f2c2beb11fa14a.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2024/06/09/hello-world/" title="Hello World">Hello World</a><time datetime="2024-06-09T16:55:08.076Z" title="发表于 2024-06-09 16:55:08">2024-06-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/10/virtualBox/" title="VirtualBox虚拟机磁盘扩容"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/648456981ddac507cc049e1e.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VirtualBox虚拟机磁盘扩容"/></a><div class="content"><a class="title" href="/2023/06/10/virtualBox/" title="VirtualBox虚拟机磁盘扩容">VirtualBox虚拟机磁盘扩容</a><time datetime="2023-06-10T19:35:23.000Z" title="发表于 2023-06-10 19:35:23">2023-06-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/02/dataStructure/" title="数据结构"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/6484545f1ddac507cc022402.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构"/></a><div class="content"><a class="title" href="/2023/06/02/dataStructure/" title="数据结构">数据结构</a><time datetime="2023-06-02T21:12:25.000Z" title="发表于 2023-06-02 21:12:25">2023-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例"><img src= "/img/loading.gif" data-lazy-src="https://pic1.imgdb.cn/item/6366396d16f2c2beb1036f1c.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hadoop生态综合案例"/></a><div class="content"><a class="title" href="/2023/05/27/HadoopDemo/" title="Hadoop生态综合案例">Hadoop生态综合案例</a><time datetime="2023-05-27T14:32:15.000Z" title="发表于 2023-05-27 14:32:15">2023-05-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/17/rdd/" title="RDD"><img src= "/img/loading.gif" data-lazy-src="https://pic.imgdb.cn/item/64219d12a682492fcc086ebb.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RDD"/></a><div class="content"><a class="title" href="/2023/05/17/rdd/" title="RDD">RDD</a><time datetime="2023-05-17T09:43:41.000Z" title="发表于 2023-05-17 09:43:41">2023-05-17</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic.imgdb.cn/item/642157d0a682492fcc8d0a06.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Shiqing Huang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.huangshiqing.website/',
      region: 'ap-shanghai',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.huangshiqing.website/',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadWaline () {
  function insertCSS () {
    const link = document.createElement("link")
    link.rel = "stylesheet"
    link.href = "https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css"
    document.head.appendChild(link)
  }

  function initWaline () {
    const waline = Waline.init(Object.assign({
      el: '#waline-wrap',
      serverURL: 'https://waline.huangshiqing.website/',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      path: window.location.pathname,
      comment: false,
    }, null))
  }

  if (typeof Waline === 'function') initWaline()
  else {
    insertCSS()
    getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(initWaline)
  }
}

if ('Twikoo' === 'Waline' || !false) {
  if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
  else setTimeout(loadWaline, 0)
} else {
  function loadOtherComment () {
    loadWaline()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.huangshiqing.website/',
        region: 'ap-shanghai',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/movies/"]):not([href="/books/"]):not([href="/games/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>